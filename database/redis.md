访问模式
- 通过函数库调用的方式供外部应用使用
- 通过网络框架以socket通信的形式对外提供键值对操作

单线程与多线程的取舍
- 单线程如果某一部发生阻塞，那么整个的线程都会阻塞住，从而影响系统的响应速度
- 多线程会因为共享资源而残生线程竞争，这就需要使用额外的机制来进行保证，从而影响系统效率。并且如果使用了粗颗粒度的互斥锁，即使增加了线程，大部分的线程也是在等待获取共享资源的互斥锁，从而变成串行。采用多线程会引入同步原语来保护共享资源的并发访问，从而降低了系统代码的可调试性和可维护性。

内存键值的数据库一般使用哈希表来作为索引，因为键值数据保存在内存中。内存高性能的随机访问特性可以很好的与哈希表O(1)的操作复杂度相匹配。

持久化
- 每次修改都进行落盘，这会对性能造成影响
- 周期性的落盘，有丢失数据的风险

![nFl8gO](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/nFl8gO.png)

[[redis#压缩列表|压缩列表]]：表头有三个字段 zlbytes、zltail、zllen，分别表示列表长度、列表的尾偏移量和列表中entry的个数。

跳表：在列表的基础上增加了多级索引，通过索引位置的跳转，可以实现数据的快速定位。

> [!faq] Hash类型什么时候使用压缩列表，什么时候使用哈希表？
> 用压缩列表保存数据时有两个阈值，一旦超过了就使用哈希表来保存数据
> - hash-max-ziplist-entries：用压缩列表保存时哈希集合中的最大元素个数
> - hash-max-ziplist-value：用压缩列表保存时哈希集合中国单个元素的最大长度

使用ZipList存储时尽量使用int数据，因为ZipList在涉及时每个entry都进行了优化，针对要存储的数据，会尽量选择占用内存小的方式存储(整数比字符串在存储时占用内存更小)

==Sorted Set使用压缩列表存储时的缺点==
- 存储时需要按照score排序(为了方便zrange和zrevrange命令的使用)，所以在插入一个元素的时候，需要先根据score找到对应的位置，然后把member和score插进去，从而插入元素的性能没有Hash高。
- 在查询指定元素的时候需要遍历整个ziplist，所以使用ziplist方式存储，可以利用CPU高速缓存，但是不适合存储过多的数据，否则查询性能会下降很大
- ZipList每个元素紧凑排列，且每个元素存储了上一个元素的长度，所以当修改其中一个元素超过i一定大小的时候，会引发级联调整(前面一个元素发生大的变化，后面的元素都要重新排列位置，重新分配内存)
- 使用Hash和Sorted Set存储时，虽然节省了内存空间，但是设置过期变得困难(无法控制每个元素的过期，只能整个key设置过期，或者业务层单独维护每个元素过期删除的逻辑，但比较复杂)。而使用string虽然占用内存多，但是每个key都可以单独设置过期时间，还可以设置maxmemory和淘汰策略，以这种方式控制整个实例的内存上限。


> [!faq] 为什么数组与压缩列表的时间复杂度较高却还要使用？
> - 它们是==连续存储==的，并且比链表占用更少的空间，Redis是内存数据库，大量的数据存储在内存中，所以需要尽可能的优化来提升内存的利用率。
> - 数组对CPU的高速缓存支持更好，集合数据较少的情况下，默认使用内存紧凑排列的方式来进行存储，同时利用CPU高速缓存不会降低访问速度。当数据的元素超过阈值之后，避免查询时间复杂度太高，转为哈希和跳表数据结构存储，从而保证查询效率。对数组和压缩列表的数据大小限制在64字节以下，大于64字节就会改变存储的数据结构，所以随机访问对于CPU的高速缓存没有影响。

Redis中用fork创建的子进程
- 创建RDB的后台子进程，同时由它负责在主从同步时传输RDB给从库
- 通过误判复制方式传输RDB的子进程
- bgrewriteaof子进程

# 哈希桶

![k1K7vx](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/k1K7vx.png)

如何解决哈希冲突
- 拉链法，如果某些哈希冲突链过长，会导致这个链上而查找时间变长
- 渐进式rehash，使用两个Hashtable
	- 给Hashtable2分配更大的空间，可以是Hashtable1的两倍
	- 当Hashtable1满了之后，每处理一个请求，就从Hashtable1的第一个索引位置开始，顺带着将这个索引位置上的所有entries拷贝到Hashtable2中，等到下一个请求时，再拷贝下一个索引位置的entries，如果一定时间没有新的请求的话，也会定期的进行拷贝
	- 释放Hashtable1的空间

==Redis的单线程指的是网络IO和键值对读写事由一个线程来完成的，其他的功能由额外的线程完成==

单线程的Redis为什么快？
- 大部分操作是在内存上完成的
- 高效的数据结构
- 多路复用机制

# AOF

写后日志：先执行命令，把数据写入内存，然后才记录日志

**为什么要使用AOF？**
AOF中记录的是Redis收到的每一条命令，这些都是以文本的形式来保存的。并且为了避免额外的检查开销，在记录日志的时候不会先去对这些命令进行语法检查，所以如果先记录再执行的话，可能就会记录了错误的命令，这样在使用日志恢复数据的时候就会出错。

如果先记录再执行的话就需要提前检查命令是否正确，或者在命令错误之后再进行删除记录，这样就会增加复杂度

使用AOF的==好处==
- 避免了记录错误命令的情况
- 不会阻塞当前的写操作

使用AOF的==风险==
- 如果刚执行完一条命令，还没有记日志就宕机了，那这个命令和对应的数据就会有丢失的风险
- 不会对当前命令造成阻塞，但是可能会对下一个命令造成阻塞。因为AOF日志也是在主线程中执行的，如果把日志文件写入磁盘时，磁盘的写入压力大，就会导致写盘很慢，进而导致后续的操作也无法执行。

写回策略
- Always，同步写回，每个命令执行完立马同步将日志写回磁盘
- Everysec，每秒写回：先把日志写到AOF文件的内存缓冲区
- No，操作系统控制的写回：先把日志写到AOF文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘

AOF文件太大导致的性能问题
- 文件系统本身对文件的大小有限制，无法保存过大的文件
- 如果文件太大，之后再往里边追加记录的话，效率会变低
- 如果宕机，AOF中记录的命令要一个个的重新执行，如果日志文件太大，恢复过程就会非常缓慢，从而影响Redis正常使用

如何解决AOF文件太大的问题？
AOF重写机制：根据数据库的现状创建一个新的AOF文件。即根据键值对当前的最新状态为其生成对应的写入命令。==但是==要把整个数据库的最新数据的操作日志都写回磁盘会非常耗时。

==重写AOF不会阻塞Redis==，重写是由后台子线程来完成的，子线程会把主线程的内存拷贝一份，其中就包括了最新的数据，在添加新的日志时，不仅会添加到主线程的AOF日志中，也会添加到子线程的AOF重写日志中，在重写完之后就可以用新的AOF代替旧的文件了。

## 在重写过程中可能产生的阻塞
1. fork子进程，fork这个瞬间一定是会阻塞主线程的（注意，fork时并不会一次性拷贝所有内存数据给子进程），fork采用操作系统提供的写时复制(Copy On Write)机制，就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞问题，但fork子进程需要拷贝进程必要的数据结构，其中有一项就是拷贝内存页表（虚拟内存和物理内存的映射索引表），这个拷贝过程会消耗大量CPU资源，拷贝完成之前整个进程是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork阻塞时间越久。拷贝内存页表完成后，子进程与父进程指向相同的内存地址空间，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小。那什么时候父子进程才会真正内存分离呢？“写实复制”顾名思义，就是在写发生时，才真正拷贝内存真正的数据，这个过程中，父进程也可能会产生阻塞的风险，就是下面介绍的场景。

2. fork出的子进程指向与父进程相同的内存地址空间，此时子进程就可以执行AOF重写，把内存中的所有数据写入到AOF文件中。但是此时父进程依旧是会有流量写入的，如果父进程操作的是一个已经存在的key，那么这个时候父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认4k，如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险。另外，如果操作系统开启了内存大页机制(Huge Page，页面大小2M)，那么父进程申请内存时阻塞的概率将会大大提高，所以在Redis机器上需要关闭Huge Page机制。Redis每次fork生成RDB或AOF重写完成后，都可以在Redis log中看到父进程重新申请了多大的内存空间。

Huge page会提升TLB的命中率，因为在相同的内存容量下，使用huge page会减少页表项，TLB可以换成更多的页表项，从而减少 TLB miss 的开销。但是这个机制对于像Redis这种喜欢fork的系统并不友好，尤其是在写入请求比较多的情况下，因为fork之后，父进程修改数据采用写时复制，复制的颗粒度是一个内存页，如果只是修改一个256B的数据，父进程需要读原来的内存页，然后再映射到新的物理地址写入，一读一写会造成读写放大，如果内存页越大，那么读写放大也就会越严重，从而对Redis的性能造成影响。

为什么是要父进程来进行写时复制？
如果是子进程进行复制，而主进程直接改数据的话
- 如果子进程还没有把一块数据写入RDB时，主进程就修改了数据，那么快照完整性就被破坏了
- 子进程复制数据时，也需要加锁，避免主线程同时修改，如果此时主线程正好有写请求要处理，主线程同样会被阻塞

==快照之后复制出来的地址与原数据是怎么处理的？==
重写AOF结束之后，子进程退出，冗余的内存会被释放，还给操作系统。

## 重写日志为什么不共享AOF本身的日志？
1. 父子进程写同一个文件必然会产生==竞争==问题，控制竞争就意味着会影响父进程的性能。（这里即使不这样也会产生竞争吧）
2. 如果AOF重写过程中失败了，那么原本的AOF文件相当于被==污染==了，无法做恢复使用。所以Redis AOF重写一个新文件，重写失败的话，直接删除这个文件就好了，不会对原先的AOF文件产生影响。等重写完成之后，直接替换旧文件即可。

# 内存快照(RDB)

- 对哪些数据做快照？关系到快照的执行效率问题
- 做快照时，数据还能被增删改吗？关系到Redis是否被阻塞，能否同时正常处理请求

==全量快照==：把内存中所有的数据都记录到磁盘中
好处：一次性记录了所有的数据
坏处：全部写入磁盘会花很多的时间

生成RDB文件的方式
- save：在主线程中执行，会导致阻塞
- bgsave：创建一个子进程，专门用于写入RDB文件，避免了主线程的阻塞，是默认配置。

在使用bgsave的时候还可以正常运行，因为是==写时复制==。bgsave子进程实际上复制了主线程的页表，其中保存了在执行bgsave命令时主线程的所有数据块在内存中的物理地址。主线程在写时会把新写或修改后的数据写入到新的物理地址中，并修改自己的页表映射。

频繁执行全量快照带来的开销
- 频繁将全量数据写入磁盘，会给磁盘带来很大的压力，多个快照竞争有限的磁盘带宽，前一个还没有做完，后一个又开始做了，容易造成恶性循环
- 子进程创建之后不会再阻塞主线程，但是==fork这个创建过程本身就会阻塞主线程==，而且主线程的内存越大，阻塞时间越长，所以在Redis中如果有一个bgsave在运行，就不会再启动第二个bgsave子进程

==增量快照==：只需要将被修改的数据写入快照文件，前提是记住哪些数据被修改了。但是这个记录又会带来额外的空间开销。

==混合使用AOF日志和内存快照==：内存快照以一定的频率执行，在两次快照之间，使用AOF日志记录这期间的所有命令操作。

快照可以不用很频繁的执行，避免了对主线程的影响，AOF日志也不需要记录所有的操作，从而不会出现文件过大的情况，避免了重写开销

# 数据库同步

高可靠性
- 数据尽量少丢失，AOF和RDB
- 服务尽量少中断，增加副本冗余量


## 主从库读写分离
读操作：主库、从库都可以接收
写操作：先到主库执行，然后主库将写操作同步给从库

### 主从数据不一致

**原因**：主从库间的命令复制是异步进行的，主库收到新的写命令之后会发送给从库，但是主库自己在本地执行完命令后，就会把结果返回客户端，如果从库还没有执行主库同步过来的命令，主从库之间的数据就不一致了。

从库滞后执行同步命令的原因
- 主从库间的网络可能会有传输延迟，所以从库不能及时接收到主库发送的命令，从库上执行同步命令的时间就会被延迟
- 从库可能正在处理其他复杂度高的命令而阻塞

解决方案
- 硬件配置上尽量保证主从库间的网络连接状况良好
- 开发一个外部的程序来监控主从库间的复制进度
	- 如果某个从库的进度差值大于预设的阈值，可以让客户端不再和这个从库连接进行数据读取，这样就可以减少读到不一致数据的情况

### 读取过期数据

Redis使用两种策略删除过期的数据
- 惰性删除
	- 当一个数据到期之后，不会立即删除数据，而是等到再有请求来读写这个数据时，对数据进行检查，如果发现数据已经过期了，再删除这个数据
	- 这样可以减少CPU的使用，但是会导致大量已经过期的数据留存在内存中，占用比较多的内存资源
	- 如果客户端从主库上读到过期的数据，主库会触发删除操作，但是读到从库上的过期数据，从库不会触发删除操作，而是会返回空值，但是还是可能会从从库读到过期的数据，因为有些命令给数据设置的过期时间在从库上会被延后，导致过期的数据又在从库上被读取到了。
	- EXPIRE、PEXPIRE：给数据设置的是从命令执行时开始计算的存活时间
	- EXPIREAT、PEXPIREAT：直接把数据的过期时间设置为具体的一个时间点
- 定期删除
	- Redis每隔一段时间就会随机选出一定数量的数据。检查它们是否过期，并把其中过期的数据删除
	- 为了避免过多删除操作对性能的影响，每次随机检查数据的数量不多，如果过期的数据很多，并且一直没有再被访问，这数据就会留存在Redis实例中，从而导致业务应用读到过期的数据

### 不合理的配置项导致的服务挂掉

1. protected-mode
	限定哨兵实例能否被其他服务器访问，yes时只能在部署的服务器本地进行访问，no时可以被其他服务器访问
	
	如果为yes，而其他的哨兵实例部署在其他的服务器，那么这些哨兵实例之间就无法进行通信，从而无法判断主库下线，也无法进行主从切换，最终Redis服务不可用
	
	在应用主从集群时，将其设置为no，并将bind设置为其他哨兵实例的IP地址

2. cluster-node-timeout
	Redis Cluster中实例响应心跳消息的超时时间


> [!faq] 为什么使用读写分离？
> 如果主库从库都可以接收客户端的写操作，客户端对同一个数据修改了三次，但每一次请求都发送到不同的实例上，在不同的实例上执行，那么这三个实例上的副本就不一致了，在读取这个数据的时候就可能读取到旧的值。
> 如果非要保持这个数据在这三个实例上一致，就要涉及加锁、实例间协商是否完成修改的一系列操作，但这会带来巨大的开销。

主从数据库之间的复制
![EMMn4g](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/EMMn4g.png)

- 从库发送psync给主库，其中包括主库的runID和复制进度offset，主库使用FULLRESYNC来回复，包括主库runID和主库当前的复制进度offset，FULLRESYNC表示响应第一次使用**全量复制**(==这里还没有进行复制，只是进行了一下回复==)
- 主库将所有数据同步给从库，从库收到后在本地完成数据的加载。同步的是内存快照生成的RDB文件。从库在加载RDB文件时为了避免之前数据的影响，会先把当前的数据库清空
- 主库完成RDB文件发送之后，把replication buffer中的修改操作发送给从库，从库重新执行这些操作。

runID：每个Redis实例启动时自动生成的一个随机ID，用来唯一标记这个实例

在主库将数据同步给从库的过程中，主库不会被阻塞，主库会使用在内存中专用的replication buffer来记录RDB文件生成后收到的所有写操作。

==？？？==
**replication buffer的作用** redis的slave buffer（replication buffer，master端上）存放的数据是下面三个时间内所有的master数据更新操作。 
- master执行rdb bgsave产生snapshot的时间 
- master发送rdb到slave网络传输时间 
- slave load rdb文件把数据恢复到内存的时间 

**replication buffer太小会引发的问题**： replication buffer由client-output-buffer-limit slave设置，当这个值太小会导致主从复制链接断开。
- 当master-slave复制连接断开，server端会释放连接相关的数据结构。replication buffer中的数据也就丢失了，此时主从之间重新开始复制过程。 
- 还有个更严重的问题，主从复制连接断开，导致主从上出现rdb bgsave和rdb重传操作无限循环。

主库的压力：每次全量复制都要生成和传输RDB文件
解决方案：使用主从级联的模式，在部署的时候**手动选择**一个从库用于级联其他的从库
**基于长连接的命令传播**：一旦主从库完成了全量复制，就会一直维护一个网络连接用于之后的命令操作的同步，从而避免频繁建立连接的开销。(==这个阶段是通过命令传播来实现同步的而不是文件==)

增量复制：可以解决网络断连的问题

[[redis#复制积压缓冲区|repl_backlog_buffer]]是一个环形缓冲区，主库会记录自己写到的位置(master_repl_offset)，从库会记录自己读到的位置(slave_repl_offset)，这个buffer只会在主从重连的时候才会起作用，在主从连接正常时，即使master覆盖了slave的数据也没事，因为数据都在replication buffer里。 ^fs8pq4

在断网之后，主库会将命令写入repl_backlog_buffer这个缓冲区。

如果环形区满了之后，就会覆盖之前写入的操作，这样就会导致主从库数据的不一致，从而执行全量复制。

> [!info] repl_backlog_buffer与replication buffer之间的区别
> - repl_backlog_buffer是为了从库断开之后如何找到主从数据差异而设计的环形缓冲区，从而避免了全量同步带来的性能开销。主节点只会有一个repl_backlog_buffer
> - replication buffer是主库为每一个client分配的client buffer，所有数据交互都是通过这个buffer进行的，redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。
> - replication buffer的大小是有限制的，如果超过限制主库就会强制断开这个client的连接，中断后如果从库再次发起复制请求，就可能会导致恶性循环，引发复制风暴。
> - replication buffer 是主从库进行全量复制的时候主库用于和从库连接的客户端的buffer，在全量复制时，主库会先创建一个客户端来连接从库，然后通过这个客户端把写操作的命令发送给从库。

> [!faq] 为什么主从库之间的复制不使用AOF？
> - RDB是二进制文件，无论是要把RDB写入磁盘还是要通过网络传输RDB，IO效率都比记录和传输AOF高
> - 在从库进行恢复时，用RDB的恢复效率高于AOF

# 哨兵机制

主从库切换涉及到的三个问题：
- 主库真的挂了吗
- 该选择哪个从库作为主库
- 怎么把新主库相关的信息通知给从库和客户端

哨兵的任务：监控、选主、通知
- 在监控任务中，需要判断主库是否处于下线状态
- 在选主任务中，需要决定选择哪个从库实例作为主库

## 主观下线与客观下线

**主观下线**：哨兵进程使用PING命令检查他自己和主、从库的网络连接情况，用来判断实例的状态。如果哨兵发现主库或从库对PING命令的响应超时了，哨兵就会先把它标记为"主观下线"
**客观下线**：大多数的哨兵实例都判断主库已经"主观下线"，主库才会被标记位客观下线。

**客观下线的判断过程**
任何一个实例只要自身判断主库"主观下线"之后，就会给其他实例发送`is-master-down-by-addr`的命令，接着其他实例就会根据自己和主库的连接情况做出 Y/N 的响应。一个哨兵拿到了仲裁所需的赞成票数之后，就可以标记为"客观下线"，所需的赞成票数是由哨兵配置文件中的quorum设定的

## 由哪个哨兵执行主从切换？
在哨兵把主库标记为"客观下线之后"就可以给其他哨兵发送命令表示希望自己来执行主从切换，并让所有的哨兵来投票。

**成为Leader的条件**
- 拿到半数以上的赞成票
- 拿到的票数大于等于quorum

对于主库的主观下线来说，是不能直接进行标记的，因为很可能哨兵进行了误判，并且会导致主从切换的启动，后续的选主和通知操作都会带来额外的计算和通信开销。

> [!faq] 为什么会发生误判？
> 一般是因为集群的压力比较大、网络拥塞，或者是主库本身压力较大的情况下

选定新的主库的时候先按一定的筛选条件进行筛选，然后按照一定的规则对剩下的库进行打分，将得分最高的从库选为新的主库。

**筛选**：检查从库的当前在线状态以及它之前的网络连接状态，通过设置主从库的最大连接超时时间来判断网络连接状态，如果发生断连的次数超过了10次，就说明这个从库的网络状况不好，不适合作为新主库。

打分规则
- 从库优先级：手动进行设定
- 从库复制进度：根据master_repl_offset和repl_backlog_buffer来进行判断
- 从库ID：ID最小的从库得分最高

只要在某一轮中有从库得分最高，那么它就是主库了，如果结束之后还没有主库，那就继续进行下一轮

> 在哨兵集群中有实例挂了怎么办，会影响主库状态判断和选主吗？
> 哨兵集群多数实例达成共识，判断出主库客观下线后，由哪个实例来执行主从切换？

如果客户端使用了读写分离，那么在主库挂了之后，读请求仍然可以在从库上正常执行。但是写请求会失败，如果不想让业务感知到异常，客户端只能把写失败的请求先缓存起来或写入消息队列中间件中，等哨兵切换完主从之后再把这些写请求发送给新的主库，但是这种场景只适合对写入请求不敏感的业务，而且还需要业务层做适配，另外主从切换时间过长也会导致客户端或消息队列中间件缓存写请求过多，切换完成之后重放这写请求的时间变长。

应用程序不感知服务的中断，还需要哨兵和客户端做些什么？
当哨兵完成主从切换后，客户端需要及时感知到主库发生了变更，然后把缓存的写请求写入到新库中，保证后续写请求不会再受到影响，具体做法如下： 哨兵提升一个从库为新主库后，哨兵会把新主库的地址写入自己实例的pub/sub（switch-master）中。客户端需要订阅这个**pub/sub**，当这个pub/sub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址，然后把写请求写到这个新主库即可，这种机制属于**哨兵主动通知客户端**。 如果客户端因为某些原因错过了哨兵的通知，或者哨兵通知后客户端处理失败了，安全起见，客户端也需要支持主动去获取最新主从的地址进行访问。 所以，客户端需要访问主从库时，不能直接写死主从库的地址了，而是需要从哨兵集群中获取最新的地址（sentinel get-master-addr-by-name命令），这样当实例异常时，哨兵切换后或者客户端断开重连，都可以从哨兵集群中拿到最新的实例地址。
一般Redis的SDK都提供了通过哨兵拿到实例地址，再访问实例的方式，我们直接使用即可，不需要自己实现这些逻辑。当然，对于只有主从实例的情况，客户端需要和哨兵配合使用，而在分片集群模式下，这些逻辑都可以做在proxy层，这样客户端也不需要关心这些逻辑了，Codis就是这么做的。 

 1、哨兵集群中有实例挂了，怎么办，会影响主库状态判断和选主吗？
 这个属于分布式系统领域的问题了，指的是在分布式系统中，如果存在故障节点，整个集群是否还可以提供服务？而且提供的服务是正确的？ 这是一个分布式系统容错问题，这方面最著名的就是分布式领域中的“拜占庭将军”问题了，“拜占庭将军问题”不仅解决了容错问题，还可以解决错误节点的问题，虽然比较复杂，但还是值得研究的，有兴趣的同学可以去了解下。 
 简单说结论：存在故障节点时，只要集群中大多数节点状态正常，集群依旧可以对外提供服务。具体推导过程细节很多，大家去查前面的资料了解就好。 
 
 2、哨兵集群多数实例达成共识，判断出主库“客观下线”后，由哪个实例来执行主从切换呢？ 
 哨兵集群判断出主库“主观下线”后，会选出一个“哨兵领导者”，之后整个过程由它来完成主从切换。 但是如何选出“哨兵领导者”？这个问题也是一个分布式系统中的问题，就是我们经常听说的共识算法，指的是集群中多个节点如何就一个问题达成共识。共识算法有很多种，例如Paxos、Raft，这里哨兵集群采用的类似于Raft的共识算法。 
 简单来说就是每个哨兵设置一个随机超时时间，超时后每个哨兵会请求其他哨兵为自己投票，其他哨兵节点对收到的第一个请求进行投票确认，一轮投票下来后，首先达到多数选票的哨兵节点成为“哨兵领导者”，如果没有达到多数选票的哨兵节点，那么会重新选举，直到能够成功选出“哨兵领导者”。

# 哨兵集群

- 哨兵通过 pub/sub 机制组成集群
- 哨兵通过 INFO 命令获得从库的连接信息，从而和从库建立连接对其进行监控
- 主从切换之后，哨兵会把新主库的信息告诉客户端

## pub/sub 机制

哨兵只要和主库建立起了连接，就可以在主库上发布消息，比如他自己的连接信息，同时，它也可以从主库上订阅信息，获得其他哨兵发布的连接信息。

频道：消息的类别
只有订阅了同一个频道的应用才能通过发布的消息进行信息交换。

哨兵不仅需要彼此之间建立连接形成集群，还需要与从库建立连接。因为在哨兵的监控任务中，需要对主从库都进行心跳判断，而且在主从库切换完成之后，还需要通知从库，让它们和新主库进行同步。

## INFO命令
**哨兵如何知道从库的IP地址和端口号？**
哨兵给主库发送==INFO==命令，主库接受到这个命令之后，会把从库的列表返回给哨兵，哨兵就可以根据从库列表中的连接信息和每个从库建立连接，并且在这个连接上持续的对从库进行监控。

**客户端如何通过监控了解哨兵进行主从切换的过程？**
可以使用 pub/sub 机制，因为哨兵本质上相当于一个运行在特定模式下的Redis实例，只完成监控、选主和通知的任务。所以客户端可以从哨兵订阅消息。

客户端如何从哨兵订阅消息？
客户端读取哨兵配置文件可以获得哨兵的地址和端口号，从而和哨兵建立连接，然后就可以在客户端执行订阅命令来获取不同的事件消息。

> [!question] 哨兵实例是不是越多越好？
> 哨兵在判定"主观下线"和选举"Leader"时，都需要和其他节点进行通信，交换信息，哨兵实例越多，通信的次数也就越多，而且部署多个哨兵时，会分布在不同机器上，节点越多带来的机器故障风险也会越大，这些问题都会影响到哨兵的通信和选举，出问题时也就意味着选举时间会变长，切换主从时间变久

> [!faq] 调大down-after-milliseconds 是否对减少误判有好处？
> 有好处，适当调大可以降低哨兵和主库之间网络存在短时波动的误判率，但是调大也意味着主从切换的时间会变长，对业务的影响时间越久，需要根据实际场景进行权衡，设置合理的阈值。

# 切片集群
启动多个Redis实例组成一个集群，然后按照一定的规则把收到的数据划分成多份，每一份用一个实例来保存。

- 纵向扩展：升级单个Redis实例的配置
- 横向扩展：横向增加当前Redis实例的个数

纵向扩展的缺点：
- 随着数据量的增加，进行RDB持久化的时候，主线程fork子进程时可能会阻塞
- 受到硬件和成本的限制

横向扩展的问题：
- 数据切片后，在多个实例之间如何分布
- 客户端怎么确定想要访问的数据在哪个实例上

Redis Cluster：使用哈希槽(应该和445里边的哈希桶差不多)一个集群有16384个哈希槽
如果遇到不同实例的内存大小不一，可以手动进行分配哈希槽，例如内存大的实例多保存几个哈希槽，**在手动分配的时候必须把16384个全部分配完，否则集群无法正常工作**

在集群刚创建的时候，每个实例只知道自己被分配了哪些哈希槽，不知道其他实例拥有的哈希槽的信息。之后Redis实例会把自己的哈希槽信息扩散给和它相连的其他哈希槽，这样每一个实例就都能知道所有的哈希槽映射信息了，客户端知道哈希槽的分布之后，会缓存一份到本地。

==实例和哈希槽对应的关系可能会发生变化==
- 在集群中，实例有新增或删除，Redis需要重新分配哈希槽
- 为了负载均衡，Redis需要把哈希槽在所有实例上重新分配一遍

重定向机制：如果一个实例上没有相应的数据，但是客户端要对其进行写操作，那么实例就会给客户端发生MOVED命令，其中包括了新实例的地址，然后客户端再重新访问新实例。

==写的时候怎么办==
如果迁移了一部分的话
- 实例给客户端返回ASK，表示键值所在的哈希槽正在迁移
- 客户端发送ASKING，让实例运行执行客户端接下来发生的命令
- 客户端发生GET读取数据

ASK命令的含义
- 表面slot数据还在迁移
- 把客户端所请求数据的最新实例地址返回给客户端，但是并不会更新客户端缓存的哈希槽的分配信息。

## 哈希表什么时候rehash

- 装载因子大于等于1可以rehash
- 装载因子大于等于5立马开始rehash

如果正在进行RDB生成和AOF重写，rehash是被禁止的，这是为了避免对RDB和AOF重写造成影响

Redis会执行定时任务，其中就包括了rehash操作，所以在rehash被触发之后，即使没有收到新请求，也会定时执行一次rehash操作，并且每次执行时长不会超过1ms，以免对其他任务造成影响。

# String

string除了记录实际数据之外，还会分配额外的内存空间来记录数据长度、空间使用等信息，即元数据。

当实际保存的数据较小时，元数据的空间开销就显得比较大了。

## int编码
当保存64位有符号整数时，string会把它保存成一个8字节的Long类型整数。

![68Be7R](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/68Be7R.png)

当保存的数据中包含字符时，string会使用简单动态字符串(SDS)来保存
- buf：字节数组，保存实际数据，为了表示字节数组的结束，会自动在数组最后加一个\0，额外占用一个字节
- len：4字节，表示buf的已用长度
- alloc：4字节，表示buf的实际长度


![kb8FSo](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/kb8FSo.png)

除了SDS的额外开销，string还有来自于RedisObject结构体的开销
RedisObject统一记录不同数据类型想特的元数据(例如最后一次访问的时间、被引用的次数)，同时指向实际数据

当保存的是==Long类型的整数==时，RedisObject中的==指针直接赋值为整数数据==，这样就不用额外的指针指向整数了，从而节省了指针的空间开销

## embstr编码

当保存的是字符串数据，且字符串小于44字节时，RedisObject中的元数据、指针和SDS是一块连续的内存区域，从而避免了内存碎片

## raw编码

当字符串大于44字节时，SDS会分配独立的空间，并用指针指向SDS结构

![SYg9dn](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/SYg9dn.png)

Redis使用的内存分配库是jemalloc，在分配内存时，会向上取到 2^N

# 压缩列表

![j12Oud](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/j12Oud.png)

表头的三个字段分别表示列表长度、列表尾的偏移量，以及列表中entry的个数
表尾的zlend表示列表结束

- prev_len：前一个entry的长度
	- 取值1字节表示上一个entry的长度==小于==254字节，1字节可以表示0到255，但是zlend默认取值255，所以用255表示整个压缩列表的结束，其他表示长度的地方就不可以使用255了。5字节的prev_len的第一个字节就是254，如果1字节的prev_len能够等于254，就无法判断prev_len的长度究竟是1字节还是5字节了，所以使用255作为是否结束的标识数，254作为prev_len占用空间是1字节还是5字节的标识数，这样就只剩下254个数了。
	- 取值5字节
- len：自身长度，4字节
- encoding：编码方式，1字节
- content：保存实际数据

 基于==hash类型==的二级编码：把一个单值的数据拆分成两部分，前一部分作为hash集合的key，后一部分作为hash集合的value

# 常用的集合统计模式

![gwEtG9](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/gwEtG9.png)

## 聚合统计

统计多个集合元素的聚合结果: 包括统计多个集合的共有元素(**交集**)；把两个集合相比，统计其中一个集合独有的元素(**差集**)；统计多个集合的所有元素(**并集**)。

这个可以使用集合Set来进行操作

==Set的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算会导致Redis实例阻塞==
解决方案：从主从集群中选择一个从库，让其专门负责聚合计算，或把数据读到客户端没在客户端完成聚合统计。

## 排序统计

Redis中的有序集合：List、Sorted Set
List按照放入的顺序进行排序
Sorted Set按照元素的权重进行排序，权重是可以自己进行设置的

List在进行分页的时候可能会出现已排好序的元素在新元素进入后被挤到其他页的情况。因为在对比新元素插入前后，List相同位置上的元素会发生变化，所以在同一个位置会读到旧元素。

==在数据更新频繁或者是需要分页显示的时候，优先使用 Sorted Set==

## 二值状态统计

二值状态指集合中元素的取值只有0和1两种
在二值状态的统计中，可以使用Bitmap，这样就可以有效的节省内存空间。

## 基数统计

统计一个集合中不重复的元素的个数

HyperLogLog
当数据量很大的时候，Set和Hash都会消耗很大的内存空间，而HyperLogLog最大的优势就是**当集合元素数量非常多的时候，计算基数所需的时间是固定的，而且还很小**。

在Redis中HyperLogLog最多只需要12KB的内存就可以计算接近2^64个元素的基数

HyperLogLog的统计规则是基于概率完成的，所以统计结果会有一定的误差。


# GEO

GEO非常适合应用在基于位置信息服务(LBS)的应用
GEO的底层数据结构是Sorted Set

## GeoHash编码
先对经度和维度分别进行编码，然后再把经纬度各自的编码组合成一个最终的编码。

组合的规则：最终编码的偶数位上依次是经度的编码值，奇数位上依次是纬度的编码值，其中偶数位从0开始，奇数位从1开始。

## Redis的基本对象结构

![DddOvo](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/DddOvo.png)

- type：值的类型
- encoding：值的编码方式，用来表示Redis中实现各个基本类型的底层数据结构，如SDS、压缩列表、哈希表、跳表等
- lru：记录了这个对象最后一次被访问的时间，用于淘汰过期的键值对
- refcount：记录了对象的引用次数
- \*ptr：指向数据的指针


# 时间序列数据的保存

时序数据的特点
- 没有严格的关系模型，记录的信息可以表示成键和值的关系。
- 插入数据快，这就要求选择的数据类型进行数据插入时复杂度要低，尽量不用阻塞
- 读的时候有单条多条记录的查询以及像聚合计算

如何保存时序数据？
- 将数据同时保存在Hash与Sorted Set中
- 使用RedisTimeSeries

## 为什么保持时序数据要同时使用Hash和Sorted Set

如果使用==Hash==保存时序数据的话，可以把时间戳作为key，设备Id作为value
Hash支持单条以及多条记录的查询，但是==不支持对数据进行范围查询==，因为Hash的底层结构是哈希表，并没有对数据进行有序索引，所以要进行范围查询的话，就需要扫描所有的数据，然后在将其在客户端进行排序，所以查询效率很低

如果想要支持按时间戳的查询，可以使用==Sorted Set==来对时序数据进行保存，因为他可以根据元素的权重分数来进行排序，所以我们可以把==时间戳作为分数==，把==时间点上记录的数据作为元素本身==。

## 如何保证写入Hash和Sorted Set是一个原子性的操作

MULTI和EXEC是用来实现简单的事务的，当多个命令及其参数本身无误时，MULTI和EXEC可以保证执行这些命令的原子性

- MULTI：表示一系列原子性操作的==开始==。收到这个命令之后，Redis就知道接下来再收到的命令需要放到一个内部队列中，后续一起进行执行，保证原子性
- EXEC：表示一系列原子性操作的==结束==，一旦Redis收到这个命令，就表示所有要保证原子性的命令操作都已经发送完毕。此时Redis开始执行刚才放到内部队列中的所有命令操作。

如果使用Redis集群来进行部署，那么就不能保证原子性了，因为不支持分布式事务。

在使用MULTI和EXEC命令时，客户端可以使用[[redis#^wj93a4|pipeline]]，当使用pipeline时，客户端会把命令一次性批量发送给服务端，然后让服务端执行，这样就可以减少客户端和服务端的来回网络IO次数，提升访问性能。

## 如何对时序数据进行聚合计算

使用Sorted Set进行聚合计算的话，需要先把时间范围内的数据取回到客户端，然后在客户端完成聚合计算，但是这样会导致大量数据在Redis实例和客户端之间频繁传输，从而与其他操作命令竞争网络资源，导致其他操作变慢。


# 消息队列

![xPoa1h](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/xPoa1h.png)

消息队列：生产者将要处理的数据以消息的形式传递给消息队列，然后消费者组件从中读取消息在本地进行处理

消息队列在存取数据时必须满足的三个需求
- 消息保序
- 处理重复的消息(可能因为网络阻塞而出现消息重传出现)
- 保证消息可靠性(因为机器故障而没有处理完)

## 基于List的消息队列解决方案

1. 消息保序
	生产者使用LPUSH将要发送的消息依次写入LIST，消费者使用RPOP在另一端依次读取消息并进行处理
	
	==问题==：生产者不会主动通知有新消息写入，这就需要消费者不停的调用RPOP，从而导致消费者CPU不必要的浪费
	解决方案：阻塞式读取(BRPOP)，没有消息时，消费者自动阻塞，直到有新的数据写入队列，再开始读取新数据。
	当有数据的时候，会通知被阻塞的线程，用到了多线程的阻塞唤醒机制

2. 处理重复的消息
	消息队列为每一个消息提供全局唯一的ID，消费者将已经处理的消息的ID记录下来
	**是否可以使用一个自增的ID，这样消费者只需要记录最后处理的消息的ID，从而节省了空间**
	
	幂等性：对于同一条消息，消费者受到一次的处理结果和收到多次的处理结果一致。
	
	LIist本身不会生成ID，所以需啊哟生产者在发送消息前自己生成

3. 保证消息可靠性
	当消费者从List读取消息之后，List就不再保存这个消息了，所以当消费者宕机之后就无法再次获取这个消息。
	
	BRPOPLPUSH：让消费者从一个List中读取消息，同时Redis把这个消息再插入到另一个List留存，在消费完之后将其删除，防止备份队列存储过多无用的数据，导致内存浪费

List的缺点：不支持消费组，这样如果消费者比生产者慢很多就会给内存造成很大的压力

## 基于Streams的消息队列解决方案

Streams可以创建消费组并让消费组内的消费者读取消息，这样就可以让组内的多个消费者分担读取消息，从而实现消息读取负载在多个消费者之间是均衡分布的。

消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了。

如何保证消息可靠性？
Streams会自动使用内部队列留存消费组里每个消费者读取的消息，直到消费者使用XACK命令通知Streams"消息已经处理完成"


# Redis可能存在的阻塞点

影响Redis性能的5大潜在因素
- Redis内部的阻塞式操作
- CPU核和NUMA架构的影响
- Redis关键系统配置
- Redis内存碎片
- Redis缓冲区

Redis实例的阻塞点：
- 客户端：网络IO，键值对增删改查操作，数据库操作
- 磁盘：生成RDB快照，记录AOF日志，AOF日志重写
- 主从节点：主库生成、传输RDB文件、从库接收RDB文件、清空数据库、加载RDB文件
- 切片集群实例：向其他实例传输哈希槽信息，数据迁移

## 和客户端交互时的阻塞点

1. 集合全量查询和聚合操作
2. bigkey删除操作(删除包含大量元素的集合)
	在释放内存的时候，操作系统会把释放掉的内存块插入到一个空闲内存块的链表，以便后续进行管理和再分配，这需要一定的时间，并且会阻塞当前释放内存的应用程序，所以一次释放大量的内存，空闲内存块链表的操作时间就会增加，从而造成Redis主线程的阻塞
3. 清空数据库

## 和磁盘交互时的阻塞点

4. AOF日志同步写
	Redis直接记录AOF日志时，会根据不同的写回策略对数据做落盘保存。一个同步写磁盘的操作的耗时大约是1~2ms，如果有大量的写操作要记录在AOF日志中，并同步写回的话，就会阻塞主线程了

## 主从节点交互时的阻塞

5. 加载RDB文件
	从库在接收了RDB文件之后需要使用FLUSHDB来清空当前数据库(即第三个阻塞点)，在接收到之后还需要将RDB文件加载到内存中，这个过程所需要的时间与RDB文件的大小密切相关

## 切片集群实例交互时的阻塞点

当部署Redis Cluster时，每个Redis实例上分配的哈希槽信息需要在不同实例之间进行传递，同时当需要进行负载均衡或者有实例增删时，数据会在不同的实例之间进行迁移。

如果迁移的正好是bigkey的话，会造成主线程的阻塞，因为Redis Cluster使用的是同步迁移。


**关键路径上的操作**：客户端把请求发生给Redis后，等着Redis返回数据操作的结果
读操作是典型的关键路径上的操作

五大阻塞点除了"集合全量查询和聚合操作"和"从库加载RDB文件"，其他三个所涉及的操作都不在关键路径上。

## 异步子线程

Redis启动之后会创建3个子线程，分别负责AOF日志写操作，键值对删除以及文件关闭的异步操作

主线程会通过链表形式的任务队列和子线程进行交互。
这里有可能会涉及到多个操作使用子线程，而主线程会监控子线程的任务执行情况，所以有可能会阻塞主线程。

**惰性删除**：异步删除

开启lazt-free之后，释放一个key的内存时会先评估代价，如果代价很小，就直接在主线程中操作了

什么时候异步释放内存？
- 当Hash/Set底层采用哈希表存储时，并且元素数量超过64个
- 当Zset底层采用跳表存储时，且元素数量超过64个
- 当List链表节点数量超过64个(不是元素数量，而是链表节点的数量)


# CPU架构对Redis的影响

![Iaoxt0](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/Iaoxt0.png)

![ykbLBx](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/ykbLBx.png)

- L1、L2缓存中的指令和数据的访问速度很快，所以充分利用L1、L2缓存可以有效缩短应用程序的执行时间
- 在NUMA架构下，如果应用程序从一个Socket上调度到另一个Socket上，就可能会出现远端内存访问的情况，从而直接增加应用程序的执行时间。

运行时消息：应用程序自身使用的软硬件资源信息(如栈指针、CPU核的寄存器值等)

如果在CPU多核的情况下，Redis实例被频繁调度到不同CPU核上运行的话，每调度一次，一些请求就会受到运行时信息、指令和数据重新加载过程的影响，从而导致某些请求的延迟明显高于其他请求。

解决方案：将Redis实例绑定到一个固定的核上运行
```shell
taskset -c 0 ./redis-server
```

如果网络中断处理程序和Redis实例各自所绑定的CPU核不在同一个CPU Socket上，那么Redis实例读取网络数据时，就需要跨CPU Socket访问内存，这个过程会花费较多时间。

## 绑核的风险

风险：子进程、后台线程和Redis主线程竞争CPU资源，一旦子线程或后台线程占用CPU，主线程就会被阻塞，导致Redis请求延迟增加。

解决方案
1. 一个Redis实例对于绑一个物理核，而不是绑逻辑核
	`taskset -c 0,12 ./redis-server`

2. 优化Redis源码
	通过修改Redis源码，让子进程和后台线程绑定到不同的CPU核上。


- cpu_set_t 数据结构：是一个位图，每一位用来表示服务器上的一个 CPU 逻辑核。
- CPU_ZERO 函数：以 cpu_set_t 结构的位图为输入参数，把位图中所有的位设置为 0。
- CPU_SET 函数：以 CPU 逻辑核编号和 cpu_set_t 位图为参数，把位图中和输入的逻辑核编号对应的位设置为 1。
- sched_setaffinity 函数：以进程 / 线程 ID 号和 cpu_set_t 为参数，检查 cpu_set_t 中哪一位为 1，就把输入的 ID 号所代表的进程 / 线程绑在对应的逻辑核上。

如何进行绑核？
1. 创建一个 cpu_set_t 结构的位图变量；
2. 使用 CPU_ZERO 函数，把 cpu_set_t 结构的位图所有的位都设置为 0；
3. 3.根据要绑定的逻辑核编号，使用 CPU_SET 函数，把 cpu_set_t 结构的位图相应位设置为 1；
4. 使用 sched_setaffinity 函数，把程序绑定在 cpu_set_t 结构位图中为 1 的逻辑核上。

```C++
//线程函数
void worker(int bind_cpu){
    cpu_set_t cpuset;  //创建位图变量
    CPU_ZERO(&cpu_set); //位图变量所有位设置0
    CPU_SET(bind_cpu, &cpuset); //根据输入的bind_cpu编号，把位图对应为设置为1
    sched_setaffinity(0, sizeof(cpuset), &cpuset); //把程序绑定在cpu_set_t结构位图中为1的逻辑核

    //实际线程函数工作
}

int main(){
    pthread_t pthread1
    //把创建的pthread1绑在编号为3的逻辑核上
    pthread_create(&pthread1, NULL, (void *)worker, 3);
}
```

```C++
int main(){
   //用fork创建一个子进程
   pid_t p = fork();
   if(p < 0){
      printf(" fork error\n");
   }
   //子进程代码部分
   else if(!p){
      cpu_set_t cpuset;  //创建位图变量
      CPU_ZERO(&cpu_set); //位图变量所有位设置0
      CPU_SET(3, &cpuset); //把位图的第3位设置为1
      sched_setaffinity(0, sizeof(cpuset), &cpuset);  //把程序绑定在3号逻辑核
      //实际子进程工作
      exit(0);
   }
   ...
}
```

# 响应延迟

如何判断Redis是否变慢了？
- 查看Redis的响应延迟
- 基于当前环境下的Redis基线性能来判断

基线性能：系统在低压力下、无干扰下的基本性能

`./redis-cli --intrinsic-latency 120`

## 如何应对Redis变慢

Redis变慢可能的因素
- 使用复杂度过高的命令或一次查询全量数据
- 操作bigkey
- 大量key集中过期
- 内存达到maxmemory
- 客户端使用短连接与Redis相连
- 当Redis实例的数据量大时，无论是生成RDB，还是AOF重写，都会导致fork耗时严重
- AOF的写回策略为always，导致每个操作都要同步刷回磁盘
- Redis实例运行机器的内存不足，导致swap发生，Redis需要到swap分区读取数据
- 进程绑定CPU不合理
- Redis实例运行机器上开启了透明内存大页机制
- 网卡压力过大

### Redis自身操作特性的影响

#### 慢查询指令

排查方法：
- Redis日志
- latency monitor工具

解决方案：
- 用其他高效的命令代替
- 当执行排序、交集、并集操作时，在客户端完成，而不要使用SORT、SUNION、SINTER，以免拖慢Redis实例
- 减少KEYS的使用，用于返回和输入模式匹配的所有key，但是因为需要遍历存储的键值对，所以操作延时高

#### 过期key操作

Redis每100毫秒会删除一些过期的Key
- 采样ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP个数的key，并将其中过期的key全部删除
- 如果超过25%的key过期了，则重复删除的过程，直到过期key的比例降至25%以下

ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP默认是20

如果触发了第二条，Redis就会一直删除释放空间，==删除操作是阻塞的==，所以一旦该条件触发，就会影响其他键值的操作，进一步引起其他键值操作的延迟。

==如何触发第二条？==
频繁使用带有相同时间参数的EXPIREAT命令设置过期key，从而导致同一秒内有大量的key同时过期。

检查方案：检查业务代码在使用EXPIREAT命令设置key过期时间时，是否使用了相同的UNIX时间戳，有没有使用EXPIRE命令给批量的key设置相同的过期秒数

解决方案：如果一批key是同时过期，可以在EXPIREAT和EXPIREAT的过期时间参数上加上一个一定大小范围的随机数，这样就既保证了key在一个邻近时间范围内被删除，又避免了同时过期造成的压力。

#### KEYS返回与输入模式匹配的keys，但是复杂度很高，容易引起Redis线程操作阻塞，有哪些命令可以替代？

可以使用SCAN，通过`SCAN $cursor COUNT $count`可以得到一批key以及下一个游标`$cursor`，然后把这个`$cursor`当作SCAN的参数，再次执行，直到返回的`$cursor`为0，就把整个实例中的所有key遍历出来了。

在Redis做Rehash的时候使用SCAN不会漏key，但是可能会得到重复的key

1. 为什么不会漏key？Redis在SCAN遍历全局哈希表时，采用*高位进位法*的方式遍历哈希桶（可网上查询图例，一看就明白），当哈希表扩容后，通过这种算法遍历，旧哈希表中的数据映射到新哈希表，依旧会保留原来的先后顺序，这样就可以保证遍历时不会遗漏也不会重复。 

2.  为什么SCAN会得到重复的key？这个情况主要发生在哈希表缩容。已经遍历过的哈希桶在缩容时，会映射到新哈希表没有遍历到的位置，所以继续遍历就会对同一个key返回多次。

SCAN是遍历整个实例的所有key，另外Redis针对Hash/Set/Sorted Set也提供了HSCAN/SSCAN/ZSCAN命令，用于遍历一个key中的所有元素，建议在获取一个bigkey的所有数据时使用，避免发生阻塞风险。 但是使用HSCAN/SSCAN/ZSCAN命令，返回的元素数量与执行SCAN逻辑可能不同。执行SCAN $cursor COUNT $count时一次最多返回count个数的key，数量不会超过count。 但Hash/Set/Sorted Set元素数量比较少时，底层会采用intset/ziplist方式存储，如果以这种方式存储，在执行HSCAN/SSCAN/ZSCAN命令时，会无视count参数，直接把所有元素一次性返回，也就是说，得到的元素数量是会大于count参数的。当底层转为哈希表或跳表存储时，才会真正使用发count参数，最多返回count个元素。

#### 文件系统：AOF模式

![bqkWQw](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/bqkWQw.png)

write只要将日志记录到内核缓冲区就可以返回了，并不需要等待日志实际写回到磁盘
fsync需要把日志记录写回到磁盘后才能返回，时间较长

everysec允许丢失一秒的操作记录，所以Redis主线程并不需要确保每个操作记录日志都写回磁盘，并且fsync的执行时间很长，如果是在Redis主线程中执行fsync就容易阻塞主线程，所以everysec会使用后台的子线程异步完成fsync

always需要确保每个操作记录日志都写回磁盘，如果用后台子线程异步完成，主线程就无法及时知道每个操作是否完成，所以always并不使用后台子线程来执行。

AOF重写本身需要的时间很长，也容易阻塞Redis主线程，所以Redis使用子进程来进行AOF重写

==风险==：AOF重写会对磁盘进行大量IO操作，而fsync有需要等到数据写到磁盘后才能返回，所以AOF重写的压力比较大，就会导致fsync被阻塞。fsync虽然是由后台子线程负责完成的，但是主线程也会监控fsync的执行速度

如果主线程发现上一次的fsync还没有执行完，那么它就会阻塞，所以后台子线程执行的fsync频繁阻塞的话(比如AOF重写占用了大量的磁盘IO带宽)，主线程也会阻塞，导致Redis性能变慢

如果业务应用对于延迟非常敏感，但是同时允许一定量的数据丢失，可以设置为
`no-appendfsync-on-rewrite yes`
在AOF重写时不尽兴fsync操作，即Redis实例把写命令写到内存后，不调用后台线程进行fsync操作就可以直接返回了。

#### 操作系统：swap

操作系统为了缓解内存不足对应用程序的影响，允许把一部分的数据换到磁盘上，以达到应用程序对内存使用的缓冲，这些内存数据被换到磁盘上的区域就是Swap，但是当内存总的数据被换到磁盘上后，Redis再访问这些数据时，就需要从磁盘上读取，访问磁盘的而速度要比访问内存慢几百倍。

与AOF日志文件读写使用的fsync线程不同，swap触发后影响的是Redis主IO线程，这会极大增加Redis响应时间。

触发Swap的原因
- Redis实例自身使用了大量的内存，导致屋里机器的可用内存不足
- 和Redis实例在同一台机器上运行的其他线程在进行大量的文件读写操作，文件读写本身会占用系统内存，这会导致分配给Redis实例的内存量变少，进而触发Redis发生Swap

解决方案：
- 增加机器的内存
- 使用Redis集群

当出现百MB甚至GB级别的swap大小的时候，就表明此时Redis实例的内存压力很大，很有可能会变慢。

#### 操作系统：内存大页

内存大页机制，该机制支持2MB大小的内存页分配

内存大页在分配相同的内存量的时候可以减少分配的次数，但是在持久化保存的过程中，Redis使用写时复制，如果使用了内存大页，即使客户端只修改100B的数据，Redis也要拷贝2MB的大页，相反，如果是常规内存页机制，只用拷贝4KB，所以内存大页机制会导致大量的拷贝，这就会影响Redis正常的访存操作，最终导致性能变慢。

关闭内存大页机制
`echo never /sys/kernal/mm/transparent_hugepage/enabled`


## Redis存储效率

**在Redis删除数据之后，为什么还会占用很多的内存？**
当数据删除之后，Redis释放的内存空间会由内存分配器管理，并不会立即返回给操作系统。
风险：是否的内存空间不是连续的，那这些内存空间可能就会处于一种闲置的状态，从而无法利用这些空闲空间来保存市局，减少Redis能够实际保存的数据量，进而降低Redis运行机器的成本回报率。

![[动态内存分配#碎片|碎片]]
碎片形成的原因
1. 内因：内存分配器的分配策略
	分配器是按照一系列固定的大小来分配内存空间的，从而减少分配的次数

2. 外因：键值对大小不一样和删改操作
	- 不同大小的键值对，分配内存时会大一些，这就会产生内部碎片
	- 键值对修改和删除会导致空间的扩容和释放，从而产生外部碎片

## 如何判断是否有内存碎片

```shell
INFO memory
# Memory
used_memory:1073741736
used_memory_human:1024.00M
used_memory_rss:1997159792
used_memory_rss_human:1.86G
…
mem_fragmentation_ratio:1.86
```

> [!faq] 如果mem_fragmentation_ratio小于1会对Redis性能和空间利用率造成什么影响
> 如果小于1了，说明操作系统分配给Redis进程的物理内存姚晓玉Redis实际存储数据的内存，这就会导致Redis的一部分数据会被换到Swap中，之后当Redis访问Swap中的数据时，延迟会变大，性能下降。

## 如何清理内存碎片
1. 重启
	- 如果数据没有持久化，数据就会丢失
	- 即使持久化了也要进行恢复，如果只有一个实例，恢复阶段就无法提供服务。

2. 搬家让位，合并空间
	- Redis是单线程的，在数据靠别时，Redis只能等着，导致Redis无法及时处理请求，性能降低
	- 有时拷贝数据需要注意顺序，这就进一步增加Redis的等待时间，导致性能降低

如何解决拷贝时性能的降低？
使用参数控制碎片清理开始与结束的时间，以及占用CPU的比例，从而减少碎片清理对Redis本身请求处理的性能影响
- `config set activedefrag yes`  自动进行内存碎片清理
- `active-defrag-ignore-bytes 100mb` 内存碎片的字节数打到100MB时开始清理
- `active-defrag-threshold-lower 10` 内存碎片空间占操作系统分配给Redis的总空间比例达到10%时，开始清理
- `active-defrag-cycle-min 25` 自动清理过程所用CPU时间的比例不低于25%，保证清理能正常开展
- `active-defrag-cycle-max 75` 自动清理过程所用CPU时间的比例不高于75%，一旦超过，就停止清理，从而避免在清理时大量的内存拷贝阻塞Redis，导致响应延迟升高

# 缓冲区

缓冲区：用来暂时存放命令数据的一块内存空间，防止出现数据和命令的处理速度慢于发送速度而导致的数据丢失和性能问题

服务器端为每一个连接的客户端都设置了一个输入缓冲区和输出缓冲区

![[Pasted image 20220818172218.png]]
==导致输入缓冲区溢出的情况==：
- 写入了bigkey，例如一下写入了百万级别的集合类型数据
- 服务器端处理请求的速度过慢，例如Redis主线程出现了间歇性阻塞，无法及时处理正常发送的请求，导致客户端发送的请求在缓冲区越积越多

查看每个客户端输入缓冲区的使用情况 `CLIENT LIST`

缓冲区溢出之后，Redis就会把客户端连接关闭，从而导致业务程序无法进行数据存取

当多个客户端连接占用的内存总量查过maxmemory，就会触发Redis进行数据淘汰
如果多个客户端导致Redis内存占用过大，也会导致内存溢出，进而引起Redis崩溃

## 如何避免输入缓冲区溢出
1. 把缓冲区调大，这个阈值无法进行设定，默认是1G
	- 这个大小对于绝大部分的客户端请求够用了
	- 如果继续往大的话，Redis可能会因为客户端占用了过多的内存而崩溃

2. 避免客户端写入bigkey，以及避免Redis主线程的阻塞

## 如何避免输出缓冲区溢出

输出缓冲区
- 大小为16KB的固定缓冲空间，用来暂存OK响应和出错信息
- 可以动态增加的缓冲空间，用来暂存大小可变的响应结果

输出缓冲区发生溢出的情况
- 服务器端返回bigkey的大量结果
- 执行MONITOR命令
- 缓冲区大小设置得不合理

MONITOR：检查Redis的执行，它的输出结果会持续占用输出缓冲区，并越占越多，最后就会发生溢出

将MONITOR用在调试环境中，在线上环境中不要持续使用MONITOR

输出缓冲区可以通过`client-output-buffer-limit`来设置
- 设置缓冲区大小的上限阈值
- 设置输出缓冲区持续写入数据的数量上限阈值，和持续写入数据的时间的上限阈值

与Redis服务器端交换的客户端
- 常规和Redis服务器端进行读写命令交互的**普通客户端**
- 订阅了Redis频道的**订阅客户端**

普通客户端每发完一个请求就会等到请求结果返回，再发送下一个请求，即==阻塞式发送==，如果不是读取体量特别大的bigkey，服务器端的输出缓冲区一般不会被阻塞

订阅客户端一旦订阅的Redis频道有消息了，服务器端就会通过输出缓冲区把消息发给客户端，所以==不属于阻塞式发送==，但是如果频道消息较多的话，也会占用较多的输出缓冲区空间。

## 主从集群中的缓冲区

### 复制缓冲区

主从库上的输出缓冲区是不计算在Redis使用的总内存中的，即主从同步延迟、数据积压在主库上的从库输出缓冲区中，这个缓冲区内存占用变大，不会超过maxmemory导致淘汰数据。

在==全量复制==的过程中，主节点在向从节点传输RDB文件的同时，会继续接收客户端发送的写命令，这些写命令会先保存在复制缓冲区中，等RDB文件传输完成，再发送给从节点去执行。主节点会为每个从节点都维护一个复制缓冲区，来保证主从节点间的数据同步。

复制缓冲区一旦溢出，主节点就会直接关闭和从节点进行复制操作的连接，导致全量复制的失败。

==如何避免复制缓冲区的溢出？==
- 控制主节点保存的数据量大小
- 使用`client-output-buffer-limit`来设置合理的复制缓冲区大小，根据主节点数据量大小、主节点的写负载压力和主节点本身的内存大小来设置

要控制主节点连接的从节点个数，避免主节点中复制缓冲区占用过多内存

### 复制积压缓冲区

[[redis#^fs8pq4|复制积压缓冲区]]：==增量复制==时使用的缓冲区
主节点在把接收到的写命令同步给从节点，同时会把这些写命令写入复制积压缓冲区，一旦从节点发生网络闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区中，读取断连期间主节点接收到的命令，进行增量同步。

## 客户端使用缓冲区的好处

1. 客户端和服务端交互，一般都会制定一个交互协议，客户端给服务端发数据时，都会按照这个协议把数据拼装好，然后写到客户端buffer中，客户端再一次性把buffer数据写到操作系统的网络缓冲区中，最后由操作系统发送给服务端。这样服务端就能从网络缓冲区中读取到一整块数据，然后按照协议解析数据即可。使用buffer发送数据会比一个个发送数据到服务端效率要高很多。 

2. 客户端还可以使用Pipeline批量发送命令到服务端，以提高访问性能。不使用Pipeline时，客户端是发送一个命令、读取一次结果。而使用Pipeline时，客户端先把一批命令暂存到buffer中，然后一次性把buffer中的命令发送到服务端，服务端处理多个命令后批量返回结果，这样做的好处是可以减少来回网络IO的次数，降低延迟，提高访问性能。当然，Redis服务端的buffer内存也会相应增长，可以控制好Pipeline命令的数量防止buffer超限。 ^wj93a4

3. 在客户端可以控制发送速率，避免把过多的请求一下子全部发到Redis实例，导致实例因压力过大而性能下降

4. 在应用Redis主从集群时，主从节点进行故障切换是需要一定时间的，此时主节点无法服务外来请求，如果客户端有缓冲区暂存请求，那么客户端仍然可以正常接收业务应用的请求，从而避免直接给应用返回无法服务的错误

==使用Redis自带的-bigkeys排查bigkey的不足==
- 只能返回每种类型中最大的那个bigkey，无法得到大小排在前N位的bigkey
- 对于集合类型，这个方法只统计集合元素个数的多少，而不是实际占用的内存量。但是一个集合中的元素个数多，并不一定占用的内存就多。


# 旁路缓存

- Redis缓存具体是怎么工作的？
- Redis缓存如果满了，该怎么办？
- 为什么会有缓存一致性、缓存穿透、缓存雪崩、缓存击穿等异常，该如何应对？
- Redis内存有限，如何用快速的固态硬盘来保存数据，可以增加缓存的数据量，那么Redis缓存可以使用快速固态硬盘吗？

计算机中的两种缓存
- CPU里面的末级缓存，即LLC，用来缓存内存中的数据，避免每次从内存中存取数据
- 内存中的高速页缓存，即page cache，用来缓存磁盘中的数据，避免每次从磁盘中存取数据

缓存的特征
- 在一个层次化的系统中，缓存是一个快速子系统，数据存在缓存中时，能避免每次从慢速子系统中存取数据
- 缓存系统的容量大小总是小于后端慢速系统的，不可能把所有数据都放在缓存系统中

缓存请求的两种情况
- 缓存命中
- 缓存缺失

为什么Redis是[[高并发设计#旁路策略|旁路缓存]]？
因为读取缓存、读取数据库和更新缓存的操作都需要在应用程序中完成

如何使用Redis缓存？
- 当应用程序需要读取数据时，需要在代码中显式调用Redis的GET操作接口，进行查询
- 如果缓存缺失了，应用程序需要再和数据库连接，从数据库中读取数据
- 当缓存中的数据需要更新时，也需要在应用程序中显式地调用SET操作接口，把更新的数据写入缓存

使用Redis缓存需要注意的地方
- 因为需要新增程序代码来使用缓存，所以不适用于那些无法获得源码的应用

## 缓存类型

### 只读缓存

所有的写请求会直接发往后端的数据库，在数据库中增删查改，对于删改的数据，如果Redis中已经缓存了相应的数据，应用需要把这些缓存的数据删除

- [x] 高并发系统设计40讲 -> Redis旁路缓存

对于只读缓存来说，没有更新操作，==只有读取和删除操作==，在数据更新时，只会写数据库，然后对于缓存来讲，更新操作分解为删除和插入操作。

好处：所有最新的数据都在数据库中，而数据库是提供数据可靠性保障的，这些数据不会有丢失的风险。

### 读写缓存

所有的写请求也会发送到缓存，在缓存中直接对数据进行增删查改，这样就可以提升业务应用的响应速度。

==缺点==：最新的数据是在Redis中，而Redis是内存数据库，一旦出现掉电或宕机，内存中的数据就会丢失

[[高并发设计#Write Back|写回策略]]
- 同步直写，优先保证数据可靠性
	- 写请求发给缓存的同时，也会发给后端数据库进行处理，等到缓存和数据库都写完数据，才会返回给客户端，适用于冷热分区
- 异步写回，优先提供快速响应
	- 所有写请求都先在缓存中处理，等到这些增改的数据要被从缓存中==淘汰时，缓存将它们写回后端数据库==，适用于高频写

## Redis的只读缓存和使用直写缓存把数据同步到后端数据库的区别

1. 使用只读缓存时，是先把修改写到后端数据库中，再把缓存中的数据删除。当下次访问这个数据时，会以后端数据库中的值为准，重新加载到缓存中。这样做的==优点==是，数据库和缓存可以保证完全一致，并且缓存中永远保留的是经常访问的热点数据。==缺点==是每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失，然后从后端数据库加载数据到缓存中，这个过程访问延迟会变大。

2. 使用读写缓存时，是同时修改数据库和缓存中的值。这样做的==优点==是，被修改后的数据永远在缓存中存在，下次访问时，能够直接命中缓存，不用再从后端数据库中查询，这个过程拥有比较好的性能，比较适合先修改又立即访问的业务场景。但==缺点==是在高并发场景下，如果存在多个操作同时修改同一个值的情况，可能会导致缓存和数据库的不一致。 

3. 当使用只读缓存时，如果修改数据库失败了，那么缓存中的数据也不会被删除，此时数据库和缓存中的数据依旧保持一致。而使用读写缓存时，如果是先修改缓存，后修改数据库，如果缓存修改成功，而数据库修改失败了，那么此时数据库和缓存数据就不一致了。如果先修改数据库，再修改缓存，也会产生上面所说的并发场景下的不一致。


# 替换策略

- 不进行数据淘汰的
	- noeviction
- 进行数据淘汰的
	- 在设置了过期时间的数据中进行淘汰
		- volatile-random，在设置了过期时间的键值对中进行随机删除
		- volatile-ttl，针对过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除
		- volatile-lru，使用LRU算法筛选设置了过期时间的键值对
		- volatile-lfu，使用LFU算法选择设置了过期时间的键值对
	- 在所有数据范围内进行淘汰，如果一个键值对被删除策略选中了，即使过期时间还没到，也要被删除，如果过期时间到了但未被选中，也会被删除
		- allkeys-random，从所有键值对中随机选择并删除数据
		- allkeys-lru，使用LRU算法在所有数据中进行筛选
		- allkeys-lfu，使用LFU算法在所有数据中进行筛选

Redis在使用的内存空间超过maxmemory时，默认使用noeviction策略

LRU因为使用链表会带来额外的空间开销，并且数据被访问是需要移动，如果有大量的数据进行移动就会很耗时，从而降低了Redis的性能。
 
LRU的简化：
- Redis会默认记录每个数据最近一次访问的时间戳，然后在淘汰数据时，第一次随机选出N个数据，然后比较这N个数据的lru字段，把lru字段值最小的数据从缓存中淘汰出去。
- 再次进行淘汰时，Redis需要挑选数据进入第一次淘汰时创建的候选集合，挑选的标准是能进入候选集合的数据的lru字段值必须小于候选集合中最小的lru值，然后激昂候选数据集中lru字段最小的数据淘汰出去
- 候选集的作用是先把符合条件的数据准备好，候选集的实现是一个链表，数据是按照lru值进行排序的


1. 优先使用 allkeys-lru 策略。这样，可以充分利用 LRU 这一经典缓存算法的优势，把最近最常访问的数据留在缓存中，提升应用的访问性能。
2. 如果你的业务数据中有明显的冷热数据区分，我建议你使用 allkeys-lru 策略。
3. 如果业务应用中的数据访问频率相差不大，没有明显的冷热数据区分，建议使用 allkeys-random 策略，随机选择淘汰的数据就行。如果你的业务中有置顶的需求，比如置顶新闻、置顶视频，那么，可以使用 volatile-lru 策略，同时不给这些置顶数据设置过期时间。这样一来，这些需要置顶的数据一直不会被删除，而其他数据会在过期时根据 LRU 规则进行筛选。

Redis淘汰了数据之后会把它们删除，即使淘汰的是脏数据，所以在使用Redis缓存时，如果数据被修改了，需要在数据修改时就将它写回数据库。


# 缓存异常

- 缓存中的数据和数据库中的不一致
- 缓存雪崩
- 缓存击穿
- 缓存穿透

## 数据的的不一致

一致性
- 缓存中有数据，那么，缓存的数据值需要和数据库中的值相同
- 缓存中本身没有数据，那么，数据库中的值必须是最新值

如何保证数据的一致性？
把要删除的缓存值或者是要更新的数据库值暂存到消息队列中，当应用没有能够成功地删除暂存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新，如果成功的话，就从消息队列中去除这些值，以免重复操作，否则重试超过一定的次数的话就向业务层发送报错信息。

==更新数据库和删除缓存值的过程中即使两个操作第一次执行时都没有失败，当有大量并发请求时，应用还是有可能读到不一致的数据。==(如果使用原子操作呢?)

1. 先删除缓存，再更新数据库
	
	另外一个线程可能将已经删除了缓存但还没有来得及更新数据库的旧值重新读取到缓存中
	
	解决方案：
	更新完数据库之后，让更新线程sleep一小段时间，再进行一次缓存删除操作，即延迟双删

在读写缓存中，如果遇到写写并发可能会出现缓存与数据库中的数据不一致的情况，可以配合分布式锁的使用，保证缓存和数据库中数据的一致性

## 缓存雪崩

大量的应用请求无法在Redis缓存中进行处理，紧接着应用将大量请求发送到数据库层，导致数据库层的压力激增。

==导致缓存雪崩的原因==
1. 缓存中有大量数据同时过期，导致大量请求无法得到处理
	解决方案
	- 使用EXPIRE给每个数据设置过期时间时，增加一个较小的随机数
	- 服务降级
		- 当业务应用访问的是非核心数据时，暂时停止从缓存中查询这些数据，而是直接放回预定义信息、空值或是错误信息
		- 当业务应用访问的是核心数据时，仍然运行查询缓存，如果缓存缺失，也可以继续通过数据库请求

2. Redis缓存实例发生故障宕机了，导致大量请求一下子积压到数据层，从而发生缓存雪崩
	解决方案：
	- 在业务系统中实现服务熔断或请求限流机制
		- 服务熔断指在发生缓存雪崩时，为了防止引发连锁的数据库雪崩，甚至是整个系统的崩溃，暂停业务应用对缓存系统的接口访问。
		- 请求限流是在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库
	- 事前预防
		- 通过主从节点的方式构建Redis缓存高可靠集群，如果主节点发生故障宕机了，从节点可以切换成主节点继续提供缓存服务。

如何检测雪崩？
缓存所在的机器负责空闲或宕机的情况下，数据库机器负载激增。

## 缓存击穿

针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。

缓存击穿经常发生在热点数据过期失效时。

解决方案：对于访问特别频繁的热点数据，不设置过期时间

## 缓存穿透

要访问的数据既不在Redis缓存中，也不在数据库中，导致请求在访问换成时发生换成缺失，再去访问数据库时，发现数据库中也没有要访问的数据。

缓存穿透发生的情况
- 业务层误操作：缓存中的数据和数据库中的数据被误删除了
- 恶意攻击，专门访问数据库中没有的数据

解决方案：
- 缓存空值或者缺省值
- 使用==布隆过滤器==快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力
- 在请求入口的前端进行请求检测


# 缓存被污染

有些数据被访问的次数非常少，甚至只会被访问一次，当这些数据服务完访问请求之后，如果还继续留在缓存中的话，就会白白占用缓存空间。

LRU在处理扫描式单次查询操作时，无法解决缓存污染，因为这些被查询的数据刚刚被访问过，所以lru字段值都很大。

LFU从两个维度来筛选并淘汰数据
- 数据访问的时效性
- 数据的被访问次数

## LFU缓存策略的优化

与被频繁访问的数据相比，扫描式单次查询的数据因为不会被再次访问，所以它们的访问次数不会再增加，因此LFU会优先把这些访问次数低的数据淘汰出缓存，这样可以避免这些数据对缓存造成的污染了

将原来24bit大小的lru字段，进一步拆分成两部分
- ldt值：lru字段的前16bit，表示数据的访问时间戳
- counter值：lru字段的后8bit，表示数据的访问次数

counter最大只能表示255，如何进行较大的访问次数的计数？
每当数据被访问一次时，首先用计数器当前的值乘以配置项`lfu_log_factor`再加一，然后取其倒数，得到一个p值，然后把这个p值和一个取值范围在(0, 1)间的随机数r值比大小，只有p值大于r值的时候，计数器才加1

计数器的初始值默认是5，这样就可以避免数据刚被写入缓存，就因为访问次数少而被立即淘汰。(==那这大家都是5的话，不还是最小的吗==)

**counter值的衰减**：为了防止有些数据在短时间内被大量访问后就不再被访问了，但按访问次数来筛选的话，这些数据还会被留存在缓存中，不会提升缓存命中率
计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位，然后LFU策略再把这个差值除以`lfu_decay_time`，所得的结果就是数据counter要衰减的值


# 大容量Redis

大容量实例的缺点：在实例恢复、主从同步过程中会引起一系列潜在问题、例如恢复时间增长、主从切换开销大、缓冲区易溢出

**内存快照RDB生成和恢复效率低**
实例内存容量大，RDB文件也会相应增大，那么RDB文件生成时的fork时长就会增加，从而导致Redis实例阻塞，并且RDB文件增大后，使用RDB文件进行恢复的时长也会增加，导致Redis较长时间无法对外提供服务。

**主从同步**
主从同步第一步是全量同步，全量同步是RDB文件传送，如果RDB文件很大，会导致同步时间增加，并且还可能导致复制缓冲区溢出，一旦溢出了就要重新开始全量同步。
如果主库发生了故障，进行主从切换，其他库都要和新主库进行一次全量同步，如果RDB文件很大，会导致主从切换的时间增加，从而会影响业务的可用性


# 无锁的原子操作

临界区代码：访问同一份数据的RWM操作代码

## 把多个操作在Redis中实现为一个操作，也就是单命令操作

INCR/DECR 将读数据、数据增减、写回数据原子性的执行

## 把多个操作写到一个Lua脚本中，以原子性方式执行单个脚本

Redis会把整个Lua脚本作为一个整体执行，在执行过程中不会被打断，从而保证了Lua脚本中操作的原子性，但是会导致执行脚本的时间增加，同样会降低Redis的并发性能。


# 分布式锁

分布式锁：保存在一个共享存储系统中，可以被多个客户端共享访问和获取

分布式锁的要求
- 分布式锁的加锁和释放锁的过程涉及多个操作，所以实现分布式锁时，需要保证这些锁操作的原子性
- 共享存储系统保存了锁变量，如果共享存储系统发生故障或宕机，那么客户端也就无法进行锁操作了，所以在实现分布式锁时，需要考虑共享存储系统的可靠性，进而保证锁的可靠性

## 基于单个Redis节点实现分布式锁

Redis使用单线程处理请求，所以即使多个客户端同时发送加锁请求给Redis，Redis也会串行处理它们的请求

使用SETNX和DEL命令组合实现加锁和释放锁的操作。
SETNX：对于不存在的键值对，先创建再设置值

存在的两个风险
1. 如果某个客户端加锁之后，在操作共享数据时发生了异常，从而一直没有释放锁，这样其他客户端就一直无法拿到锁了
	解决方案：给锁设置一个过期时间

2. 一个客户端加锁之后可能会被另一个客户端误释放
	解决方案：每个客户端给锁变量设置一个唯一的值
	SET：只在键值对不存在时才会进行设置，否则不做赋值操作
	SET在执行时可以带上EX或PX，用来设置键值对的过期时间

## 基于多个Redis节点的分布式锁

Redlock: 客户端和多个独立的Redis实例依次请求加锁，如果可以和半数以上的实例成功的完成加锁操作，就可以认为获得了分布式锁

步骤
- 客户端获取当前时间
- 客户端按顺序依次向N个Redis实例执行加锁操作
- 一旦客户端完成了和所有的Redis实例的加锁操作，客户端就要计算整个加锁过程的总耗时

加锁成功的条件
- 从超过半数的Redis实例上成功获取到锁
- 获取锁的总耗时没有超过锁的有效时间

在满足这两个条件之后，需要重新计算锁的有效时间，计算的结果是锁的最初有效时间减去客户端为获取锁的总耗时，如果锁的有效时间已经来不及完成其他共享数据的操作了，就可以释放锁，以免出现还没完成数据操作，锁就过期了
如果没有同时满足这两个条件，那么客户端向所有Redis节点发起释放锁的操作


# 事务机制

## Redis事务的实现

1. 客户端使用MULTI显式的开启一个事务
2. 客户端把事务中本身要执行的具体操作发送给服务器端，Redis实例将这写些命令暂存到一个命令队列
3. 客户端向服务端发送EXEC，即提交事务的命令

## 原子性

- 在执行EXEC命令前，客户端发送的操作命令本身有错误，在命令入队时Redis就会报错并记录下来，此时还能继续提交命令，等到执行了EXEC命令之后，Redis就会拒绝执行所以提交的命令。返回事务失败的结果。
- 事务入队时，命令和操作的数据类型不匹配，但Redis实例没有检查出错误，但是在执行完EXEC命令之后，Redis实例执行这些事务操作时，就会报错，但是还会把正确的命令执行完，在这种情况下，事务的原子性就无法得到保证了。
- 在执行事务的EXEC命令时，Redis实例发生了故障，导致事务执行失败。如果开启了AOF日志，那么只会有部分的事务操作被记录到AOF日志中，可以使用redis-check-aof把未完成的事务操作从AOF文件中去除。

Redis没有提供回滚操作，DISCARD只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。

## 一致性

- 命令入队时就报错，事务本身会放弃执行所以可以保证一致性
- 命令入队时没有报错，有错误的命令不会被执行，正确的命令可以正常执行，不会改变数据库的一致性
- EXEC命令执行时实例发生故障
	- 如果没有开启RDB或AOF，实例故障之后数据都没有了，数据库是一致的
	- 如果使用了RDB快照，RDB快照不会在事务执行时执行，所以事务的命令也不会被保存到RDB快照中，使用RDB快照进行恢复时，数据库里的数据也是一致的
	- 如果使用了AOF日志，但事务操作还没有记录到AOF日志时，实例就发生了故障，那么AOF日志恢复的数据库数据是一致的。如果只记录了一部分操作到AOF日志中，可以使用redis-check-aof清除事务中已完成的操作，数据库恢复后也是一致的。

## 隔离性

- 并发操作在EXEC命令前执行，此时隔离性的保证要使用WATCH机制来实现，否则隔离性无法保证
- 并发操作在EXEC命令后执行，此时隔离性可以保证
	- 因为Redis是单线程的，而且EXEC命令执行后，Redis会保证先把命令队列中所有的命令执行完。

WATCH：在事务执行前，监控一个或多个键的值变化情况，当事务调用EXEC命令执行时，WATCH机制会先检查监控键是否被其他客户端修改了，如果修改了，就放弃事务的执行，避免事务的隔离性被破坏。然后客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作，事务就能正常执行，隔离性也得到了保证。

## 持久性

Redis不管采用什么持久化模式，事务的持久性属性都得不到保证


