- undo log：是InnoDB存储引擎生成的日志，实现了事务中的原子性，主要用于事务回滚和MVCC
- redo log：是InnoDB存储引擎生成的日志，实现了事务的持久性，主要用于掉电等故障恢复
- binlog：是Server层生成的日志，主要用于数据备份和主从复制

## undo log

一条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 的事务 id：
- 通过 trx_id 可以知道该记录是被哪一个事务修改的
- 通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为版本链

undo log的作用：
- 实现事务回滚，保障事务的原子性。事务处理过程中，如果出现了错误或者用户执行了 ROLLBACK 语句，MySQL可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态
- 实现MVCC的关键因素之一：MVCC是通过 ReadView + undo log 实现的，undo log 为每一条记录保存多份历史数据，MySQL在执行快照读(普通select)的时候，会根据事务的 ReadView 里的信息，顺着 undo log 的版本找到满足其可见性的记录

> undo log 如何刷盘？
> undo log 和数据页的刷盘策略一样，都需要通过 redo log 保证持久化
> buffer pool 中有 undo 页，对 undo 页的修改也都会记录到 redo log，redo log 会每秒刷盘，提交事务时也会刷盘，数据页和 undo 页都是靠这个机制保证持久化的。

## Buffer Pool

Buffer Pool会缓存索引页、数据页、Undo 页、插入缓存、自适应哈希索引、锁信息

## redo log

当更新数据的时候，InnoDB会先更新内存，并将相应的页设置为脏页，然后将本次对这个页的修改以 redo log 的形式记录下来，这时候才算更新完成了，之后 InnoDB引擎会由后台线程将缓存在 Buffer Pool的脏页刷到磁盘里，即WAL

**redo log 与 undo log 的区别**
- redo log 记录了此次事务完成后的数据状态，记录的是更新后的值
- undo log 记录了此次事务开始前的数据状态，记录的是更新之前的值

redo log 的作用：
- 实现了事务的持久性
- 将写操作的顺序有随机写变为了顺序写，提升了MySQL写入磁盘的性能，因为 redo log 是由追加的方式写入的

redo log并不是直接写入磁盘，而是先写入到 redo log buffer，然后再写入到磁盘。因为如果直接写入磁盘的话，会产生大量的IO操作，而且磁盘的运行速度是远慢于内存的。

### redo log 什么时候落盘

- MySQL 正常关闭时
- 当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘
- InnoDB 的后台线程每隔一秒，将 redo log buffer持久化到磁盘
- 每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘

`innodb_flush_log_at_trx_commit`可以控制 redo log 落盘的策略
- 0，表示每次事务提交时，还是将 redo log 留在 redo log buffer 中，该模式下事务提交时不会主动触发写入磁盘的操作
- 1，表示每次事务提交时，都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘，这样可以保证 MySQL 异常重启之后数据不会丢失
- 2，表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件，写入到 redo log 文件并不意味着写入到了磁盘，因为操作系统的文件系统中有个 Page Cache，Page Cache 是专门用来缓存文件数据的，所以写入 redo log 文件意味着写入到了操作系统的文件缓存

### redo log 文件满了怎么办

默认情况下， InnoDB 存储引擎有 1 个重做日志文件组( redo log Group），「重做日志文件组」由有 2 个 redo log 文件组成，这两个 redo 日志的文件名叫 ：`ib_logfile0` 和 `ib_logfile1` 。

重做日志文件组是以**循环写**的方式工作的，从头开始写，写到末尾就又回到开头，相当于一个环形。

### 为什么要有 redo log

- 能够在发生错误或用户执行ROLLBACK时提供回滚相关的信息
- 在整个系统发生崩溃、数据库进程直接被杀死后，当用户再次启动数据库进程时，还能够立刻通过查询回滚日志将之前未完成的事务进行回滚，这也就需要回滚日志必须先于数据持久化到磁盘上，是我们需要先写日志后写数据库的主要原因

## bin log

MySQL 在完成一条更新操作后，Server 层还会生成一条 binlog，等之后事务提交的时候，会将该事务执行过程中产生的所有的 binlog 统一写入到 binlog 文件。

binlog文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的日志

### redo log 与 bin log 的区别

- 适用对象不同
	- binlog 是 MySQL 的Server 层实现的日志，所有存储引擎都可以使用
	- redo log 是 InnoDB 存储引擎实现的日志
- 文件格式不同
	- binlog有3种格式类型，分别是 STATEMENT、ROW、MIXED
		- STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致；
		- ROW：**记录行数据**最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已；
		- MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；
	- redo log 是物理日志，记录的是在某个数据页做了什么修改
- 写入方式不同
	- binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志
	- redo log 是循环写，日志空间大小是固定的，全部写满就从头开始，保存未被刷入磁盘的脏页
- 用途不同
	- binlog 用于备份恢复，主从复制
	- redo log 用于掉电等故障恢复

如果整个数据库都被删除了，就只能用 binlog 来进行恢复，因为 redo log 文件是循环写，边写边擦除日志，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会从 redo log 文件里删除；而binlog保存的是全量的日志，也就是保存了所有数据变更的情况，理论上只要记录在 binlog 上的数据都可以恢复

### 如何实现主从复制

MySQL 集群的主从复制过程梳理成 3 个阶段：
- **写入 Binlog**：主库写 binlog 日志，提交事务，并更新本地存储数据。
- **同步 Binlog**：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。
- **回放 Binlog**：回放 binlog，并更新存储引擎中的数据。

具体详细过程如下：
- MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。
- 从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。
- 从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。

MySQL主从复制的机制
- **同步复制**：MySQL 主库提交事务的线程要等待所有从库的复制成功响应，才返回客户端结果。这种方式在实际项目中，基本上没法用，原因有两个：一是性能很差，因为要复制到所有节点才返回响应；二是可用性也很差，主库和所有从库任何一个数据库出问题，都会影响业务。
- **异步复制**（默认模型）：MySQL 主库提交事务的线程并不会等待 binlog 同步到各从库，就返回客户端结果。这种模式一旦主库宕机，数据就会发生丢失。
- **半同步复制**：MySQL 5.7 版本之后增加的一种复制方式，介于两者之间，事务线程不用等待所有的从库复制成功响应，只要一部分复制成功响应回来就行，比如一主二从的集群，只要数据成功复制到任意一个从库上，主库的事务线程就可以返回给客户端。这种**半同步复制的方式，兼顾了异步复制和同步复制的优点，即使出现主库宕机，至少还有一个从库有最新的数据，不存在数据丢失的风险**。

### binlog什么时候落盘

事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到 binlog 文件中。

一个事务的 binlog 是不能被拆开的，因此无论这个事务有多大（比如有很多条语句），也要保证一次性写入。这是因为有一个线程只能同时有一个事务在执行的设定，所以每当执行一个 begin/start transaction 的时候，就会默认提交上一个事务，这样如果一个事务的 binlog 被拆开的时候，在备库执行就会被当做多个事务分段自行，这样破坏了原子性，是有问题的。

MySQL 给每个线程分配了一片内存用于缓冲 binlog ，该内存叫 binlog cache，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。

## 两阶段提交

两阶段提交是为了避免 binlog 与 redo log 之间逻辑的不一致

两阶段提交分为准备阶段和提交阶段
- 准备阶段，写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘
- 提交阶段，写入到 binlog，然后将 binlog持久化到磁盘，接种调用引擎的提交事务接口，将 redo log 状态设置为 commit

### 两阶段提交的问题

- **磁盘 I/O 次数高**：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。
	- 如果 sync_binlog 和 当 innodb_flush_log_at_trx_commit 都设置为 1，那么在每个事务提交过程中， 都会**至少调用 2 次刷盘操作**，一次是 redo log 刷盘，一次是 binlog 落盘，所以这会成为性能瓶颈。
- **锁竞争激烈**：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。

### 组提交

MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数

prepare 阶段不变，只针对 commit 阶段，将 commit 阶段拆分为三个过程：
- **flush 阶段**：多个事务按进入的顺序将 binlog 从 cache 写入文件（不刷盘）；
- **sync 阶段**：对 binlog 文件做 fsync 操作（多个事务的 binlog 合并一次刷盘）；
- **commit 阶段**：各个事务按顺序做 InnoDB commit 操作；

上面的**每个阶段都有一个队列**，每个阶段有锁进行保护，因此保证了事务写入的顺序，第一个进入队列的事务会成为 leader，leader领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束。