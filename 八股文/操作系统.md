## 内核态与用户态

### 为何要区分用户态和内核态

最简单的运行程序的方式是"直接运行"，即直接在CPU上执行任意程序。直接执行的问题是：
- 如何限制代码的行为？比如禁止：==设置特殊寄存器的值==、访问存储器的任意位置、I/O请求、申请更多系统资源等
- 在运行这个程序的时候，如何切换到另一个程序？进程调度应该是 OS 才有的权限

因此引入用户态和内核态两种模式。用户态无法执行受限操作，如 I/O 请求，执行这些操作会引发异常。核心态只能由操作系统运行，可以执行特权操作。用户程序通过系统调用执行这些特权操作。OS 执行前会判断进程是否有权限执行相应的指令

区分用户态与核心态的执行机制称为"受限直接执行"

### 什么时候会陷入内核态

[[操作系统#陷阱、中断、异常、信号|系统调用、中断、异常]]

系统调用是用户进程主动发起的。发起系统调用，陷入内核，由操作系统执行系统调用，然后返回到进程。

中断和异常是被动的，无法预测发生时机。中断包括 I/O 中断、外部信号中断、各种定时器引起的时钟中断等。异常包括程序运算引起的各种错误如除 0、缓冲区溢出、缺页等

在系统的处理上，中断和异常类似，都是通过中断向量表来找到相应的处理程序来进行处理。区别在于，中断来自处理器外部，不是由任何一条专门的指令造成，而异常是执行当前指令的结果。

### 如何切换用户态与内核态

### C 访问空指针会不会陷入内核态

会。

访问空指针相当于访问一个虚拟地址，硬件会将虚拟地址映射到真实的物理内存。如果映射失败，硬件会抛出一个段错误异常，此时从用户态转为内核态进行处理。

OS 会在中断描述符表中，找到处理  page fault exception 的中断向量，执行相应的 handler。一般情况下，OS 会抛出一个 SIGSEGV 信号给进程，终止进程，打印出 debug 信息。


## 陷阱、中断、异常、信号

### 异常控制流

每个进程对应的程序文件由一条一条的指令组成。进程在执行的时候。会将程序文件加载到进程的内存空间中，这些指令在内存空间中是相邻的。进程会通过调整程序计数器 PC 的值，一条一条地执行指令。我们将进程执行的指令序列叫做处理器的"控制流"。

正常情况下，进程可能会顺序执行相邻的指令，也可能通过跳转、调用、返回等程序指令转移到另一个位置开始执行。无论是前者还是后者，都是程序正常执行的结果，是可以预知的，符合预期的。

但是，系统中也会发生一些**异常情况**。处理这些异常的时候，会打断进程正常执行的控制流，转而执行相应的处理程序，执行完毕再返回，我们将这类突变称为 "异常控制流"

![-w471](https://imageslr.com/media/15948281929782.jpg)

异常控制流的形式有以下几种：陷阱、中断、异常，此外还有信号，这是一种更高层的异常形式，也会改变进程的控制流。

### 陷阱

陷阱是有意造成的异常，是执行一条指令的结果。**陷阱是同步的**。

**陷阱的主要作用是实现系统调用**。比如，进程可以 syscall n 指令向内核请求服务。当进程执行这条指令后，会中断当前的控制流，陷入内核态，执行相应的系统调用。内核的处理程序在执行结束后，会将结果返回给进程，同时退回到用户态。进程此时继续执行下一条指令。

每个系统调用有一个唯一的整数号，对应于内核中的一个跳转表的偏移量。这个跳转表中的每一个条目表示一个系统调用的代码位置。执行系统调用时，通过这个整数号作为跳转表的偏移量，就可以执行相应的系统调用。

![[Pasted image 20221111105039.png]]

陷阱也被称为"软中断"，它不是真正意义上的中断，但是和硬件中断的处理流程类似。

### 中断

中断由处理器**外部**的**硬件**产生，不是执行某条指令的结果，也无法预测发生时机。由于中断独立于当前执行的程序，因此**中断是异步事件**。

中断包括 I/O 设备发出的 I/O 中断、各种定时器引起的时钟中断、调试程序中设置的断点等引起的调试中断等。

每个中断都有一个中断号。操作系统使用**中断描述符表**（Interrupt Descriptor Table，IDT）来保存每个中断的中断处理程序的地址。当发生中断时，操作系统会根据中断号，在中断描述表中查找并执行相应的中断处理程序。当处理程序返回后，进程继续执行**下一条指令**，就好像没有发生过中断一样。

![[Pasted image 20221111105152.png]]

#### 软中断

原因:中断请求的处理程序应该要短且快，这样才能减少对正常进程运行调度地影响，而且中断处理程序可能会暂时关闭中断，这时如果中断处理程序执行时间过长，可能在还未执行完中断处理程序前，会丢失当前其他设备的中断请求。

Linux 系统**为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」。**

- **上半部直接处理硬件请求，也就是硬中断。用来快速处理中断**，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。负责耗时短的工作，特点是快速执行；
- **下半部由内核触发，也就说软中断。用来延迟处理上半部未完成的工作**，一般以「内核线程」的方式运行。通常都是耗时比较长的事情，特点是延迟执行；

### 异常

异常是一种错误情况，是执行当前指令的结果，可能被错误处理程序修正，也可能直接终止应用程序。**异常是同步的**。

注意这里的“异常”和上文一开始说的“异常”的区别。上文的“异常”是一个通用的术语，表示因为某些事件/操作而引起的控制流的改变，包括陷阱、中断和异常。这里的“异常”特指因为执行当前指令而产生的**错误情况**，比如除法异常、缺页异常等。有些书上为了区分，也将这类“异常”称为 **“故障”**。

当发生异常时，操作系统会将控制转移给相应的异常处理程序。如果处理程序能够修正这个错误情况，就将返回到**引起异常的指令**重新执行。否则，**终止**该应用程序。

异常处理程序的地址也保存在中断描述符表（IDT）中。

![-w494](https://imageslr.com/media/15948647387834.jpg)

常见的异常类型及处理：
- 除法错误（异常 0）：当应用程序试图除以零，或者一个除法指令结果溢出的时候，就会发生除法错误。Linux 会**直接终止**程序。Linux shell 报告为“浮点异常（Floating exception）”
- 一般保护故障（异常 13）：当应用程序访问一个未定义的虚拟内存区域（如访问空指针），或者试图写一个只读的文本段时，会发生一般保护故障。Linux 会**直接终止**程序。Linux shell 报告为“段错误（Segmantation fault）”
- 缺页异常（异常 14）：当应用程序访问未加载的页面时，会引起缺页异常。缺页处理程序会加载适当的页面，然后**重新执行**引起异常的指令

![[Pasted image 20221111105739.png]]

==中断与异常的异同==
1. 相同点
	- 最后都是由CPU发送给内核，由内核去处理
	- 处理程序的流程设计上是相似的
2. 不同点
	- 产生源不同，异常是由CPU产生的，而中断是由硬件设备产生的
	- 内核需要根据是异常还是中断调用不同的处理程序
	- 中断不是时钟同步的，这意味着中断可能随时到来；异常由于是CPU产生的，所以它是时钟同步的
	- 当处理中断时，处于中断上下文中；处理异常时，处于进程上下文中
	- 硬中断和软中断（只要是中断上下文）执行的时候都不允许内核抢占

### 信号

信号是一种更高层的软件形式的异常，同样会中断进程的控制流，可以由进程来进行处理一个信号代表了一个消息。**信号的作用是用来通知进程发生了某种系统事件**。

信号可以直接进行用户空间进程和内核空间进程的交互，内核进程可以用它来通知用户空间进程发生了哪些系统事件。

上文的陷阱、中断和异常都是低层异常机制，由内核的异常处理程序进行处理，正常情况下对用户进程是不可见的。信号提供了一种机制，通知用户进程发生了这些异常。比如，如果一个进程试图除0，那么内核会收到一个除零的异常，内核会给进程发送一个 SIGFPE 信号(=8)，如果一进程非法内存访问，那么内核会收到一个一般保护故障，内核会给进程发送一个 SIGSEGV 信号(=11)

此外，还有其他系统事件。也可以通过信号来通知进程。比如，如果按下 Ctrl + C，那么内核会给进程发送一个 SIGINT 信号

#### 发送信号

信号除了由内核发给进程，也可以作为进程间通信的一种方式，明确由一个进程发送给另一个进程

发送信号的机制：
- 用 /bin/kill 程序发送信号
- 从键盘发送信号，比如按下 Ctrl + C 发送 SIGINT 信号、按下 Ctrl + Z 发送 SIGTSTP 信号
- 用 kill 函数发送信号
- 用 alarm 函数向自己发送 SIGALARM 信号

#### 接收信号

每个进程有一个待处理信号的集合。待处理信号表示发送给该进程但是还未被处理(接收)的信号，任何时刻同一类型的待处理信号最多只有一个，后续发送的同类型信号将会被丢弃(隐式阻塞)

进程也可以选择阻塞某种信号。当一种信号被阻塞时，它仍可以被发送，但产生的待处理信号不会被目标进程接收，直到进程取消对这种信号的阻塞(显式阻塞)

#### 处理信号

信号处理的时机
- 当内核把进程**从内核态切换到用户态时**。例如，从系统调用返回，或是完成一次上下文切换
- 内核通过**控制转移**来强制进程 _接收/处理_ 信号。如果进程的未被阻塞的待处理信号集合不为空，则内核会选择集合中的某个信号（通常是最小的），并将控制传递到信号处理程序；否则，内核正常地将控制传递到进程的下一条指令

用户进程对信号的处理过程有三种：
1.  执行默认操作，linux 对每种信号都规定了**默认行为**（见上图），是下面的一种
    -   进程终止
    -   进程终止并转储内存（core dump）
    -   进程停止（挂起）直到被 SIGCONT 信号重启
    -   进程忽略该信号
2.  忽略信号。当不希望接收到的信号对进程的执行产生影响，而让进程继续执行时，可以忽略该信号，即不对信号进程作任何处理
3.  处理信号。定义信号处理程序，当信号发生时，执行相应的处理程序

信号处理程序是一个**用户层函数**。进程可以为某个信号指定一个信号处理程序，接收到信号后，进程会跳转执行信号处理程序，执行完成后再返回到中断位置的**下一条指令**继续执行。

![-w407](https://imageslr.com/media/15949144782600.jpg)


## 进程与线程
### 进程






### 线程

#### 为什么需要线程

进程切换是一个开销很大的操作。进程切换的开销主要包括：
- 处理机的上下文切换：保存和恢复相关寄存器的内容
- 与进程相关的数据结构的更改：存储管理有关的记录信息（如页表）、文件管理有关数据（如文件描述符）、进程控制块中的各种队列（如阻塞队列、就绪队列、通信队列）等

进程的处理机资源和其他的资源是一起分配的，进程切换的时候会整体切换，开销很大。如果我们**只切换必须的、与处理机相关的信息**，就可以有效减少开销。这种情况下，处理机分配的单位和其他的资源分配的单位不能再是一个实体

由此引入线程：把一个进程分为多个执行任务的单元体，只为其分配处理机，这些执行任务的单元体就是线程

#### 线程的上下文切换

线程有自己的寄存器和栈，当上下文切换时，正在运行的线程会将寄存器的状态保存到TCB(Thread Control Block)里(进程是PCB, Proxess Control Block)，然后恢复另一个线程的上下文

与进程的区别是，线程只需要切换处理机执行的上下文，不帮助改变地址空间。这意味着：
- 不需要重新加载页表，切换开销少，提高效率
- 多个线程共享地址空间，有利有弊

![15941873964798.jpg](https://imageslr.com/media/15941873964798.jpg)

#### 线程的优缺点

优点：
- 提高效率：切换开销小
- 通信方便，共享内存；进程必须通过进程间通信==IPC==
- 各个线程之间可以并发执行，提高程序并发性
- 多个线程是IO密集型时，多线程可以使这些活动彼此重叠运行，可以加快程序的执行速度。

缺点：
- 一个线程出错，操作系统会结束整个进程，不够健壮；而多进程没有这个问题
- 同一个进程中的多个线程共享内存，会有并发问题

#### 同一进程中的线程共享与独占的资源

共享资源：
- 内存空间
	- 代码
	- 公共数据（全局变量、静态变量）
	- 堆
- 文件描述符
- 信号处理器
- 进程 ID / 进程组 ID
- ...

独占资源，以及为什么需要独占：
- 线程ID：在本进程中唯一，进程用来标识此线程
- 一组寄存器的值
- 栈：每个线程中的函数调用过程是独立的，因此需要有独立的栈
- 错误返回码：系统调用或库函数发生错误时，会设置全局errno，各个线程的错误返回码应该是独立的
- 信号屏蔽码：每个线程所感兴趣的信号不同，所以线程的信号屏蔽码应该由自己管理；但每个线程都共享本进程的信号处理器

#### 线程的实现方式

线程也像进程一样有多个状态：运行、就绪、阻塞 ...

从Linux内核的角度看，线程和进程并没有被区别对待。无论线程还是进程，都是用 task_struct 结构表示的，只不过线程的 mm(内存空间)和 files(打开的文件)结构体是共享的。

线程实现的方式有三种：
- 在内核实现：在内核中实现的线程，是由内核管理的线程
- 在用户空间实现：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理
- 混合方式实现(轻量级进程)：在内核中来支持用户线程

##### 用户线程

用户线程是基于用户态的线程管理库来实现的，那么**线程控制块**也是在库里面来实现的，对于操作系统而言是看不到这个TCB的，它只能看到整个进程的PCB。所以用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。

优点：
- 每个进程都需要有它私有的线程控制块(TCB)列表，用来跟踪记录它各个线程状态信息(PC、栈、指针、寄存器)，TCB由用户级线程库函数来维护，可用于不支持线程技术的操作系统
- 用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快
- 允许每个进程有自己的调度算法
- 具有较好的可扩展性，因为在内核空间中内核线程需要一些固定表格空间和堆栈空间，如果内核线程的数量非常大，就会出现问题
- 线程能够利用的表空间和堆栈空间比内核线程多

缺点：
- 由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了
- 当一个线程开始运行后，除非它主动交出CPU的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的
- 由于时间片分配给进程，故与其他进程相比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢

##### 内核线程

内核线程是由操作系统管理的，线程对应的TCB放在操作系统里，这样线程的创建、终止和管理都是由操作系统负责

优点：
- 在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行
- 时间片分配给线程，多线程的进程获得更多的CPU运行时间

缺点：
- 在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如PCB 和 TCB
- 线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大

##### 轻量级进程

轻量级进程（LWP）是内核支持的用户线程，一个进程可以有一个或多个LWP，每个LWP是跟内核线程一对一映射的，也就是LWP都是由一个内核线程支持

LWP与普通进程的区别在于它只有一个最小的执行上下文和调度程序所需的统计信息。一般来说，一个进程代表程序的一个实例，而LWP代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以LWP也不带有这样的信息。

在LWP之上也是可以使用用户线程的，那么LWP与用户线程的对应关系就有三种
- 1：1，即一个LWP对应一个用户线程
- N：1，即一个LWP对应多个用户线程
- M：N，即多个LWP对应大哥用户线程

**1：1 模式**
一个线程对应到一个LWP再对应到一个内核线程
优点：实现并行，当一个LWP阻塞，不会影响其他LWP
缺点：每一个用户线程，就产生一个内核线程，创建线程的开销较大

**N：1 模式**
多个用户线程对应一个LWP再对应一个内核线程，线程管理是在用户空间完成的，此模式中用户的线程对操作系统不可见
优点：用户线程要开几个都没问题，且上下文切换发生在用户空间，切换的效率较高
缺点：一个用户线程如果阻塞了，则整个进程都将会阻塞，另外在多核CPU中，是没办法充分利用CPU的

**M：N 模式**
根据前面的两个模型混搭在一起，就形成 M：N 模型，该模型提供了两级控制，首先多个用户线程对应到多个LWP，LWP再一一对应到内核线程
优点：综合了前两种优点，大部分的线程上下文切换发生在用户空间，且多个线程又可以充分利用多核CPU的资源。

##### 用户级线程与内核级线程的区别

- 内核级线程是OS内核可感知的，而用户级线程是OS内核不可感知的
- 用户级线程的创建、撤销和调度不需要OS内核的支持，是在语言这一级处理的；内核级线程创建、撤销和调度都需OS内核提供支持，而且与进程的创建、撤销和调度大体是相同的
- 用户级线程执行系统调用指令时将导致其所属进程被中断，而内核级线程执行系统调用指令时，只导致该线程被中断
- 在只有用户级线程的系统内，CPU调度还是以进程为单位，处于运行状态的进程中的多个线程，有用户程序控制线程的轮换运行；在有内核支持线程的系统内，CPU调度则以线程为单位，由OS的线程调度程序负责线程的调度
- 用户级线程的程序实体是运行在用户态下的程序，而内核支持线程的程序实体则是可以运行在任何状态下的程序

#### 如何回收线程

-   等待线程结束：int pthread_join(pthread_t tid, void** retval);
    - 主线程调用，等待子线程退出并回收其资源，类似于进程中wait/waitpid回收僵尸进程，调用pthread_join的线程会被阻塞。
        - tid：创建线程时通过指针得到tid值。
        - retval：指向返回值的指针。
    - 结束线程：pthread_exit(void \*retval);
    - 子线程执行，用来结束当前线程并通过retval传递返回值，该返回值可通过pthread_join获得。
        - retval：同上。

- 分离线程：int pthread_detach(pthread_t tid);
    - 主线程、子线程均可调用。主线程中pthread_detach(tid)，子线程中pthread_detach(pthread_self())，调用后和主线程分离，子线程结束时自己立即回收资源。
    - tid：同上。


## 进程的调度
### 进程的状态
#### 基本状态

就绪、执行、睡眠
- 就绪：进程已获得除处理机以外的所需资源，等待分配处理机资源
- 执行：进程正在占用处理机资源执行
- 阻塞：进程等待某种条件，在条件满足之前我无法执行。如发起 I/O 系统调用，会被阻塞，等待 I/O 中断发生


![](https://vl67qv51dr.feishu.cn/space/api/box/stream/download/asynccode/?code=YmUxM2RiYjNmMjAyODM5MWJjNzE1YTQ1NjdmMGJjNjFfUktONEhsTkp4eHVxaWRPbldwRnlVbkF5dTd4RUE5cUVfVG9rZW46Ym94Y253eFRSR3lCeFlsS290V3RoMWYzanpjXzE2Njg1ODIwOTc6MTY2ODU4NTY5N19WNA)

应该注意以下内容：
- 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。

那么，就需要一个新的状态，来**描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态**。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。
-   **阻塞挂起状态**：进程在外存（硬盘）并等待某个事件的出现；
-   **就绪挂起状态**：进程在外存（硬盘），但只要进入内存，即刻立刻运行；

**只有就绪态和运行态可以相互转换，其它都是单项转换**

### 挂起

"挂起"是将暂不执行的进程换出到外存，节省内存空间

"挂起"和"阻塞"都是进程暂停执行的状态，但是却是两个维度的概念
- 阻塞表示进程正在等待一个事件的发生，阻塞状态下收到信号会切换到就绪状态
- 挂起表示进程被换出到外存，挂起状态下被激活时会被载入到内存，切换为非挂起状态

挂起状态的进程按照是否阻塞可以分为：
- 挂起就绪状态：进程在外存，但是只要被载入内存就可以执行
- 挂起阻塞状态：进程在外存中并等待一个时间，即使被载入内存（激活）也无法运行

![[Pasted image 20221114092329.png]]

### 睡眠

Linux将进程的阻塞状态进一步细分为：暂停、浅睡眠、深睡眠。其中，若不需要等待资源，则切换为"暂停"；若需要等待资源，切换为"睡眠"；如果睡眠状态能被唤醒，则是"浅睡眠"，否则是"深睡眠"

![[Pasted image 20221114092546.png]]

### 挂起、阻塞、睡眠的区别

从触发机制上：
-   睡眠是主动触发的，
-   挂起也是主动触发
-   而阻塞是被动的

从资源占用角度来说：
- 阻塞进程不再占用CPU资源，但还在占用调度器和内存资源
- 挂起进程不再占用CPU和内存资源了
- 睡眠进程既占用内存资源又占用CPU资源
- 从恢复上来看： 睡眠恢复是自动完成的，因为睡眠有一个睡眠时间，睡眠时间到则恢复到就绪态。
- 阻塞是被动的，是在等待某种事件或者资源的表现，一旦获得所需资源或者事件信息就自动回到就绪态。
- 最后挂起情况最多，如果是用户将进程挂起的话，那么只有用户才能解除进程的挂起状态，而如果是被操作系统挂起的，这要根据系统资源情况，优先级，挂起中的状态来判定什么时候解除挂起状态。

### 进程控制块

**进程控制块/表（PCB）来描述进程，PCB 是进程存在的唯一标识**，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。

一般会选择链表进行组织，把具有**相同状态的进程链在一起，组成各种队列****。**因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。

**组成（包含进程上下文信息）：**
-   **进程描述信息**
    -   进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；
    -   用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；

-   **进程控制和管理信息**
    -   进程当前状态，如 new、ready、running、waiting 或 blocked 等；
    -   进程优先级：进程抢占 CPU 时的优先级；

-   **资源分配清单**
    -   有关内存地址空间或虚拟地址空间的信息（如页表基地址），所打开文件的列表和所使用的 I/O 设备信息。

-   **CPU 相关信息：**
    -   CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。

> 线程控制块 TCB 中包含了哪些内容？
>
> -   线程标识符
> -   一组寄存器
>     -   通用寄存器
>     -   程序计数器PC
>     -   状态寄存器
> -   线程运行状态
> -   优先级
> -   线程专有存储区
> -   信号屏蔽
> -   堆栈指针

### 进程的上下文切换

操作系统需要事先帮 CPU 设置好 **CPU 寄存器和程序计数器，**CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 **CPU 上下文。**

进程是由内核管理和调度的，所以进程的切换只能发生在**内核态**。

所以，**进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。**

通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中。

#### 上下文切换的场景

- 时间片耗尽，进程从运行状态变为就绪状态
- 资源不足，等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行
- sleep主动挂起
- 有优先级更高的进程运行时，当前进程会被挂起，由高优先级进程来运行
- 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；

### 调度算法

#### 调度算法的分类

- 按照CPU的分配方式：非抢占式、抢占式
- 按照系统的分时方式：在批处理系统，交互系统或实时系统下的调度

#### 饥饿问题

某个进程无限等待，无法被调度

#### 批处理系统的调度算法

调度算法的目标：
- 吞吐量：系统每小时完成的作业数，要尽可能多
- 周转时间：一个作业从提交到完成时的统计平均时间
- CPU利用率：由于没有交互，CPU不会出现等待输入的情况，银保吃CPU利用率要高

##### 先来先服务（First Come First Serverd, FCFS）

- 按照请求CPU的顺序使用CPU，非抢占式
- 优点是易于理解，便于实现，只需一个就绪队列
- 缺点是对短作业不公平；对 I/O 密集型进程不利，长时间等待设备；响应时间不确定

##### 最短作业优先

- 预知作业的运行时间，选择最短时间的优先运行
- 优点是提高平均周转时间
- 缺点是对长作业不公平；可能导致饥饿问题

##### 最短剩余时间优先

- 最短作业的抢占式版本，如果新作业比正在执行的作业剩余时间短，则它优先执行
- 缺点是对长作业不公平；可能导致饥饿。同"最短作业优先"

##### 最高响应比优先

- 响应比的定义：作业等待时间 / 作业运行所需时间
- 哪个进程的响应比大，哪个进程优先
- 由响应比的定义可以知道，作业运行所需时间越小、作业等待时间越长，响应比越大
- 优点：同时考虑了等待时间和执行时间，既优先考虑短作业，也防止长作业无限等待的饥饿。

#### 交互系统(分时系统)的调度算法

调度算法的目标：
- 响应时间：要快速响应交互请求
- CPU的运行分为若干个时间片，能够处理不同的运算请求，使每个用户都能共享主机资源

##### 时间片轮转

- 将所有就绪的进程排成一个队列，按照时间片轮流调度，用完时间片的进程排到队列末尾，属于抢占式
- 优点：没有饥饿问题
- 问题：若时间片小，进程切换频繁，吞吐量低；若时间片长，则响应时间过长，实时性得不到保证

##### 优先级调度算法

- 优先级高的进程先运行，同优先级的进程轮转。当高优先级队列中没有进程后，再调度下一级队列
- 缺点是可能导致低优先级进程饿死

引入**动态设定优先级的思想**：在优先级高的进程运行一个时间片后，降低其优先级，防止其一直占用CPU，饿死低优先级的进程。结合这个思想，可设计出"多级反馈队列"

##### 多级反馈队列

有许多独立的队列，每个队列有不同的优先级

- 优先级高的队列先执行；**优先级越高，时间片越短**；如果一个进程在当前队列规定的时间片内无法执行完毕，则移动到下一个队列的队尾
- 缺点是也有可能出现饥饿问题，比如不断有新的更高优先级的进程加入
	- 解决方案：经过一段时间S，就将系统中所有工作重新加入最高优先级队列

使用时间片的一个缺点，如果程序在每个时间片快要用完之前主动放弃CPU，那么他就会一直处于高优先级
解决方案：使用时间配额而不是时间片

##### 彩票法

彩票数代表了进程占有某个资源的份额，一个进程拥有的彩票数占总彩票数的百分比就是它占有资源的份额。

调度程序从总的票数中抽取中奖彩票，拥有这个数对应的彩票的进程中奖

随机方法的优点
- 可以避免奇怪的边角问题，例如LRU在有重复序列的负载时表现非常差
- 轻量，几乎不需要记录任何状态
- 很快，只要可以很快地产生随机数，做出决策就很快

- 向进程提供各种系统资源的彩票，调度是随机抽取彩票，拥有该彩票的进程得到资源
- 可给重要的进程更多的彩票；协作进程可以交换彩票
- 缺点是在工作运行时间很短的情况下，经常不能产生正确的bili
	- 解决方案：步长调度，一个确定性的公平分配算法
	- 使用一个大数分别除以每个进程的票数来获得每个进程的步长
	- 选择目前拥有最小行程值的进程，并且运行之后将该进程的行程值增加一个步长
- 彩票调度不需要全局状态，而步长调度需要拥有全局状态

这两种方式没有作为CPU的调度程序被广泛使用
- 这两种方式都不能很好地适合 I/O
- 最难的票数分配问题并没有确定的解决方式

##### 公平共享法

- 为每用户分配一定比例的CPU时间，而不是按照进程
- 各用户之间按照比例挑选进程

#### 实时系统的调度算法

调度算法的目标：满足任务的截止时间。也就是说，如果有一个任务需要执行，实时操作系统会马上执行该任务，并不会有较长的延时

##### 最早截止时间优先算法

先把截止时间早的任务给完成，否则这个任务如果在截止时间后才完成，就没有意义了

### 僵尸进程、孤儿进程、守护进程

- 僵尸进程：停止运行
- 孤儿进程：正在运行
- 守护进程：正在运行

#### 僵尸进程

当一个进程由于某种原因终止时，内核并不是把它从系统中清除。进程会保持在一种"已终止"的状态中，直到被它的父进程回收。当父进程回收已终止的子进程时，内核会抛弃已终止的进程，此时该进程就不存在了。

僵尸进程是指终止但还未被回收的进程，如果子进程退出，而父进程并没有调用 `wait()` 或 `waitpid()` 来回收，那么就会产生僵尸进程。僵尸进程是一个已经死亡的进程，但是其进程描述符仍然保存在系统的进程表中。

危害：占用进程号，系统所能使用的进程号是有限的，可能导致不能产生新的进程；占用一定的内存

如何避免产生僵尸进程：
- 通过`signal(SIGCLD, SIG_IGN)` 通知内核对子进程的结束不关心，由内核回收。如果不想让父进程挂起，可以在父进程中加入一条语句：`signal(SIGCLD, SIG_IGN)` ，表示父进程忽略SIGHLD信号，该信号是子进程退出的时候向父进程发送的
- 父进程调用 `wait()` 或者  `waitpid()` 等待子进程结束，如果尚无子进程退出，wait会导致父进程阻塞。waitpid可以通过传递WNOHANG使父进程不阻塞立即返回
- 如果父进程很忙，可以用signal注册信号处理函数，在信号处理函数调用wait/waitpid等待子进程退出
- 通过两次调用fork，父进程首先调用fork创建一个子进程，然后waitpid等待子进程退出，子进程再fork一个孙进程后退出。这样子进程退出后会被父进程等待回收，而对于孙子进程，其父进程已经退出，所以孙子进程就成为了一个孤儿进程，孤儿进程由Init进程接管，孙子进程结束后，Init会等待回收

第一种方法忽略SIGCHLD信号，这常用于并发服务器的性能的一个技巧因为并发服务器常常fork很多子进程，子进程终结之后需要服务器进程去wait清理资源。如果将此信号的处理方式设为忽略，可让内核把僵尸子进程转交给init进程去处理，省去了大量僵尸进程占用系统资源。

**设置僵尸进程的目的**是维护子进程的信息，以便父进程在以后的某个时候获取。这些信息至少包括进程ID，进程的终止状态，以及该进程使用的CPU时间，所以当终止子进程的父进程调用wait或waitpid时就可以获得这些信息。如果一个进程终止，而该进程有子进程处于僵尸状态，那么它的所有僵尸子进程的父进程id将被重置为1(init进程)。继承这些子进程的init进程将清理他们(也就是说Init进程将wait他们，从而去除他们的僵尸状态)

#### 孤儿进程

如果某个进程的父进程先结束了，那么它的子进程会成为孤儿进程，每个进程结束的时候，学习通都会扫描是否存在子进程，如果有，则用 Init 进程(pid = 1) 接管，并由 Init 进程调用 `wait` 等待其结束，完成状态收集工作。孤儿进程不会对系统造成危害。

#### 守护进程

守护进程是一种在后台周期性执行某种任务的进程，独立于控制终端。

## 进程间的通信方式

| 方式     | 传输的信息量       | 使用场景       | 关键词                                                         |
| -------- | ------------------ | -------------- | -------------------------------------------------------------- |
| 信号     | 少量               | 任何           | 硬件来源、软件来源信号队列                                     |
| 管道     | 少量               | 亲缘进程间               | 单向流动/内核缓冲区/循环队列/没有格式的字节流/操作系统负责同步 |
| 命名管道 | 大量               | 任何           | 磁盘文件/访问权限/无数据块/内核缓冲区/操作系统负责同步         |
| 信号量   | N                  | 任何           | 互斥同步/原子性/P减V增                                         |
| 共享内存 | 大量               | 多个进程       | 内存映射/简单快速/操作系统不保证同步                           |
| 消息队列 | 比信号多，但有限制 | 任何           | 有格式/按消息类型过滤/操作系统负责同步                         |
| 套接字   | 大量               | 不同主机的进程 | 读缓冲区/写缓冲区/操作系统负责同步                             |

### 信号

[[操作系统#信号|信号]]是Linux系统响应某些条件而产生的一个事件，由操作系统事先定义，接收到该信号的进程可以才去自定义的行为。这是一种"订阅-发布"的模式

信号的来源分为硬件来源和软件来源
- 硬件来源：如按下 CTRL+C、除0、非法内存访问等等
- 软件来源：如Kill命令、Alarm Clock超时、当Reader终止后又向管道写数据等等

一般的信号是都是由一个错误产生的。以除 0 为例。在 x86 机器上 DIV 或 IDIV 指令除数为 0 时，会引发 0 号中断，编号 \#DE(Divide Error)，即所谓除零异常。这是一个硬件级中断，会导致陷入内核，执行操作系统预定义在 IDT 中的中断处理程序。而操作系统处理这个异常的方法，就是**向进程发送一个信号 `SIGFPE`**。如果进程设置了相应的 signal handler，就执行进程的处理方法。否则，执行操作系统的默认操作，一般这种信号的默认操作是杀死进程。

同理，溢出、非法内存访问（越界）、非法指令等也都属于硬件中断，由操作系统处理。**操作系统会将这些硬件异常包装成“信号”发送给进程**。如果进程不处理这几个异常信号，那么默认的行为就是挂掉。

但是，信号也可以作为进程间通信的一种方式，明确地由一个进程发送给另一个进程。

进程如何发送信号？
- 操作系统提供发送信号的系统调用
- 该系统调用会将信号放到目标进程的**信号队列**中
- 如果目标进程未处于执行状态，则该信号就由内核保存起来，直到该进程恢复执行并传递给它为止。如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消时才被传递给进程

进程如何接收信号？
- 每个进程有一个**信号队列**，放其他进程发给它、等待它处理的信号
- 进程在执行过程中的特定时刻，检查并处理自己的信号队列。如从系统空间返回到用户空间之前
- 发送信号时，必须指明发送目标进程的号码。一般用在具有亲缘关系的进程之间

用户进程对信号的处理过程有三种：
1. 处理信号。定义信号处理函数，当信号发生时，执行相应的处理函数
2. 忽略信号。当不希望接收到的信号对进程的执行产生影响，而让进程继续执行时，可以忽略该信号，即不对信号进程作任何处理
3. 不处理也不忽略。执行默认操作，linux 对每种信号都规定了默认操作

有的信号，用户进程是无法处理也无法忽略的，比如`SIGSTOP`、`SIGKILL` 等。

### 管道

管道命令，在 Linux Shell 中经常使用，一般，我们使用管道操作符 `|` 来表示两个命令之间的数据通信。比如：

```
ps -ef | grep java | xargs echo
```

管道操作符的内部实现其实就是 Linux 的管道接口。由管道操作符 `|` 分割的每个命令是独立的进程，各个进程的标准输出 STDOUT，会作为下一个进程的标准输入 STDIN。

#### 定义

管道是一种半双工的通信方式，数据只能**单向流动**，上游进程往管道中写入数据，下游进程从管道中接收数据。如果想实现双方通信，那么需要建立两个管道。

管道适合于**传输大量信息**。管道发送的内容是以字节为单位的，**没有格式的字节流**。

#### 创建管道

通过 `pipe()` 系统调用来创建并打开一个管道，当最后一个使用它的进程关闭对他的引用时，pipe 将自动撤销。

通过 `pipe()` 创建的是匿名管道，只能用于具有亲缘关系的进程之间（父子进程或兄弟进程）。

#### 管道的实现

**管道就是一个文件**，是一种只存在于内存中的特殊的文件系统。

在 Linux 中，管道借助了文件系统的 File 结构实现。父进程使用 File 结构保存向管道写入数据的例程地址，子进程保存从管道读出数据的例程地址。这解释了上文所说的：

1.  单向流动
2.  只能用于具有亲缘关系的进程之间

管道是由内核管理的一个缓冲区，缓冲区被设计成为环形的数据结构，以便管道可以被循环利用（循环队列）。

#### 管道的同步

管道是一个具有特定大小的缓冲区
- 操作系统会保证读写进程的同步
- 下游进程或者上游进程需要等另一方释放锁后才能操作管道。管道就相当于一个文件，同一时刻只能有一个进程访问
- 当管道为空时，下游进程读阻塞；当管道满时，上游进程写阻塞
- 管道不再被任何进程使用时，自动消失

#### 管道的读写

- 读操作
	- 有数据
		- read 正常读，返回读出的字节数
	- 无数据
		- 写端全部关闭
			- read解除阻塞，返回0，相当于读文件读到了尾部
		- 没有全部关闭
			- read阻塞
- 写操作
	- 读端全部关闭
		- 管道破裂，进程终止，内核给当前进程发SIGPIPE信号
	- 读端没全部关闭
		- 缓冲区写满了
			- write阻塞
		- 缓冲区没满
			- 继续write

若是读端设置为非阻塞
- 写端没有关闭，管道中没有数据可读，则read返回-1
- 写端没有关闭，管道中有数据可读，则read返回实际读到的字节数
- 写端已经关闭，管道中有数据可读，则read返回实际读到的字节数
- 写端已经关闭，管道中没有数据可读，则read返回0

### 命名管道

Linux 管道包含匿名管道和命名管道。上面说的是匿名管道，只能用在亲缘进程中，管道文件信息保存在内存里。

命名管道（FIFO）可用于没有亲缘的进程间。Pipe 和 FIFO 除了建立、打开、删除的方式不同外，二者几乎一模一样。

通过 `mknode()` 系统调用或者 `mkfifo()` 函数建立命名管道。一旦建立，任何有访问权的进程都可以通过文件名将其打开和进行读写，而不局限于父子进程。

建立命名管道时，会在磁盘中创建一个索引节点，命名管道的名字就相当于索引节点的文件名。索引节点设置了进程的访问权限，但是没有数据块。命名管道实质上也是通过**内核缓冲区**来实现数据传输。有访问权限的进程，可以通过磁盘的索引节点来读写这块缓冲区。

当不再被任何进程使用时，命名管道在内存中释放，但磁盘节点仍然存在。

### 信号量

信号量是一种特殊的变量，对它的操作都是原子的，有两种操作：V（`signal()`）和 P（`wait()`）。V 操作会增加信号量 S 的数值，P 操作会减少它。

-   V(S)：如果有其他进程因等待 S 而被挂起，就让它恢复运行，否则 S 加 1
-   P(S)：如果 S 为 0，则挂起进程，否则 S 减 1

P、V 来自于荷兰语：Probeer (try)、Verhoog (increment)。

如果信号量是一个任意的整数，通常被称为计数信号量（Counting semaphore），或一般信号量（general semaphore）；如果信号量只有二进制的 0 或 1，称为二进制信号量（binary semaphore）。在 Linux 系统中，二进制信号量又称互斥锁（Mutex）。信号量可以用于实现进程或线程的互斥和同步。

信号量在底层的实现是通过硬件提供的原子指令，如 `Test And Set`、`Compare And Swap` 等。比如 golang 实现互斥量就是使用了 `Compare And Swap` 指令（[github](https://github.com/golang/go/blob/master/src/sync/mutex.go#L72)）。

### 共享内存

共享内存顾名思义，允许两个或多个进程共享同一段物理内存。**不同进程可以将同一段共享内存映射到自己的地址空间，然后像访问正常内存一样访问它**。不同进程可以通过向共享内存端读写数据来交换信息。

一个进程可以通过操作系统的系统调用，创建一块共享内存区；其他进程通过系统调用把这段内存映射到自己的用户地址空间中；之后各个进程向读写正常内存一样，读写共享内存。共享内存区只会驻留在创建它的进程地址空间内。

**共享内存的优点是简单且高效**，访问共享内存区域和访问进程独有的内存区域一样**快**，原因是不需要系统调用，不涉及用户态到内核态的转换，也不需要对数据不必要的复制。

比如管道和消息队列，需要在内核和用户空间进行四次的数据拷贝（读输入文件、写到管道；读管道、写到输出文件），而共享内存则只拷贝两次：一次从输入文件到共享内存区，另一次从共享内存到输出文件（[图示](https://cloud.tencent.com/developer/article/1021157)）。此外，消息传递的实现经常采用系统调用，也就经常需要用户态和内核态互相转换；而共享内存只在建立共享内存区域时需要系统调用；一旦建立共享内存，所有访问都可作为常规内存访问，无需借助内核。

**共享内存的缺点是存在并发问题**，有可能出现多个进程修改同一块内存，因此共享内存一般与信号量结合使用。

Linux 的 2.2.x 内核支持多种共享内存方式，如 mmap() 系统调用，Posix 共享内存，以及系统 V 共享内存。

mmap() 系统调用的主要作用是将**普通文件**映射到进程的地址空间，然后可以像访问普通内存一样对文件进行访问，不必再调用 read()，write() 等操作。mmap() 不是专门用来共享内存的，但是多个进程可以通过 mmap() 映射同一个普通文件，来实现共享内存。

system V 则是通过映射**特殊文件**系统 shm 中的文件实现进程间的共享内存。通过 shmget 可以创建或获得共享内存的标识符。取得共享内存标识符后，通过 shmat 将这个内存区映射到本进程的虚拟地址空间。

有关 mmap() 系统调用、system V 共享内存的详细介绍，以及两者的对比，可以进一步查看这两篇文章：

### 消息队列

**消息队列是一个消息的链表**，保存在内核中。消息队列中的每个消息都是一个**数据块**，具有特定的格式。操作系统中可以存在多个消息队列，每个消息队列有唯一的 **key**，称为消息队列标识符。

消息队列**克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点**。和信号相比，消息队列能够传递更多的信息。与管道相比，消息队列提供了**有格式**的数据，但消息队列仍然有大小限制。

消息队列允许一个或多个进程向它写入与读取消息。消息的发送者和接收者不需要同时与消息队列交互。消息会保存在队列中，直到接收者取回它。也就是说，消息队列是**异步**的，但这也造成了一个缺点，就是接收者必须**轮询**消息队列，才能收到最近的消息。

操作系统提供创建消息队列、取消息、发消息等系统调用。

操作系统负责读写同步：若消息队列已满，则写消息进程排队等待；若取消息进程没有找到需要的消息，则在等待队列中寻找。

消息队列和管道相比，相同点在于二者都是通过发送-接收的方式进行通信，并且数据都有最大长度限制。不同点在于消息队列的数据是有格式的，并且**取消息进程可以选择接收特定类型的消息**，而不是像管道中那样默认全部接收。

与FIFO相比，消息队列的优点
- 消息队列可以独立于读写进程存在，从而避免了FIFO中同步管道的打开和关闭时可能产生的困难
- 避免了FIFO的同步阻塞问题，不需要进程自己提供同步方法
- 读进程可以根据消息类型有选择地接收消息，而不像FIFO那样只能默认地接收

特点：
- 消息队列是保存在内核中的消息链表，每个消息体都是固定大小的存储块。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除
- 如果没有释放消息体队列或者没有关闭操作系统，消息队列就会一直存在

缺点：
- 通信不及时，附件有大小限制
- 不适合比较大数据的传输，每个消息体都有一个最大长度的限制，同时所有队列包含的全部消息体的总长度也有上限
- 存在用户态与内核态之间的数据拷贝开销

### 套接字 Socket

- 不同的计算机的进程之间通过 socket 通信，_也可用于同一台计算机的不同进程_
- 需要通信的进程之间首先要各自创建一个 socket，**内容包括主机地址与端口号**，声明自己接收来自某端口地址的数据
- 进程通过 socket 把消息发送到网络层中，网络层通过主机地址将其发到目的主机，目的主机通过端口号发给对应进程

操作系统提供创建 socket、发送、接收的系统调用，为每个 socket 设置发送缓冲区、接收缓冲区。

### 进程通信与线程通信有什么不同



## 锁

- 互斥锁(mutex)：
	- 一次只能一个线程拥有互斥锁，其他线程只有等待
	- 互斥锁是抢锁失败的情况下主动放弃CPU进入睡眠状态直到锁的状态改变时再唤醒，而操作系统负责线程调度，为了实现锁的状态发生改变时唤醒阻塞的线程或者进程，需要把锁交给操作系统管理，所以互斥锁在加锁操作时涉及上下文切换。互斥锁实际的效率还可以接受，加锁的时间大概100ns左右
	- 实际上互斥锁的一种可能的实现是先自旋一段时间，当自旋的时间超过阈值之后再将线程投入睡眠中，因此在并发运算中使用互斥锁（每次占用锁的时间很短）的效果不亚于自旋锁。
	- 互斥锁的开销主要体现在线程的**重新调度**和**上下文切换**上，获取锁的开销是比较大的，因此mutex适用于线程**持有锁时间比较长**的场景。
- 读写锁：
	- 多个读者可以同时进行读
	- 写者必须互斥
	- 写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）
- 自旋锁(spinlock)：
	- 如果进线程无法取得锁，进程不会立即放弃CPU时间片，而是一直循环尝试获取锁，直到获取为止。如果别的线程长期占有锁，那么自旋锁就是在浪费CPU做无用功，但是自旋锁一般应用于加锁时间很短的场景，这个时候效率比较高
	- 优点：避免了操作系统的**重新调度**和**上下文切换**的开销
	- 缺点：在单处理器的场景下，如果锁已经被另一个线程持有，那么当前线程在尝试加锁时需要将整个时间片空转完毕。除非发生上下文切换，否则它是不可能获取到锁的，自旋锁可能会导致**饥饿**
	- 自旋锁的性能在多处理器的场景下不单处理器更好
- 条件锁：
	- 条件变量允许线程阻塞和等待另一个线程发送信号的方法弥补了互斥锁只有锁定与非锁定两种状态的不足
	- 当某些执行状态不满足时，线程可以把自己加入队列，等待该条件
	- 条件变量常和互斥锁一起使用，以免出现竞态条件。当条件不满足的时候，线程往往解开相应的互斥锁并阻塞线程然后等待条件发生变化。一旦其他的某个线程改变了条件变量，它将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程。
	- 总的来说，互斥锁是线程间互斥的机制，条件变量则是同步机制。
- 自适应锁：
	- 先执行自旋锁，不断持续尝试获取锁，如果尝试多次还是获取不到，就执行mutex操作，让线程进入睡眠

![[Pasted image 20221110155612.png]]

### 互斥锁，信号量的使用场景

### 信号量与互斥锁解决父子线程同时阻塞的区别

### 怎么实现自旋锁

### 锁的可重入与不可重入

## 死锁以及怎么解决死锁

### 死锁产生的四个条件

- 互斥：进程对所需求的资源具有排他性，若有其他进程请求该资源，请求进程只能等待
- 非抢占：进程在所获得的资源未释放之前，不能被其他进程强行夺走，只能自己释放
- 持有并等待：进程持有了资源，同时又在等待其他资源
- 循环等待：进程之间存在一个环路，环路上的每个线程都额外持有一个资源，而这个资源又是下一个线程要申请的

### 死锁预防

破坏上面四个条件的任意一个，但是很难实现

- 破坏互斥条件：允许某些资源同时被多个进程访问。但是==有些资源本身并不具有这种属性==，因此本方案实用性有限。
- 破坏非抢占条件：允许进程强行抢占被其他进程占有的资源，会降低系统的性能
- 破坏持有并等待条件：
	- 实行资源预先分配策略（当一个进程开始运行之前，必须一次性想系统申请他所需的全部资源，否则不运行）
	- 只允许进程在没有占用资源的时候才能申请资源（申请资源前先释放占有的资源）
	- 缺点：很多时候无法预知一个进程所需的全部资；同时，会降低资源利用率，降低系统并发性
- 破坏循环等待条件：对所有的资源统一编号，所有进程对资源的请求必须按照序号递增的顺序提出，即只有占有了编号较小的资源才能申请编号较大的资源。这样避免了占有大号资源的进程去申请小号资源，各个进程申请资源的顺序是从小到大的，就不会有环了

### 死锁避免

允许系统同时存在四个必要条件，但是每当进程提出资源申请时，系统要分析满足该资源请求后，系统是否会发生死锁，若不发生则实施分配。银行家算法实现了这个过程


### 死锁检测

画出资源分配图，检测是否存在环路。检测环路前要将资源分配图化简，化简的原理是"一个目前占有运行所需的资源的进程，迟早能够执行完成释放资源"。因此可以从"进程-资源分配图"中找到一个既不阻塞又非孤立的进程，删除所有与该进程相连的有向边，回收资源，使之成为孤立节点，然后将所回收的资源分配给其它进程。循环此过程，直到无法化简。若仍存在环路，则该系统目前处于死锁状态。

检测到死锁后，需要解除死锁。

### 死锁解除

破坏除了"互斥条件"之外的三个条件
- 回退执行：系统定期对各个进程进行检查，将检查点的有关信息写入文件。死锁时，让某占有必要资源的进程回退到取得资源之前的一个检查点，释放的资源分配给一个死锁进程（破坏"占有且等待"）
- 抢占资源：剥夺占有进程的资源，分配给另外某些进程，直至死锁环路被打破（破坏"不可抢占"）
- 杀掉进程：一次终止一个进程，直至消除死锁环路（破坏"循环等待")

### 如何发现程序中的死锁

## 物理内存管理
### 操作系统在对内存进行管理的时候需要做些什么

- 操作系统负责内存空间的分配与回收。
- 操作系统需要提供某种技术从逻辑上对内存空间进行扩充。
- 操作系统需要提供地址转换功能，负责程序的逻辑地址与物理地址的转换。
- 操作系统需要提供内存保护功能。保证各进程在各自存储空间内运行，互不干扰

内部碎片：由固定分区法产生，指被占用分区上未被利用的空间，由于该分区被占用，因此无法被分配使用
外部碎片：由动态分区法产生，指被占用分区之间的小空间，虽然可以被使用，但是由于太小而无法被分配

### 为什么分段式存储管理有外部碎片而无内部碎片，固定分区分配有内部碎片而不会有外部碎片

#### 分段式存储管理有外部碎片而无内部碎片

分段式是按需分配, 所以不存在内部碎片

而已分配的内存回收时由于部分进程还在运行, 导致回收的内存可能不会连续, 再继续分配内存时就可能产生了无法利用的小内存,就是外部碎片

内存总量相同，100M，比如，内存分配依次5M，15M，50M，25M，程序运行一段时间之后，5M，15M的程序运行完毕，释放内存，其他程序还在运行，再次分配一个10M的内存供其它程序使用，只能从头开始分片，这样，就会存在10M+5M的外部碎片

#### 为什么固定分区分配有内部碎片而不会有外部碎片

固定分配可能会多分内存

固定分配，将100M分割成10块，每块10M，一个程序需要45M，那么需要分配5块，第五块只用了5M，剩下的5M就是内部碎片；

由于固定分配, **那么释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存。并且可以分配非连续的地址空间**

### 如何消除碎片文件

对于外部碎片，通过紧凑技术消除，就是操作系统不时地对进程进行移动和整理。但是这需要动态重定位寄存器地支持，且相对费时。紧凑地过程实际上类似于Windows系统中地磁盘整理程序，只不过后者是对外存空间地紧凑

解决外部内存碎片的问题就是内存交换。

可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。

回收内存时要尽可能地将相邻的空闲空间合并。

### 不同的内存分配技术及其优缺点
#### 等长固定分区法

每个分区的大小相同，在系统启动时分配好，系统运行期间保持不变；每次给进程分配一整块区域，因此进程的大小必须小于等于分区的大小

- 优点：系统需要维护的管理信息非常少，只要维护一个固定行数的表格，记载分区的使用情况；内存分配算法很简单，有足够大的空闲分区就分配，否则就拒绝
- 缺点：不童锦程需要的空间不同，内部碎片多，浪费空间；分区总数固定，限制了并发执行的程序数量

#### 不等长固定分区法

每个分区大小不同，当系统启动时分配好，系统运行期间保持不变；分配时，需要根据进程的大小在空闲分区中选择一个大小合适的分区

优缺点同上

#### 动态分区法

在系统运行中，根据每个进程需要的空间大小确定分区大小；通过空闲分区链表进行组织

- 优点：并发执行的程序数量不受限制，只取决于是否有大小合适的内存块可以分配
- 缺点：管理空闲块的复杂度增加；分配算法的时间开销增加，可能需要遍历多次才能找到合适的内存块

#### 页式内存管理

把固定分区面积缩小，一个进程可以使用多个分区；进程被分割成若干个块，装入内存中的几个分区中，物理上无需相连，逻辑上通过页表关联。这是一种内存的不连续分配方法

优点：不存在任何外部碎片，只在每个进程的最后一个页框中存在内部碎片

https://www.cnblogs.com/edisonchou/p/5115242.html

#### 段页式内存管理

把分段和分页两种方式结合，先把程序按照逻辑意义分成段，然后每个段再分成固定大小的页

### 不同的动态分区放置算法及其优缺点
#### 最佳适应算法

-   检查所有空闲分区，选择和新进程申请内存大小最接近的空闲分区
-   优点：该算法保留大的空闲区
-   缺点
    - 检查所有空闲分区需要时间
    - 外部碎片多：会留下许多难以利用的，很小的空闲分区，称为外部碎片
    - 可以采用内存紧凑的方法，将被使用的分区都移动到一起，减少外部碎片。但是移动内存中的代码和数据也需要很多时间

#### 最差适应算法

- 每次为进程分配分区时，都选择最大的空闲分区分配
- 最差适应算法使链表中的结点大小趋于均匀，适用于请求分配的内存大小范围较窄的系统
- 优点：该算法保留小的空闲区，尽量减少外部碎片的产生
- 缺点：检查比较所有的空闲区间需要时间；系统中不会存在面积很大的空闲区间，难满足大进程的要求

#### 首次适应算法

- 只要发现能用的分区就分配。这种方法目的在于减少查找时间。为适应这种算法，空闲分区表（空闲区链）中的空闲分区要按地址由低到高进行排序。该算法优先使用低址部分空闲区，在低址空间造成许多小的空闲区，在高地址空间保留大的空闲区
- 优点：可以剩下大的分区
- 缺点：外部碎片多，集中在低址部分；并且每次查找都是从低址部分开始的，这无疑又会增加查找可用空闲分区时的开销

#### 下一个适应法

- 由于上面的放置算法每次都需要从头检查，有可能浪费很多时间。因此“下一个适应法”就是操作系统记住接下来该检查的空闲分区的位置，给进程分配分区时，系统从记录的分区开始依次向后查找直到碰到能用的分区为止，如果到链表尾还没有找到，就再从头开始
- 缺点：上面的三个放置算法都是按照分区大小来分配，或是留下大区间（首次适应，最佳适应），或是留下小区间（最差适应）。下一个适应法很难剩下面积很大的区间，会使剩余分区的大小比较平均

## 虚拟内存管理
### 虚拟内存的目的

1. 虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。**（64位128T，32位3G）**
2. 每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的。这就解决了多进程之间地址冲突的问题。
3. 页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。

### 虚拟内存的思想 / 实现方式

- 在系统中为每个程序定义一个虚拟地址空间，虚拟地址空间中的地址都是连续的
- 虚拟地址空间被分割成多个块，每块称为一个页或者页面
- 物理内存被分成和页面大小相同的多个区域，称作页框
- 程序加载时，可将任意一个页面放入内存中的任意一个页框
- CPU的硬件负责将虚拟地址映射到物理内存中的地址(页面 -> 页框)
- 程序的整个地址空间无需全部载入物理内存，还有部分暂时存储在外存上，需要时再换入内存
- 如果程序引用到一部分不在物理内存中的虚拟地址时，会发生缺页中断，由操作系统负责将缺失的页面载入页框，并重新执行失败的指令

![[Pasted image 20221116101328.png]]

### 暂时不在内存中的数据存在哪里

存储在交换分区[swap](https://wiki.archlinux.org/title/Swap_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87))中，当内存不足时，操作系统先把内存中暂时不用的数据，存储到硬盘的交换空间，释放内存空间。

### 虚拟地址的映射

页表：每个进程有一个页表，描述该进程每个页面对应的页框号，以及该页面是否已经被载入内存("在/不在"位)。以下是一个进程的页表和地址映射过程的示意图

![[Pasted image 20221116102023.png]]

- 一个完整的页表表项包含一下内容
	- 页框号
	- 存在位：页面是否在内存中
	- 访问位：页面是否已被访问，影响页面淘汰选择
	- 修改位：页面是否被修改，修改过的页面需要重新写回外存
	- ...
	- 页面号：在页表中的下标，修改过的页面需要重新写回外存

进程在运行时，需要将页表放在内存中。但在虚拟地址空间很大的情况下，会被分成很多个页面，那么进程的页表将占据很大的内存空间，甚至无法全部载入内存。

针对大内存的页表实现方式：

1. 多级页表：将页表进一步分页，页目录表相当于"页表的页表"，记录每个内内层页表存放在哪个页框中；内层页表依然记录进程的每个页面存放在哪个页框中，以下是一个多级页表的示意图

![[Pasted image 20221116102608.png]]

2. 倒排页表：不再为每个进程记录页面到页框的映射，而是记录每个页框对应的(进程号，页面号)二元组。整个操作系统只需要一个倒排页表，节省了大量空间。但他必须遍历整个页表才能找到某个表项，无法将页面号当做索引直接找到页框号

![[Pasted image 20221116102848.png]]

3. 散列表：为了节省页表空间，同时加速查找过程，可以将当前进程的所有在内存中的页面建立一张散列表。用每个页面的虚拟地址来散列，相同散列值的元素会被链接到一起，每个元素包含三项内容：页面号、页框号、指向链表下一个元素的指针

![[Pasted image 20221116103110.png]]

### TLB的原理

现代操作系统中，页表的个数是很多的，而每次执行语句时都需要先查找页表，将虚拟地址转换为物理内存地址。这部分切换的时间开销是很大的。因此，解决方案是为计算机设置一个小型的硬件设备TLB。

转换检测缓冲区(TLB)，是MMU(内存管理单元)的一部分。他提供一个缓冲区，记录虚拟页面号到物理页框的映射，这样可以在O(1)的时间里直接将虚拟页面映射到物理页框，不需要访问页表，从而节省时间

工作流程：如果页面号在TLB中，得到页框号，访问内存；否则，从内存中的页表得到页框号，将其存入TLB，访问内存。

TLB基于局部性原理的实现：
- 空间局部性：如果程序访问了地址 x，那么很有可能访问地址 x 附近的地址
- 时间局部性：如果程序访问了地址 x，很可能立刻又访问 x

### 什么时候会发生缺页中断

### 缺页中断的处理

应用程序访问未加载到内存中的页面时，会引起缺页中断。操作系统会将缺失的页面加载入页框中，然后重新执行引起异常的指令。

缺页中断更准确地说，应当是"缺页异常"。异常执行当前指令产生的错误情况，中断则是外部硬件产生的事件。

### 页面淘汰

当内存空间已被占满而又要调入新的页面时，必须将已在内存中的某个页面淘汰掉。如果被淘汰的页面曾被修改过，还要将此页写回到外存，再换进新的页面。这一过程称为**页面淘汰**。

如果某个页面频繁的被“调入-淘汰-调入-淘汰”，这种现象称为**抖动**。抖动导致系统将大部分时间花在了页面的置换上，因此在淘汰时，要选择今后不会或者最近不会用到的内容，以减少抖动。

### 不同的淘汰算法及其适用场景

根据具体的应用场景，选择合适的淘汰算法。除了操作系统的页面置换，redis 中也经常用到各种内存淘汰算法，往往需要结合具体业务场景来选择。

以下是几种常见的淘汰算法：

1. 最佳置换算法 / 最优策略（OPT）：选择以后再也不会用到的页面淘汰；如果都会用到，就选择那些再次使用的时间距离现在最远的页面淘汰。这是一种理想情况下的页面置换算法，实际上不可能实现。可以作为评测其他淘汰策略的标准。

2. 先进先出法（FIFO）：直接换出最早装入的页面。
    - 优点：简单
    - 缺点：性能不是很好，因为它淘汰的可能是常用的页面
    - 适用场景：数据只用一次，将来不太可能使用；[redis] 对数据时效性有要求（越旧的缓存越先被淘汰）

3. 第二次机会置换法（SCR：Second Chance Replacement）：对 FIFO 算法的改进，每个页面访问 2 次后再淘汰。具体实现上，设置页面访问位，每次检查队首的页面访问位：如果该位为 0，淘汰该页；如果该位为 1，将该位设为 0，将其移到队尾，看成新装入的页。
	- 优点：一定程度上，避免把经常使用的页面置换出去

![16013705538675.jpg](https://imageslr.com/media/16013705538675.jpg)

4. 时钟置换法（Clock）：对第二次机会置换法的改进。第二次机会置换法需要在链表中移动页面，而时钟置换法将页面保存在环形链表中，只需要后移队头指针，就相当于是把原来的队头放到队尾了。
	-   优点：避免了移动链表节点的开销

![[Pasted image 20221116110822.png]]

5. 最近最少使用法（LRU：Least Recently Used）：优先淘汰最久未被访问的页面。根据局部性原理，一个进程在一段时间内要访问的指令和数据都集中在一起。如果一个页面很久没有被访问，那么将来被访问的可能性也比较小。
    - 优点：实验证明 LRU 的性能较好，能够降低置换频率
    - 缺点：存在**缓存污染**问题，即由于偶发性或周期性的冷数据批量查询，热点数据被挤出去，导致缓存命中率下降
    - 适用场景：访问分布未知的情况；[redis] 要求热点数据有效；[redis] 应用对缓存的访问符合二八定律 / [幂律分布](http://wiki.swarma.net/index.php/%E5%B9%82%E5%BE%8B%E5%88%86%E5%B8%83)

6. LRU-K：LRU-K 算法的核心思想是将“最近使用过 1 次”的判断标准扩展为“最近使用过 K 次”，LRU 可以认为是 LRU-1。能够降低“缓存污染”的问题。

7. 最近最不经常使用法（LFU：Least Frequently Used）：优先淘汰最近访问频率最少的数据。
    - 优点：能够避免缓存污染问题对 LRU 的命中影响
    - 缺点：存在**访问模式问题**，即如果访问内容发生较大变化，LFU 需要用更长的时间来适应，导致缓存命中率下降；维护相关数据结构的开销大
    -   适用场景：[redis] 数据的访问模式固定

8.  随机淘汰法（Random）：实现简单，不需要保留有关访问历史记录的任何信息
    -   适用场景：[redis] 如果应用对于缓存 key 的访问概率相等，则可以使用这个算法

操作系统常用的是 LRU 算法；一般数据的访问模式是随时间变化的，所以大多数的缓存也都是使用 LRU 算法或其变种。还有一些其他算法如 MRU、SLRU 等，见[维基百科](https://en.wikipedia.org/wiki/Cache_replacement_policies)。

### 内存回收

如果没有空闲的物理内存，那么内核就会开始进行**回收内存**的工作，回收的方式主要是两种：直接内存回收和后台内存回收。

- **后台内存回收**（kswapd）：在物理内存紧张的时候，会唤醒 kswapd **内核线程**来回收内存，这个回收内存的过程**异步**的，不会阻塞进程的执行。
- **直接内存回收**（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是**同步**的，会阻塞进程的执行。

如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——**触发 OOM （Out of Memory）机制**。

OOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。

#### 哪些内存可以回收

主要有两类内存可以被回收，而且它们的回收方式也不同。（LRU算法）

- **文件页**（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，**回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存**。
- **匿名页**（Anonymous Page）：应用程序通过 mmap 动态分配的堆内存叫作匿名页，这部分内存很可能还要再次被访问，所以不能直接释放内存，它们**回收的方式是通过 Linux 的 Swap 机制**，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。

#### 内存回收的影响

在前面我们知道了回收内存有两种方式。

- 一种是后台内存回收，也就是唤醒 kswapd 内核线程，这种方式是异步回收的，不会阻塞进程。
- 一种是直接内存回收，这种方式是同步回收的，会阻塞进程，这样就会造成很长时间的延迟，以及系统的 CPU 利用率会升高，最终引起系统负荷飙高。

可被回收的内存类型有文件页和匿名页：
- 文件页的回收：对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，这个操作会发生磁盘 I/O 的，这个操作是会影响系统性能的。
- 匿名页的回收：如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。

可以看到，回收内存的操作基本都会发生磁盘 I/O 的，如果回收内存的操作很频繁，意味着磁盘 I/O 次数会很多，这个过程势必会影响系统的性能，整个系统给人的感觉就是很卡。

### 分页分段的区别

- 段是信息的逻辑单位，是根据用户的需要进行划分的，因此段对用户是可见的；页是信息的物理单位，是为了管理主存的方便而划分的，对用户是透明的。
- 段的大小不固定，由它所完成的功能决定，页大小固定，由系统决定
- 段向用户提供二维地址空间，页向用户提供一维地址空间。
- 段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制。

## 虚拟地址空间的组成部分
### 虚拟地址空间的组成部分

整体上，操作系统将每个进程的虚拟地址空间划分成两个部分：内核空间和用户空间。内核空间存放的是内核代码和数据，用户空间存放的是用户程序的代码和数据。在32位操作系统中，一般是将最高的1G字节作为内核空间，而将较低的3G字节作为用户空间。

进程运行在内核空间时，处于内核态，此时可以执行任何特权指令。每个进程的内核空间都是相同的，用户代码无法访问内核空间。

虚拟地址空间的完整组成
![[Pasted image 20221116142838.png]]

从上往下依次是：
- 内核虚拟内存：所有进程共享内核的代码和全局数据结构，独享与进程相关的数据结构，Linux会将内核虚拟内存的共享区域映射到被所有进程共享的物理页面上
- 用户栈：从高地址向低地址增长
- 共享库：动态链接阶段
- 运行时堆：从低地址向高地址增长
- 程序代码和数据：从可执行文件中加载(代码段、数据段、BSS段)

### 栈

用户栈起始就是函数调用栈，作用主要是：
- 保存函数的局部变量
- 保存某些寄存器的值
- 向被调用函数传递参数
- 返回函数的返回值
- 保存函数的返回值

每个函数在执行过程中都需要使用一块栈内存用来保存上述这些值，这块栈内存为该函数的栈帧。栈的增长和收缩由编译器插入的代码自动完成，随着函数的调用而分配，随函数的返回而自动释放。程序员无需关心，这一点与堆不同

### 堆

栈内存的分配需要实现确定其大小，而堆内存允许程序在运行时动态申请某个大小的内存空间。申请的内存在函数退出后仍然保留，需要手动释放。C语言中的`malloc/free`就是从堆中分配/释放内存，操作系统通过一个记录空闲内存地址的链表来管理堆内存

如果反复向操作系统申请内存而不释放，会导致内存泄露。在C/C++中，必须由程序员手动释放堆内存。而JAVA/Golang中有垃圾回收期，会定期主动回收内存。但是即使有垃圾回收器，也有内存泄露的分险，比如长期持有某个大对象的引用。

### 堆与栈的区别

1. 增长方向：栈向低地址方向增长，堆向高地址方向增长
2. 申请回收：栈自动分配和回收，堆需要手动申请和释放
3. 生命周期：栈的数据仅存在于函数运行过程中，堆的数据只要不释放就一直存在
4. 连续分配：栈是连续分配的，堆是不连续分配的，很容易产生内存碎片
5. 空间大小：栈的大小是有限的，而堆的空间较大，受限于系统中有效的虚拟内存

### 从堆和栈上建立对象哪个快

从两方面来考虑：
- 分配和释放，堆在分配和释放时都要调用函数（malloc,free)，比如分配时会到堆空间去寻找足够大小的空间（因为多次分配释放后会造成内存碎片），这些都会花费一定的时间，具体可以看看malloc和free的源代码，函数做了很多额外的工作，而栈却不需要这些。
- 访问时间，访问堆的一个具体单元，需要两次访问内存，第一次得取得指针，第二次才是真正的数据，而栈只需访问一次。另外，堆的内容被操作系统交换到外存的概率比栈大，栈一般是不会被交换出去的。

## 缓冲区溢出
### 什么是缓冲区溢出

C语言使用运行时栈来存储过程信息，每个函数的信息存储在一个栈帧中，包括寄存器、局部变量、参数、返回地址等。C对于数组引用不进行任何边界检查，因此**对越界的数组元素的写操作会破坏存储在栈中的状态信息**，这种现象称为缓冲区溢出。

![[Pasted image 20221116145445.png]]
### 缓冲区溢出的攻击方式

缓冲区溢出会破坏程序运行，也可以被用来进行攻击计算机，如使用一个指向攻击代码的指针覆盖返回地址。

![16017013835258.jpg](https://imageslr.com/media/16017013835258.jpg)

### 缓冲区溢出攻击的防范方法

#### 随机化

使用缓冲区溢出进行攻击，需要知道攻击代码的地址。因此常见的防范方法有：

1. 栈随机化：程序开始时在栈上分配一段随机大小的空间
2. 地址空间布局随机化（Address-Space Layout Randomization，ASLR）：每次运行时程序的不同部分，包括代码段、数据段、栈、堆等都会被加载到内存空间的不同区域

但是攻击者依然可以使用蛮力克服随机化，这种方式称为“空操作雪橇（nop sled）”，即在实际的攻击代码前插入很长的一段 nop 指令序列，执行这条指令只会移动到下一条指令。因此只要攻击者能够猜中这段序列的某个地址，程序就会最终经过这段序列，到达攻击代码。

因此栈随机化和 ASLR 只能增加攻击一个系统的难度，**但不能完全保证安全**。

#### 栈保护

在发生缓冲区溢出、造成任何有害结果之前，尝试检测到它。常见的栈破坏检测方法是栈保护机制：在每个函数的栈帧的局部变量和栈状态之间存储一个**随机产生的**特殊的值，称为金丝雀值（canary）。在恢复寄存器状态和函数返回之前，程序检测这个金丝雀值是否被改变了，如果是，那么程序异常终止。

![[Pasted image 20221116145831.png]]

#### 限制可执行代码区域

内存页的访问形式有三种：可读、可写、可执行。只有编译器产生的那部分代码所处的内存才是可执行的，其他页应当限制为只允许读和写。以前 x86 将读和执行视为一个标志位，可读就可执行，为了限制某些页可读但不可执行，往往会带来严重的性能损失。现在新的处理器在硬件上引入新的位，将读和执行分开，由硬件来检查页是否可执行，效率上没有损失。

## I/O 模型
### 五种 I/O 模式

https://imageslr.com/2020/02/27/select-poll-epoll.html

阻塞 I/O、非阻塞 I/O、信号驱动式 I/O、I/O 多路复用、异步 I/O(aio)

**I/O 同步与异步的区别**：将数据从内核复制到用户空间时，用户进程是否会阻塞（需要用户进程来完成）
**I/O 阻塞与非阻塞的区别**：进程发起系统调用后，是会被挂起直到收到数据后再返回、还是立即返回成功或错误

![[Pasted image 20221109203537.png]]

### 阻塞 I/O 到 I/O 多路复用

**阻塞 I/O**：进程发起调用后，会被挂起，直到收到数据再返回。如果调用一直不反悔，进程就会一直被挂起。因此，当使用阻塞 I/O 时，需要使用多线程来处理多个文件描述符。
多线程切换会有一定的开销，因此引入非阻塞 I/O。非阻塞 I/O 不会将进程挂起，调用时会立即返回成功或错误，因此可以在一个线程轮询多个文件描述符是否就绪

阻塞等待的是内核数据准备好和数据从内核态拷贝到用户态的这两个过程

**非阻塞I/O**：非阻塞的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区，read 调用才可以获取到结果

最后一次 read 调用，获取数据的过程，是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓冲区的这个过程。

**非阻塞 I/O 的缺点**：每次发起系统调用，只能检查一个文件描述符是否就绪。当文件描述符很多时，系统调用的成本很高。

因此引入了 **I/O 多路复用**，可以通过一次系统调用，检查多个文件描述符的状态。这是 I/O 多路复用的主要优点，相比于非阻塞 I/O，在文件描述符较多的场景下，避免了频繁的用户态和内核态的切换，减少了系统调用的开销。

> I/O 多路复用相当于将遍历所有文件描述符、通过非阻塞 I/O 查看其是否就绪的过程从用户线程已到了内核中，由内核来负责轮询。

进程可以通过 select、poll、epoll 发起 I/O 多路复用的系统调用，这些系统调用都是同步阻塞的：**如果传入的多个文件描述符中，有描述符就绪，则返回就绪的描述符；否则如果所有文件描述符都未就绪，就阻塞调用进程，直到某个描述符就绪，或者阻塞时长超过设置的 timeout 后，再返回**。I/O 多路复用内部使用*非阻塞 I/O*检查每个描述符的就绪状态。

如果 `timeout` 参数设为 NULL，会无限阻塞直到某个描述符就绪；如果 `timeout` 参数设为 0，会立即返回，不阻塞。

I/O 多路复用引入了一些额外的操作和开销，性能更差。但是好处是用户可以在一个线程内同时处理多个 I/O 请求。如果不采用 I/O 多路复用，则必须通过多线程的方式，每个线程处理一个 I/O 请求。后者线程切换也是有一定的开销的。

**异步I/O**：内核数据准备好和数据从内核态拷贝到用户态这两个过程都不用等待。

### aio的优缺点

### aio是半异步模式还是全异步模式

### 什么是文件描述符fd

文件描述符是一个非负整数，从0开始。进程使用文件描述符来标识一个打开的文件。

系统为每一个进程维护一个文件描述符表，表示该进程打开文件的记录表，而**文件描述符实际上就是这张表的索引**。当进程打开或者新建文件时，内核会在该进程的文件列表中新增一个表项，同时返回一个文件描述符--也就是新增表项的下标。

一般来说，每个进程最多可以打开64个文件。在不同的系统上，最多允许打开的文件个数不同，Linux2.4.22强制规定最多不能超过1048576

### fd_set 文件描述符集合

fd_set类型表示文件描述符的集合

由于文件描述符fd是一个从0开始的无符号整数，所以可以使用fd_set的二进制每一位来表示一个文件描述符。某一位为1，表示对应的文件描述符已就绪。



## 协程

协程是一个用户态的线程，用户在堆上模拟出协程的栈空间。当需要进行协程上下文切换的时候，主线程只需要交换栈空间和恢复协程的一些相关的寄存器的状态，就可以实现上下文切换。没有了从用户态到内核态的切换成本，协程的执行也就更加高效了。

## 写时复制

也称为隐式共享。COW将复制操作推迟到第一次写入时进行：在创建一个新副本时，不会立即复制资源，而是共享原始副本的资源；当修改时再执行复制操作。通过这种方式共享资源，可以显著减少创建副本时的开销，以及节省资源；同时资源修改操作会增加少量开销。

### 为什么需要写时复制

当通过 `fork()` 来创建一个子进程时，操作系统需要将父进程虚拟内存空间中的大部分内容全部复制到子进程中（主要是数据段、堆、栈；代码段共享）。这个操作不仅非常耗时，而且会浪费大量物理内存。特别是如果程序在进程复制后立刻使用 `exec` 加载新程序，那么负面效应会更严重，相当于之前进行的复制操作是完全多余的。

因此引入了写时复制技术。内核不会复制进程的整个地址空间，而是只复制其页表，`fork` 之后的父子进程的地址空间指向同样的物理内存页。

但是不同进程的内存空间应当是**私有**的。假如所有进程都只读取其内存页，那么就可以继续共享物理内存中的同一个副本；然而只要有一个进程试图写入共享区域的某个页面，那么就会为这个进程创建该页面的一个新副本。

写时复制技术将内存页的复制延迟到第一次写入时，更重要的是，在很多情况下不需要复制。这节省了大量时间，充分使用了稀有的物理内存。

### 写时复制实现原理

`fork()` 之后，内核会把父进程的所有内存页都标记为**只读**。一旦其中一个进程尝试写入某个内存页，就会触发一个保护故障（缺页异常），此时会陷入内核。

内核将拦截写入，并为尝试写入的进程创建这个页面的一个**新副本**，恢复这个页面的**可写权限**，然后重新执行这个写操作，这时就可以正常执行了。

![[Pasted image 20221117100754.png]]

内核会保留每个内存页面的引用数。每次复制某个页面后，该页面的引用数减少一；如果该页面只有一个引用，就可以跳过分配，直接修改。

这种分配过程对于进程来说是透明的，能够确保一个进程的内存更改在另一进程中不可见。

### 优缺点

优点：减少不必要的资源分配，节省宝贵的物理内存。

缺点：如果在子进程存在期间发生了大量写操作，那么会频繁地产生页面错误，不断陷入内核，复制页面。这反而会降低效率。

## 直接内存访问(DMA)

没有DMA，CPU需要参与搬运数据，从磁盘到内核态的缓冲区

DMA：在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU就可以去处理别的事务。

## 零拷贝

没有在内存层面去拷贝数据，即全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。

### 传统的文件 I/O

- 需要**4 次用户态与内核态的上下文切换**。发生了两次系统调用，一次是 `read()` ，一次是 `write()`，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。    
- 需要4 次数据拷贝，其中两次是 DMA 的拷贝（磁盘和内核缓冲区之间），另外两次则是通过 CPU 拷贝的（内核缓冲区和用户缓冲区）

![[Pasted image 20221129094023.png]]

### 零拷贝实现方式
#### mmap + write

在前面我们知道，`read()` 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，于是为了减少这一步开销，我们可以用 `mmap()` 替换 `read()` 系统调用函数。mmap直接将文件映射，不需要用read读。

- 应用进程调用了 `mmap()` 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；
- 应用进程再调用 `write()`，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；
- 最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。

我们可以得知，通过使用 `mmap()` 来代替 `read()`， 可以减少一次数据拷贝的过程。**仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次。**

![[Pasted image 20221129094320.png]]


#### sendfile

```Apache
#include <sys/socket.h>
ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
```

前两个参数分别是目的端和源端的文件描述符，它可以替代前面的 `read()` 和 `write()` 这两个系统调用，这样就可以**减少一次系统调用，也就减少了 2 次上下文切换的开销。**

可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。

![[Pasted image 20221129094652.png]]

#### SG-DMA

如果网卡支持 SG-DMA（_The Scatter-Gather Direct Memory Access_）技术（和普通的 DMA 有所不同），我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程

`sendfile()` 系统调用的过程发生了点变化，具体过程如下：
- 第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；
- 第二步，将内核空间的读缓冲区中对应的数据描述信息(内存地址、地址偏移量)记录到相应的 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以根据内存地址、地址偏移量直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；

2次上下文切换、0次CPU拷贝、2次DMA拷贝

![[Pasted image 20221129094813.png]]

#### splice

在内核空间的读缓冲区和网络缓冲区之间建立管道，从而避免了两者之间的CPU拷贝操作，2次上下文切换，0次CPU拷贝以及2次DMA拷贝。

![](https://pic4.zhimg.com/v2-437bf99c54a064faedb89a680ab3e0c3_r.jpg)
![](blob:https://vl67qv51dr.feishu.cn/bf9d3c06-2e3e-489c-94e9-88f3822f9f06)

## PageCache

磁盘文件数据拷贝「内核缓冲区」里，这个「**内核缓冲区**」实际上是**磁盘高速缓存（**_**PageCache**_**）。**

PageCache 来**缓存最近被访问的数据**，当空间不足时淘汰最久未被访问的缓存。

读磁盘数据的时候，优先在 PageCache 找，如果数据存在则可以直接返回；如果没有，则从磁盘中读取，然后缓存 PageCache 中。

**PageCache 使用了「预读功能」。**
**但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，那就白白浪费 DMA 多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能。**因为大文件很快就占满了PageCache

### 大文件传输方式

**在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术。**

> 绕开 PageCache 的 I/O 叫直接 I/O，使用 PageCache 的 I/O 则叫非直接 I/O。通常，对于磁盘，异步 I/O 只支持直接 I/O。

## 内存的交换与覆盖
### 内存的覆盖是什么，有什么特点

由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序），因此可以把用户空间分成为一个固定区和若干个覆盖区。将经常活跃的部分放在固定区，其余部分按照调用关系分段，首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统将其调入覆盖区，替换覆盖区中原有的段。

**覆盖技术的特点**：是打破了必须将一个进程的全部信息装入内存后才能运行的限制，但当同时运行程序的代码量大于主存时仍不能运行，再而，大家要注意到，内存中能够更新的地方只有覆盖区的段，不在覆盖区的段会常驻内存。

### 内存交换是什么，有什么特点

交换(对换)技术的设计思想：内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已具备运行条件的进程换入内存(进程在内存与磁盘间动态调度)

换入：操作系统把硬盘上的内存页写入到内存中

换出：操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上。

内存交换用于不同程序之间

### 什么时候会进行内存交换

内存交换通常在许多进程运行且内存吃紧时进行，而系统负荷降低就暂停。例如:在发现许多进程运行时经常发生缺页，就说明内存紧张，此时可以换出一些进程；如果缺页率明显下降，就可以暂停换出。

### 内存交换与覆盖的区别

交换技术主要是在不同进程(或作业)之间进行，而覆盖则用于同一程序或进程中

### 内存交换中，被换出的进程保存在哪里

保存在磁盘中，也就是外存中。具有对换功能的操作系统中，通常把磁盘空间分为文件区和对换区两部分。

文件区主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理采用离散分配方式;

对换区空间只占磁盘空间的小部分，被换出的进程数据就存放在对换区。由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理主要追求换入换出速度，因此通常对换区采用连续分配方式(学过文件管理章节后即可理解)。总之，对换区的I/O速度比文件区的更快。

### 在发生内存交换时，有哪些进程是被优先考虑的

首先选择处于阻塞状态或睡眠状态的进程，当有多个这样的进程时，应当选择优先级最低的进程。在有的系统，为了防止低优先级的进程在被调入内存后很快又被换出，还需考虑进程在内存的驻留时间。如果系统中已无阻塞进程，而现在的内存空间仍不足以满足需求，便选择优先级最低的就绪进程换出。

(注意: PCB 会常驻内存，不会被换出外存)

### 内存交换需要注意的关键点

1. 交换需要备份存储，通常是快速磁盘，它必须足够大，并且提供对这些内存映像的直接访问。
2. 为了有效使用CPU，需要每个进程的执行时间比交换时间长，而影响交换时间的主要是转移时间，转移时间与所交换的空间内存成正比。
3. 如果换出进程，比如确保该进程的内存空间成正比。
4. 交换空间通常作为磁盘的一整块，且独立于文件系统，因此使用就可能很快。
5. 交换通常在有许多进程运行且内存空间吃紧时开始启动，而系统负荷降低就暂停。
6. 普通交换使用不多，但交换的策略的某些变种在许多系统中（如UNIX系统）仍然发挥作用。

## 交换空间与虚拟内存的关系

### 交换空间

Linux 中的交换空间（Swap space）在物理内存（RAM）被充满时被使用。如果系统需要更多的内存资源，而物理内存已经充满，内存中不活跃的页就会被移到交换空间去。虽然交换空间可以为带有少量内存的机器提供帮助，但是这种方法不应该被当做是对内存的取代。交换空间位于硬盘驱动器上，它比进入物理内存要慢。

交换空间可以是一个专用的交换分区（推荐的方法），交换文件，或两者的组合。

交换空间的总大小应该相当于你的计算机内存的两倍和 32 MB这两个值中较大的一个，但是它不能超过 2048MB（2 GB）。

### 虚拟内存

虚拟内存是文件数据交叉链接的活动文件。是WINDOWS目录下的一个 "WIN386.SWP"文件，这个文件会不断地扩大和自动缩小。

就速度方面而言,CPU的L1和L2缓存速度最快，内存次之，硬盘再次之。但是虚拟内存使用的是硬盘的空间，为什么我们要使用速度最慢的硬盘来做为虚拟内存呢？因为电脑中所有运行的程序都需要经过内存来执行，如果执行的程序很大或很多，就会导致我们只有可怜的256M/512M内存消耗殆尽。而硬盘空间动辄几十G上百G，为了解决这个问题，Windows中运用了虚拟内存技术，即拿出一部分硬盘空间来充当内存使用。

## 抖动

主存和辅存之间频繁页面置换的现象, 在更换页面时，如果更换页面是一个很快会被再次访问的页面，则再次缺页中断后又很快会发生新的缺页中断。

原因:
1.内存不够, 直接内存回收(同步,会阻塞进程)
2.页面置换算法不合理

## 常见的内存分配方式

内存分配方式
（1） 从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static变量。
（2） 在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。
（3） 从堆上分配，亦称动态内存分配。程序在运行的时候用malloc或new申请任意多少的内存，程序员自己负责在何时用free或delete释放内存。动态内存的生存期由我们决定，使用非常灵活，但问题也最多。

## 常见的内存分配内存错误

（1）内存分配未成功，却使用了它。
编程新手常犯这种错误，因为他们没有意识到内存分配会不成功。常用解决办法是，在使用内存之前检查指针是否为NULL。如果指针p是函数的参数，那么在函数的入口处用assert(p!=NULL)进行检查。如果是用malloc或new来申请内存，应该用if(p\==NULL) 或if(p!=NULL)进行防错处理。

（2）内存分配虽然成功，但是尚未初始化就引用它。
犯这种错误主要有两个起因：一是没有初始化的观念；二是误以为内存的缺省初值全为零，导致引用初值错误（例如数组）。内存的缺省初值究竟是什么并没有统一的标准，尽管有些时候为零值，我们宁可信其无不可信其有。所以无论用何种方式创建数组，都别忘了赋初值，即便是赋零值也不可省略，不要嫌麻烦。

（3）内存分配成功并且已经初始化，但操作越过了内存的边界。
例如在使用数组时经常发生下标“多1”或者“少1”的操作。特别是在for循环语句中，循环次数很容易搞错，导致数组操作越界。

（4）忘记了释放内存，造成内存泄露。
含有这种错误的函数每被调用一次就丢失一块内存。刚开始时系统的内存充足，你看不到错误。终有一次程序突然挂掉，系统出现提示：内存耗尽。动态内存的申请与释放必须配对，程序中malloc与free的使用次数一定要相同，否则肯定有错误（new/delete同理）。

（5）释放了内存却继续使用它。常见于以下有三种情况：
- 程序中的对象调用关系过于复杂，实在难以搞清楚某个对象究竟是否已经释放了内存，此时应该重新设计数据结构，从根本上解决对象管理的混乱局面。
- 函数的return语句写错了，注意不要返回指向“栈内存”的“指针”或者“引用”，因为该内存在函数体结束时被自动销毁。
- 使用free或delete释放了内存后，没有将指针设置为NULL。导致产生“野指针”。

## 原子操作如何实现

实现方式：基于缓存加锁与总线加锁。

### 总线加锁

使用处理器提供的一个lock#信号，当一个处理器在总线上输出此信号时，其他处理器的请求会被阻塞住，那么该处理器可以独占共享内存。

但总线锁定把cpu和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以开销比较大。

### 缓存加锁

频繁使用的内存会缓存在处理器的L1、L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁

当今 CPU 都是多核的，每个核心都有各自独立的 L1/L2 Cache，只有 L3 Cache 是多个核心之间共享的。所以，我们要确保多核缓存是一致性的，否则会出现错误的结果。

要想实现缓存一致性，关键是要满足 2 点：
- 第一点是写传播，也就是当某个 CPU 核心发生写入操作时，需要把该事件广播通知给其他核心；
- 第二点是事物的串行化，这个很重要，只有保证了这个，才能保障我们的数据是真正一致的，我们的程序在各个不同的核心上运行的结果也是一致的；

基于总线嗅探机制的 MESI 协议，就满足上面了这两点，因此它是保障缓存一致性的协议。

MESI 协议，是已修改(M)、独占(E)、共享(S)、已失效(I)这四个状态的英文缩写的组合。整个 MSI 状态的变更，则是根据来自本地 CPU 核心的请求，或者来自其他 CPU 核心通过总线传输过来的请求，从而构成一个流动的状态机。另外，对于在「已修改」或者「独占」状态的 Cache Line，修改更新其数据不需要发送广播给其他 CPU 核心。

“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中, 当一个核心进行原子递增时, 首先会把cache line的状态变成locked, 其余核心在解锁之前就不能进行操作, 阻塞等待。直到操作核心将其unlocked. 并更新cache line的标记

## page cache 和 buffer cache

**Page Cache 用于缓存文件的页数据，buffer cache 用于缓存块设备（如磁盘）的块数据。**

-   页是逻辑上的概念，因此 Page Cache 是与文件系统同级的；
-   块是物理上的概念，因此 buffer cache 是与块设备驱动程序同级的。

在 Linux 2.4 版本的内核之前，Page Cache 与 buffer cache 是完全分离的。但是，块设备大多是磁盘，磁盘上的数据又大多通过文件系统来组织，这种设计导致很多数据被缓存了两次，浪费内存。

**所以在 2.4 版本内核之后，两块缓存近似融合在了一起：如果一个文件的页加载到了 Page Cache，那么同时 buffer cache 只需要维护块指向页的指针就可以了。**

## cache 和 buffer

cache 是为了弥补高速设备和低速设备的鸿沟而引入的中间层，最终起到**加快访问速度**的作用。

而 buffer 的主要目的进行流量整形，把突发的大数量较小规模的 I/O 整理成平稳的小数量较大规模的 I/O，以**减少响应次数**（比如从网上下电影，你不能下一点点数据就写一下硬盘，而是积攒一定量的数据以后一整块一起写，不然硬盘都要被你玩坏了）。

1、**Buffer**（缓冲区）是系统两端处理**速度平衡**（从长时间尺度上看）时使用的。它的引入是为了减小短期内突发I/O的影响，起到**流量整形**的作用。比如生产者——消费者问题，他们产生和消耗资源的速度大体接近，加一个buffer可以抵消掉资源刚产生/消耗时的突然变化。  
2、**Cache**（缓存）则是系统两端处理**速度不匹配**时的一种**折衷策略**。因为CPU和memory之间的速度差异越来越大，所以人们充分利用数据的局部性（locality）特征，通过使用存储系统分级（memory hierarchy）的策略来减小这种差异带来的影响。  
3、假定以后存储器访问变得跟CPU做计算一样快，cache就可以消失，但是buffer依然存在。比如从网络上下载东西，瞬时速率可能会有较大变化，但从长期来看却是稳定的，这样就能通过引入一个buffer使得OS接收数据的速率更稳定，进一步减少对磁盘的伤害。  
4、TLB（Translation Lookaside Buffer，翻译后备缓冲器）名字起错了，其实它是一个cache.

https://www.zhihu.com/question/26190832/answer/32387918

## 条件变量


## 信号量和互斥锁解决父子线程同时阻塞的区别



## 如果多线程访问 LRU，需要在哪些地方加锁



## 如果 LRU 链表的节点值是指针，把它取出后赋值给其他变量，如何解决线程不安全的问题（深拷贝，移动语义）


## 申请一块内存，操作系统会怎么做


## 键盘敲击字母时，期间发生的什么

当用户输入了键盘字符，键盘控制器就会产生扫描码数据，并将其缓冲在键盘控制器的寄存器中，紧接着键盘控制器通过总线给CPU发送中断请求

CPU收到中断请求后，操作系统会保存被中断进程的CPU上下文，然后调用中断处理程序。

中断处理函数的功能就是从键盘控制器的寄存器的缓冲区读取扫描码，再根据扫描码找到用户在键盘输入的字符，得到了显示字符的ASCII码后，就会把ASCII码放到读缓冲区队列，接下来就是要把显示字符显示屏幕了，显示设备的驱动会定时从读缓冲区队列读取数据放到写缓冲区队列，最后把写缓冲区队列的数据一个一个地写入到显示设备的寄存器中的的数据缓冲区，最后将这些数据显示在屏幕里，显示出结果后，回复被中断进程的上下文。

## Linux下的内存管理

## 套接字工作原理


## 程序加载运行的全过程