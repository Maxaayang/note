## OSI 七层模型

- 应用层：应用层协议定义的是应用进程间的通行和交互的规则，不同的网络应用需要不同的协议
- 表示层：把数据转换为能与接收者的系统格式兼容并适合传输的格式
- 会话层：在数据传输中设置和维护电脑网络中两台电脑之间的通信方式
- 传输层：向两台主机进程之间的通信提供通用的数据传输服务
- 网络层：基于网络层地址(IP地址)进行不同网络系统间的路径选择
- 数据链路层：在不可靠的物理介质上提供可靠的传输
- 物理层：在局域网上透明地传送比特，尽可能屏蔽掉具体传输介质和物理设备的差异

## TCP/IP 模型

从上到下分为四层，对应 OSI 中的 5 层
- 应用层：对应于 OSI 参考模型的应用层，为用户提供所需要的各种服务。定义的是应用进程间的通信和交互的规则，不同的网络应用需要不同的应用层协议。协议包括 SMTP、HTTP、FTP 等
- 传输层：对应于 OSI 参考模型的传输层，为应用层实体提供端到端的、**通用的**通信功能，保证了数据包的顺序传送及数据的完整性。“通用的”是指不同的应用可以使用同一个运输层服务。协议包括 TCP、UDP 等
- 网络层（或网际互联层）：对应于 OSI 参考模型的网络层，主要解决主机到主机的路由问题。协议包括 IP、ICMP 等
- 网络接入层：对应于 OSI 参考模型的物理层和数据链路层，负责相邻的物理节点间的可靠数据传输。协议包括 ARP、IEEE 802.2 等

## 比较 TCP/IP 模型与 OSI 模型

共同点：
- 都采用了层次结构的概念
- 都能够提供面向连接和无连接的通信服务机制

不同点：
- OSI 采用了七层模型，而 TCP/IP 是四层
- OSI 是一个在协议开发前设计的、有清晰概念的模型；TCP/IP 是先有协议集然后建立的、事实上得到广泛应用的弱模型，功能描述和实现细节混在一起
- OSI 的**网络层**既提供面向连接的服务，又提供无连接的服务；TCP/IP 的网络层只提供无连接的网络服务
- OSI 的**传输层**只提供面向连接的服务；TCP/IP 的传输层既提供面向连接的服务 TCP，也提供无连接的服务 UDP

## 为什么要把 TCP/IP 协议栈分成 5 层(或7层)

- 各层之间是独立的
- 灵活性好
- 结构上可以分隔开
- 易于实现和维护
- 能促进标准化工作

## DNS

域名和IP地址相互映射的一个分布式数据库

### 为什么域名解析使用UDP协议

因为UDP快啊！UDP的DNS协议只要一个请求、一个应答就好了。

而使用基于TCP的DNS协议要三次握手、发送数据以及应答、四次挥手，但是UDP协议传输内容不能超过512字节。

不过客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。

### DNS区域传送

DNS主从复制，就是将主DNS服务器的解析库复制传送至从DNS服务器，进而从服务器就可以进行正向、反向解析了。从服务器向主服务器更新查询数据，保证数据一致性，此为区域传送。

**为什么使用TCP**
1. 区域传送将使用TCP而不是UDP，因为数据同步传送的数据量比一个请求和应答的数据量要多得多。会超出512字节
2. TCP是一种可靠的连接，保证了数据的准确性。

### DNS解析的过程

1. 浏览器先检查自身是否有缓存该域名对应的IP地址，若有解析结束。
2. 若浏览器自身没有缓存，则检查操作系统缓存和hosts中是否有对应的解析结果，若有解析结束。
3. 若没有，浏览器会发出一个**dns请求到本地dns服务器**，**本地dns服务器一般都是你的网络接入服务器商提供**，比如中国电信，中国移动等。查询输入的网址的DNS请求到达本地DNS服务器之后，**本地DNS服务器会首先查询它的缓存记录**，如果缓存中有此条记录，就可以直接返回结果，此过程是**递归的方式进行查询**。
4. 若本地DNS服务器没有缓存，本地DNS服务器向根域名服务器发送请求，根域名服务器不直接用于DNS解析，只会给本地DNS服务器返回一个顶级域名服务器IP地址。
5. 本地DNS服务器向顶级域名服务器发送请求，顶级域名服务器返回负责这个域名的权威域名服务器地址
6. 本地DNS服务器向权威域名解析服务器发送请求，返回域名对应的IP地址，本地DNS服务器缓存这个解析记录，把解析结果返回给用户，用户缓存到本地中。

### DNS 负载均衡策略

当一个网站有足够多的用户的时候，假如每次请求的资源都位于同一台机器上面，那么这台机器随时可能会崩掉。处理办法就是用DNS负载均衡技术，它的原理是在**DNS服务器中为同一个主机名配置多个IP地址,在应答DNS查询时,DNS服务器对每个查询将以DNS文件中主机记录的IP地址按顺序返回不同的解析结果,将客户端的访问引导到不同的机器上去,使得不同的客户端访问不同的服务器**,从而达到负载均衡的目的｡例如可以根据每台机器的负载量，该机器离用户地理位置的距离等等。

### DNS查询方式
#### 递归查询

当局部DNS服务器自己不能回答客户机的DNS查询时，它就需要向其他DNS服务器进行查询。此时有两种方式。**局部DNS服务器自己负责向其他DNS服务器进行查询，一般是先向该域名的根域服务器查询，再由根域名服务器一级级向下查询**。最后得到的查询结果返回给局部DNS服务器，再由局部DNS服务器返回给客户端。

#### 迭代查询

当局部DNS服务器自己不能回答客户机的DNS查询时，也可以通过迭代查询的方式进行解析。局部DNS服务器不是自己向其他DNS服务器进行查询，**而是把能解析该域名的其他DNS服务器的IP地址返回给客户端DNS程序**，客户端DNS程序再继续向这些DNS服务器进行查询，直到得到查询结果为止。也就是说，迭代解析只是帮你找到相关的服务器而已，而不会帮你去查。比如说：baidu.com的服务器ip地址在192.168.4.5这里，你自己去查吧，本人比较忙，只能帮你到这里了。

## HTTP
### HTTP是否可以使用UDP作为底层

### 完整的HTTP请求过程

-   建立起客户机和服务器连接。
-   建立连接后，客户机发送一个请求给服务器。
-   服务器收到请求给予响应信息。
-   客户端浏览器将返回的内容解析并呈现，断开连接。

域名解析 --> 发起TCP的3次握手 --> 建立TCP连接后发起http请求 --> 服务器响应http请求，浏览器得到html代码 --> 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） --> 浏览器对页面进行渲染呈现给用户。

### HTTP的特点

- 灵活可扩展
- 可靠传输
	- HTTP协议是基于 TCP/IP 的
	- 并不能保证数据一定能发送到另一端，在网络繁忙、连接质量差等恶劣环境下，也有可能收发失败
	- 可靠传输是指在网络基本正常的情况下数据收发必定成功
- 应用层协议
	- HTTP几乎可以传递一切东西
- 请求-应答
	- 客户端主动请求，服务端被动应答
- 无状态
	- 优点
		- 服务器不需要额外的资源来记录状态信息，实现上会简单，而且还能减轻服务器的负担，能够把更多的CPU和内存用来对外提供服务
		- 无状态表示服务器都是相同的，没有状态的差异，所以可以很容易组成集群
	- 缺点
		- 无法支持多个步骤的事务操作
- 不安全，是明文


### HTTP请求方法

HTTP 请求方法表明了要对给定资源执行的**操作**，每一个请求方法都实现了不同的**语义**。包括：GET、HEAD、POST、PUT、PATCH、DELETE、OPTIONS，以及不常用的 CONNECT、TRACE。

- **GET**：获取服务器的指定资源
- **HEAD**：与 GET 方法一样，都是发出一个获取服务器指定资源的请求，但服务器只会返回 Header 而不会返回 Body。用于确认 URI 的有效性及资源更新的日期时间等。一个典型应用是下载文件时，先通过 HEAD 方法获取 Header，从中读取文件大小 `Content-Length`；然后再配合 `Range` 字段，分片下载服务器资源
- **POST**：提交资源到服务器 / 在服务器新建资源
- **PUT**：替换整个目标资源
- **PATCH**：替换目标资源的部分内容
- **DELETE**：删除指定的资源(通常只是对资源进行一个删除的标记)
- OPTIONS：用于描述目标资源的通信选项。可以用于检测服务器支持哪些 HTTP 方法，或者在 CORS 中发起一个预检请求，以检测实际请求是否可以被服务器所接受
- CONNECT：建立一个到由目标资源标识的服务器的隧道
- TRACE：执行一个消息环回测试，返回到服务端的路径。客户端请求连接到目标服务器时可能会通过代理中转，通过 TRACE 方法可以查询发送出去的请求的一系列操作（[图示](https://imageslr.com/media/15993132198241.jpg)）

**幂等的**：一个 HTTP 方法是幂等的，指的是同样的请求执行一次与执行多次的效果是一样的。换句话说就是，幂等方法不应该具有副作用。

- 常见的幂等方法：GET，HEAD，PUT，DELETE，OPTIONS
- 常见的非幂等方法：POST

**安全的**：一个 HTTP 方法是安全的，指的是这是一个对服务器只读操作的方法，不会修改服务器数据。

- 常见的安全方法：GET，HEAD，OPTIONS
- 常见的不安全方法：PUT，DELETE，POST
- 所有安全的方法都是幂等的；有些不安全的方法如 DELETE 是幂等的，有些不安全的方法如 PUT 和 DELETE 则不是

**可缓存的**：GET、HEAD。

### 使用状态机解析GET和POST，GET与POST的差别，怎么解析


|               | GET                                      | POST                             |
| ------------- | ---------------------------------------- | -------------------------------- |
| 应用          | 获取服务器的指定数据                     | 添加/修改服务器的数据            |
| 历史记录/书签 | 可保留在浏览器历史记录中，或者收藏为书签 | 不可以                           |
| Cacheable     | 会被浏览器缓存                           | 不会缓存                         |
| 幂等          | 幂等，不会改变服务器上的资源             | 非幂等，会对服务器资源进行改变   |
| 后退/刷新     | 后退或刷新时，GET是无害的                | 后退或刷新时，POST会重新提交表单 |
| 参数位置      | query中(直接明文暴露在链接中)            | query或body中                    |
| 参数长度      | 2KB(2048个字符)                          | 无限制                                 |

### GET的方法参数写法是固定的吗

在约定中，我们的参数是写在 ? 后面，用 & 分割。

我们知道，解析报文的过程是通过获取 TCP 数据，用正则等工具从数据中获取 Header 和 Body，从而提取参数。

比如header请求头中添加token，来验证用户是否登录等权限问题。

也就是说，我们可以自己约定参数的写法，只要服务端能够解释出来就行，万变不离其宗。

### GET方法的长度限制

网络上都会提到浏览器地址栏输入的参数是有限的。

首先说明一点，HTTP 协议没有 Body 和 URL 的长度限制，对 URL 限制的大多是浏览器和服务器的原因。

浏览器原因就不说了，服务器是因为处理长 URL 要消耗比较多的资源，为了性能和安全（防止恶意构造长 URL 来攻击）考虑，会给 URL 长度加限制。

### POST比GET更安全？

有人说POST 比 GET 安全，因为数据在地址栏上不可见。
然而，从传输的角度来说，他们都是不安全的，因为 HTTP 在网络上是明文传输的，只要在网络节点上捉包，就能完整地获取数据报文。
要想安全传输，就只有加密，也就是 HTTPS。

### POST会产生两个TCP数据包？

有些文章中提到，POST 会将 header 和 body 分开发送，先发送 header，服务端返回 100 状态码再发送 body。
HTTP 协议中没有明确说明 POST 会产生两个 TCP 数据包，而且实际测试(Chrome)发现，header 和 body 不会分开发送。
所以，header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为。

### GET与POST传递数据的最大长度能够达到多少

get 是通过URL提交数据，因此GET可提交的数据量就跟URL所能达到的最大长度有直接关系。

很多文章都说GET方式提交的数据最多只能是1024字节，而实际上，URL不存在参数上限的问题，HTTP协议规范也没有对URL长度进行限制。

这个限制是特定的浏览器及服务器对它的限制，比如IE对URL长度的限制是2083字节(2K+35字节)。对于其他浏览器，如FireFox，Netscape等，则没有长度限制，这个时候其限制取决于服务器的操作系统；即如果url太长，服务器可能会因为安全方面的设置从而拒绝请求或者发生不完整的数据请求。

post 理论上讲是没有大小限制的，HTTP协议规范也没有进行大小限制，但实际上post所能传递的数据量大小取决于服务器的设置和内存大小。

因为我们一般post的数据量很少超过MB的，所以我们很少能感觉的到post的数据量限制，但实际中如果你上传文件的过程中可能会发现这样一个问题，即上传个头比较大的文件到服务器时候，可能上传不上去。

以php语言来说，查原因的时候你也许会看到有说PHP上传文件涉及到的参数PHP默认的上传有限定，一般这个值是2MB，更改这个值需要更改php.conf的post_max_size这个值。这就很明白的说明了这个问题了。

### HTTP常见字段

- Host字段：客户端发送请求时，用来指定服务器的域名
- Content-Length：服务器在返回数据时，表明本次回应的数据长度
	- HTTP通过设置回车符、换行符作为HTTP Header的边界，通过Content-Length字段作为HTTP body的边界来解决粘包问题
- Connection字段：常用于客户端要求服务端使用HTTP长连接的机制，以便其他请求复用
- Content-Type：用于服务器回应时，告诉客户端，本次数据是什么格式
- Content-Encoding：说明数据的压缩方法，表示服务器返回的数据使用了什么压缩格式

### HTTP请求和响应报文有哪些主要字段
#### 请求报文

-   请求行：Request Line
-   请求头：Request Headers
-   请求体：Request Body

#### 响应报文

-   状态行：Status Line
-   响应头：Response Headers
-   响应体：Response Body

### HTTP 的长连接与短连接

HTTP/1.0默认使用的是短连接。也就是说，浏览器每请求一个静态资源，就建立一次连接，任务结束就中断连接

HTTP/1.1默认使用的是长连接。长连接是指在一个网页打开期间，所有网络请求都使用同一条已经建立的连接。当没有数据发送时，双方需要法检测包以维持此连接。长连接不会永久保持连接，而是有一个保持时间。实现长连接需要客户端和服务端都支持长连接。

长连接的优点：TCP三次握手时会有1.5RTT的延迟，以及建立连接后慢启动特性，当请求频繁时，建立和关闭TCP连接会浪费时间和带宽，而重用一条已有的连接性能更好。

长连接的缺点：长连接会占用服务器的资源

### HTTP/1.0、HTTP/1.1、HTTP/2.0 的变化
#### HTTP 0.9 - 最初的版本

HTTP的最初版本，请求由单行指令构成，只支持GET方法，并且在响应请求之后立即关闭连接

#### HTTP/1.0 - 构建可扩展性

- 在请求中新增了协议版本信息，HEAD、POST等
- 引入了 **HTTP 头**的概念，让HTTP处理请求和响应更加灵活
- 在响应中新增了**状态码**，标记可能的错误原因
- 默认使用短连接：浏览器每请求一个静态资源，就建立一次连接，任务结束就中断连接
- 传输的数据不再局限于文本

#### HTTP/1.1 - 标准化的协议

- 增加了 PUT、DELETE 等新的方法
- 增加了缓存管理和控制
- 明确了连接管理，允许持久连接
- 允许响应数据分块（chunked），利于传输大文件
- 强制要求 Host 头，让互联网主机托管成为可能

优点：
- 简单：
	- HTTP 基本的报文格式就是 `header + body`，头部信息也是 `key-value` 简单文本的形式，**易于理解**，降低了学习和使用的门槛。
- 灵活和易于扩展
	- HTTP 协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员**自定义和扩充**。
	- 同时 HTTP 由于是工作在应用层（ `OSI` 第七层），则它**下层可以随意变化**，比如：
		- HTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层
		- HTTP/1.1 和 HTTP/2.0 传输协议使用的是 TCP 协议，而到了 HTTP/3.0 传输协议改用了 UDP 协议。
- 应用广泛和跨平台
	- 互联网发展至今，HTTP 的应用范围非常的广泛，从台式机的浏览器到手机上的各种 APP，从看新闻、刷贴吧到购物、理财、吃鸡，HTTP 的应用遍地开花，同时天然具有**跨平台**的优越性。

缺点：
- 无状态
	- 好处：因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。
	- 坏处：既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。
	- 解决方案：cookie
- 明文传输
- 不安全
	- 明文传输，内容可能会被窃听
	- 不验证通信方的身份，有可能遭遇伪装
	- 无法证明报文的完整性，有可能已遭篡改
	- 解决方案：HTTPS

性能：
- 长连接
- 管道网络传输
	- 在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以**减少整体的响应时间。**
	- 服务器必须按照请求的顺序发送对这些管道化请求的响应
- 队头阻塞
	- 当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据


- 默认支持**长连接**：在一个网页打开期间，所有网络请求都复用同一条已经建立的连接
    - Pros：性能更好，节省频繁建立 TCP 连接、慢启动、关闭连接等的时间，整体耗时更短
    - Cons：会占用服务器的资源
- 引入额外的**缓存控制**机制：如 `Entity tag`、`If-None-Match` 等更多可供选择的缓存头
- 新增了 24 个**错误状态响应码**，如 409（Conflict）、410（Gone）
- 引入内容协商，允许通信双方约定语言（`Accept-Language`）、编码（`Accept-Encoding`）等
- 支持响应分块（断点续传）
- 引入[管线化（Pipelining）](https://zh.wikipedia.org/wiki/HTTP%E7%AE%A1%E7%B7%9A%E5%8C%96)：从前发送请求后需等待并收到响应，才能发送下一个请求，现在允许客户端同时并行发送多个请求
    - Pros：在收到上一个请求的响应之前就可以发出下一个请求，能够节省请求到达服务器的时间，降低通信延迟
    - Cons：服务器要遵循 HTTP/1.1 协议，必须按照客户端发送的请求顺序返回响应，可能发生队头阻塞（HOL blocking）——若上一个请求的响应迟迟没有处理完毕，则后面的响应都会被阻塞
- Host 头，允许不同域名配置在同一个 IP 地址上
- 增加了PUT、DELETE等新的方法

长连接、管线化都是为了让请求更短时间内结束。

**优化**
- 尽量避免发送HTTP请求
	- 缓存并保存一个过期时间，将请求的URL作为key，响应作为value
	- 如果过期了，在请求的Etag头部会带上第一次请求的响应头部中的摘要，这个摘要是唯一标识响应的资源，当服务器收到请求后，会将本地资源的摘要和请求中的摘要做比较
- 在需要发送HTTP请求时，考虑如何减少请求次数
	- 减少重定向请求次数，重定向之后需要重新发起HTTP请求
	- 合并请求
		- 将多个小文件的请求合并成一个大的请求，可以减少重复发送的HTTP的头部
		- 1.1是请求响应模型，如果第一个发送的请求未收到对应的响应，那么后续的请求就不会发送，为了防止单个请求的阻塞，一般浏览器会同时发起5-6个请求，每一个请求都是不同的TCP连接，如果合并了请求的话，也就减少了TCP连接的数量，因而省去了TCP握手和慢启动过程耗费的时间
		- 问题，当大资源中的一个小资源发生变化后，客户端必须重新下载整个完整的大资源文件
	- 延迟发送请求
- 减少服务器的HTTP响应的数据大小
	- 无损压缩
	- 有损压缩


#### HTTP/2.0 - 为了更优异的表现

- 二进制协议，不再是纯文本
- 可发起多个请求，废弃了 1.1 里的管道
- 使用专用的算法压缩头部，减少数据传输量
- 允许服务器主动向客户端推送数据
- 增强了安全性，"事实上"要求加密通信

HTTP/2.0 的三大特性：Header压缩、服务端推送、多路复用

##### Header压缩

HTTP/1.1 每次通信都会携带 Header 信息用于描述资源属性。但 headers 在一系列请求中常常是相似的。HTTP/2.0 中，对于 Header 中相同的数据，不会在每次通信中重新发送，而是采用**追加**或**替换**的方式。

具体实现上，HTTP/2.0 在客户端和服务端之间共同维护一个 Header 表，所有的字段都会存入这个表，生成一个索引号，以后就不发送同样的字段了，只发送索引号，这样就提高速度了。Header 表在 HTTP/2.0 的连接期间始终存在。

Header 压缩可以减少每次通信的数据量，提高传输速度。

##### 服务端推送

服务器可以对一个客户端请求发送**多个**响应。服务器向客户端推送资源无需客户端明确的请求。

服务端根据客户端的请求，提前推送额外的资源给客户端。比如在发送页面 HTML 时主动推送其它 CSS/JS 资源，而不用等到浏览器解析到相应位置，发起请求再响应。

服务端推送可以减轻数据传输的冗余步骤，同时加快页面响应速度，提升用户体验。

##### 多路复用
###### 二进制分帧

HTTP/1.x 使用**文本格式**传输数据。HTTP/2.0 在将所有传输信息分割为若干个**帧**，采用**二进制格式**进行编码。

具体实现上，是在应用层（HTTP）和传输层（TCP）之间增加一个二进制分帧层。每个请求对应一个**流**，有一个唯一的整数标识符。HTTP/1.x 的报文会被拆分为一个或多个帧，每个帧有序列号，以及自己所述的流的标识符，接收端自行合并。

二进制分帧采用更高效的编码协议，提升了传输效率。同时，二进制分帧也为多路复用提供了基础。

###### 多路复用

HTTP/1.x 有**顺序**和**阻塞**约束：

- 顺序：服务端必须按照客户端请求到来的顺序，串行返回数据
    - 即使 HTTP/1.1 允许通过同一个连接发起多个请求，也无法真正并行传输
- 阻塞：浏览器会限制每个域名下最多同时发起的 6 个连接，超过该数量的连接会被阻塞，以下是常见的优化方法：
    - 使用多个域名（比如 CDN）来提高浏览器的下载速度
    - 将多个 JS 文件、CSS 文件等打包成一个文件，将多个小图片合并为雪碧图，减少 HTTP 请求数

HTTP/2.0 引入了**多路复用**，通过同一个连接发起多个请求，服务端可以**并行**地传输数据。基于二进制分帧层，HTTP/2.0 可以同时交错发送多个消息中的帧，接收端可以根据帧中的流标识符和顺序标识，重新组装数据。

多路复用使用同一个 TCP 连接并发处理同一域名下的所有请求，可以减少 TCP 建立连接带来的时延。此外多路复用代替了 HTTP/1.x 中的顺序和阻塞机制，实现了真正的并行传输，可以避免 HTTP/1.x 中的队头阻塞问题，极大的提高传输效率。

##### 缺陷

还存在队头阻塞问题，只不过不是在HTTP的层面，而是在TCP这一层

HTTP/2是基于TCP协议来传输数据的，TCP是字节流协议，TCP层必须保证收到的字节数据完整且连续的，这样内核才会将缓冲区的数据返回给HTTP应用，那么当「前1个字节数据」没有到大时，后收到的字节数据只能存放在内核缓冲区里，只有等到这1个字节数据到达时，HTTP/2应用层才能从内核中拿到数据。

#### HTTP/3.0

HTTP/3.0将下层的TCP协议改成了UDP
基于UDP的QUIC协议可以实现类似TCP的可靠性传输

QUIC的特点
- 无队头阻塞
	- QUIC也可以多路复用，但是当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题
- 更快的连接建立
	- 在之前的HTTP协议中，TCP和TLS是分层的，分布属于内核实现的传输层、openssl库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先TCP握手，再TLS握手
	- HTTP/3在传输数据前需要QUIC协议握手，只需要1RTT，目的是为确认双方的「连接ID」，连接迁移就是基于连接ID实现的
	- QUIC协议不是与TLS分层，而是QUIC内部包含了TLS，它在自己的帧会携带TLS里的"记录"，再加上QUIC使用的是TLS/1.3，所以仅需1个RTT就可以「同时」完成建立连接与密钥协商
- 连接迁移
	- 基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接**。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。
	- QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID**来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。


### HTTP2.0之前怎么实现服务器推送机制

### HTTP3.0 2.0 1.0 在多路复用上的进步

1.0队头阻塞，只有前面的请求得到了应答后边的请求才可以发送
2.0也是队头阻塞，但它是出现在TCP层
3.0没有了队头阻塞


### HTTP 分块传输编码

在 HTTP 通信过程中，请求的编码实体资源尚未全部传输完成之前，浏览器无法显示请求页面。在传输大容量数据时，通过把数据分割成多块，能够让浏览器逐步显示页面。这种把实体主体分块的功能称为分块传输编码（Chunked Transfer Coding）。

分块传输编码会将实体主体分成多个部分（块），每一块都会用十六进制来标记块的大小，而实体主体的最后一块会使用 `0(CR+LF)` 来标记。

使用分块传输编码的实体主体会由接收的客户端负责解码，恢复到编码前的实体主体。

> 注意区分“消息主体”和“实体主体”。《图解 HTTP》将也消息主体称为“报文主体”。

### HTTP 协议有状态码

第一位表示的是分类

#### 信息响应 (100-199)

提示信息，表示目前是协议处理的中间状态，还需要后续的操作
- 100 continue：表明目前为止都很正常，客户端可以继续发送请求或者忽略这个响应

#### 成功响应 (200-299)

成功，报文已经收到并被正确处理
- 200 OK
- 201 Created：该请求已成功，并因此创建了一个新的资源。这通常是在POST请求之后返回的响应
- 204 No Content：该请求以成功处理，但是返回的响应报文不包含实体的主体部分。通常用于只需要从客户端往服务器发送信息，而不需要返回数据时
- 206 Partial Content：服务器已经成功处理了部分GET请求，该请求必须包含Range头信息来指示客户端希望得到的内容范围，通常使用此类响应来实现断点续传，或者将一个大文档分为多个片段然后并行下载。

#### 重定向 (300-399)

重定向，资源位置发生变动，需要客户端重新发送请求
- **301 Moved Permanently**：永久性重定向，此次请求的资源已经不存在了，需要改用新的URI再次访问
- **302 Found**：临时性重定向，资源还在，但需要暂时用另一个URI访问。常见应用场景是通过 302 跳转将所有的 HTTP 流量重定向到 HTTPS
- 303 See Other：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源
- **304 Not Modified**：如果客户端发送了一个带条件的 GET 请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个状态码。304 响应不包含消息体，可以理解为重定向到已缓存的文件
- **307 Temporary Redirect**：临时重定向。307 与 302 之间的唯一区别在于，当发送重定向请求的时候，307 状态码可以确保**请求方法**和消息主体不会发生变化；而如果使用 302 响应状态码，一些旧客户端会错误地将请求方法转换为 GET

#### 客户端错误 (400-499)

客户端错误，请求报文有误，服务器无法处理
- 400 Bad Request：请求报文中存在语法错误，或者参数有误，只是一个笼统的错误
- 401 Unauthorized：未认证（没有登录）
- 403 Forbidden：没有权限（登录了但没有权限）
- 404 Not Found
- 405 Method Not Allowed

#### 服务器错误 (500-599)

服务器错误，服务器在处理请求时内部发生了错误
- 500 Internal Server Error：服务器遇到了不知道如何处理的情况
- 502 Bad Gateway：网关错误，作为网关或代理角色的服务器，从上游服务器（如tomcat、php-fpm）中接收到的响应是无效的
- 503 Service Unavailable：服务器无法处理请求，常见原因是服务器因维护或重载而停机

#### 301、302、307 重定向的原理

返回的Header中有一个Location字段指向目标URL，浏览器会重定向到这个URL

#### 304与缓存机制

强制缓存、协商缓存

### HTTP缓存
#### 强制缓存

为资源设置一个过期时间，只要资源没有过期，就读取浏览器的缓存。强制缓存不需要向服务器发起请求，浏览器直接返回200

- 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；
- 浏览器再次请求访问服务器中的该资源时，会先**通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期**，如果没有，则使用该缓存，否则重新请求服务器；
- 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。

#### 协商缓存

浏览器携带缓存资源的元信息，向服务器发起请求，由服务器决定是否使用缓存。如果协商生效，服务器返回304和Not Modified；如果协商缓存失效，服务器返回200和请求结果

协商缓存的原理是：服务端根据资源的元信息，判断浏览器缓存的资源在服务器上是否有改动。**元信息有两种**，一种是资源的上次修改时间，另一种是资源 Hash 值。前者实现简单，但是精确度低，文件修改时间只能以秒记；后者精确度高，但是性能低，需要计算哈希值。

优先级：
- 强制缓存 > 协商缓存
- 在协商缓存中，Hash值 > 上次修改时间

### HTTP是作用在哪层的协议


### HTTP缺点

- 使用明文进行通信，内容可能会被窃听
- 不验证通信方的身份，通信方的身份有可能遭遇伪装
- 无法证明报文的完整性，报文有可能遭篡改

## HTTPS

HTTPS 并不是新协议，而是HTTP 与 TCP 层之间加入了 `SSL/TLS` 协议通， **HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信，也就是说 HTTPS 使用了隧道进行通信**，通过使用 SSL，HTTPS 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）。

HTTPS需要先完成TCP连接的建立，然后再TLS握手的过程，才能建立通信安全的连接

### HTTPS 解决了 HTTP 什么问题

**存在问题**：
-   **窃听风险**，比如通信链路上可以获取通信内容，用户号容易没。
-   **篡改风险**，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。
-   **冒充风险**，比如冒充淘宝网站，用户钱容易没。

**解决方式：**
1.  **信息加密：混合加密**的方式实现信息的**机密性**，解决了窃听的风险。
HTTPS 采用的是**对称加密**和**非对称加密**结合的「混合加密」方式：
- 在通信建立前采用**非对称加密**的方式交换「会话秘钥」，后续就不再使用非对称加密。非对称加密速度慢，但可以解决密钥交换问题，私钥保密保证对称密钥的安全。
- 在通信过程中全部使用**对称加密**的「会话秘钥」的方式加密明文数据。对称密钥运算速度快，但无法做到单独的安全密钥交换

2.  **校验机制：摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。

**摘要算法和数字签名**：摘要算法计算内容的哈希值，可以保证哈希值是唯一的，但是不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明。因此对内容的哈希值进行加密，**通过「私钥加密，公钥解密」的方式，来确认消息的身份**，我们常说的**数字签名算法。**内容和数字签名一起发出去。

3.  **身份证书**：将服务器公钥放入到**数字证书**中，解决了冒充的风险。
权威机构（CA）用自己的私钥对服务器的公钥进行签名， 并颁发数字证书（包含服务器的公钥和数字签名），拥有这个证书的服务器就是可信的。CA的公钥一般被内置浏览器或者操作系统。

### HTTP和HTTPS的区别

HTTP是明文的，不安全
HTTPS有了机密性、完整性、身份认证和不可否认

HTTPS下层的传输协议由 HTTP over TCP/IP 变为了 HTTP over SSL/TLS

1、HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全， HTTPS协议是由HTTP+TLS协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。
2、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。
3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
4、https协议需要向CA(证书权威机构)申请数字证书，来保证服务器的身份是可信的

### 什么是 SSL/TLS

SSL：（Secure Socket Layer，安全套接字层），位于可靠的面向连接的网络层协议和应用层协议之间的一种协议层。SSL通过互相认证、使用数字签名确保完整性、使用加密确保私密性，以实现客户端和服务器之间的安全通讯。该协议由两层组成：SSL记录协议和SSL握手协议。

TLS：(Transport Layer Security，传输层安全协议)，用于两个应用程序之间提供保密性和数据完整性。该协议由两层组成：TLS记录协议和TLS握手协议。

SSL代表安全套接字层。它是一种用于加密和验证应用程序（如浏览器）和Web服务器之间发送的数据的协议。 身份验证 ， 加密Https的加密机制是一种共享密钥加密和公开密钥加密并用的混合加密机制。

SSL/TLS协议作用：认证用户和服务，加密数据，维护数据的完整性的应用层协议加密和解密需要两个不同的密钥，故被称为非对称加密；加密和解密都使用同一个密钥的

对称加密：优点在于加密、解密效率通常比较高 ，HTTPS 是基于非对称加密的， 公钥是公开的。

> TLS可以认为是SSL的升级版本，舍弃了一些过时的加密算法

### HTTPS 的加密流程

HTTPS 采用混合的加密机制，使用**非对称密钥加密用于传输对称密钥来保证传输过程的安全性**，之后使用**对称密钥加密进行通信来保证通信过程的效率**。

确保传输安全过程（其实就是rsa原理）：
1.  Client给出协议版本号、一个客户端生成的随机数（Client random），以及客户端支持的加密方法。
2.  Server确认双方使用的加密方法，并给出数字证书、以及一个服务器生成的随机数（Server random）。
3.  Client确认数字证书有效，然后生成一个新的随机数（Premaster secret），并使用数字证书中的公钥，加密这个随机数，发给Server。
4.  Server使用自己的私钥，获取Client发来的随机数（Premaster secret）。
5.  Client和Server根据约定的加密方法，使用前面的三个随机数，生成”对话密钥”（session key），用来加密接下来的整个对话过程。

### HTTPS怎么保证安全的

- 客户端向服务器端发起SSL连接请求
- 服务器把公钥发送给客户端，并且服务器端保存着唯一的私钥
- 客户端用公钥对双方通信的对称秘钥进行加密，并发送给服务器端 
- 服务器利用自己唯一的私钥对客户端发来的对称秘钥进行解密
- 进行数据传输，服务器和客户端双方用公有的相同的对称秘钥对数据进行加密解密，可以保证在数据收发过程中的安全，即是第三方获得数据包，也无法对其进行加密，解密和篡改。

因为数字签名、摘要是证书防伪非常关键的武器。 “摘要”就是对传输的内容，通过hash算法计算出一段固定长度的串。然后，通过发送方的私钥对这段摘要进行加密，加密后得到的结果就是“数字签名”

SSL/TLS协议的基本思路是采用公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。

**补充**：SSL/TLS的四次握手，目前网上的主流答案都在重复阮一峰老师的博客，属于TLS 1.0版本的答案，使用RSA密钥交换算法。但是现在TLS 1.2已经成为主流，使用ECDHE算法，如果面试可以说出这个版本的答案，应该会更好。

### 如何保证公钥不被篡改

将公钥放在数字证书中。只要证书是可信的，公钥就是可信的。 公钥加密计算量太大，如何减少耗用的时间？ 每一次对话（session），客户端和服务器端都生成一个"对话密钥"（session key），用它来加密信息。由于"对话密钥"是对称加密，所以运算速度非常快，而服务器公钥只用于加密"对话密钥"本身，这样就减少了加密运算的消耗时间。 （1） 客户端向服务器端索要并验证公钥。 （2） 双方协商生成"对话密钥"。 （3） 双方采用"对话密钥"进行加密通信。上面过程的前两步，又称为"握手阶段"（handshake）。

### HTTPS的应用数据如何保证完整性

TLS在实现上分为**握手协议**和**记录协议**
- TLS握手协议就是TLS四次握手的过程，负载协商加密算法和生成对称密钥，后续用此密钥来保护程序数据(即HTTP数据)
- TLS记录协议负载保护应用程序数据并验证其完整性和来源，所以对HTTP数据加密是使用记录协议

具体过程
- 将消息分割成多个较短的片段，然后分布对每个片段进行压缩
- 经过压缩的片段会被加上消息认证码(MAC值，这个是通过哈希算法生成的)，这是为了保证完整性，并进行数据的认证。通过附加消息认证码的MAC值，可以识别出篡改。与此同时，为了防止重放攻击，在计算消息认证码时，还加上了片段的编码
- 经过压缩的片段再加上消息认证码会一起通过对称密码进行加密
- 经过加密的数据再加上由数据类型、版本号、压缩后的长度组成的报头就是最终的报文数据
记录协议完成后，最终的报文数据将传递到传输控制协议(TCP)层进行传输

### HTTPS握手过程
#### RSA握手

传统的TLS握手基本都是RSA算法来实现密钥交换的，在将TLS证书部署服务端时，证书文件其实就是服务端的公钥，会在TLS握手阶段传递给客户端，而服务端的私钥则一直留在服务端，一定要确保私钥不能被窃取。

在RSA密钥协商算法中，客户端会生成随机密钥，并使用服务端的公钥加密后再传给服务端，根据非对称加密算法，公钥加密的消息仅能通过私钥解密，这样服务端解密之后，双方就得到了相同的密钥，再用它加密应用消息。(==这里的公钥是否可以截获==)

**TLS第一次握手**
客户端先发一个「Client Hello」消息，里边有客户端使用的TLS版本号、支持的密码套件列表，以及生成的随机数(Client Random)，这个随机数会被服务端保留，它是生成对称加密密钥的材料之一

**TLS第二次握手**
当服务端收到客户端的消息后，会确认TLS版本号是否支持，和从密码套件列表中选择一个密码套件，以及生成随机数

- 返回「Server Hello」，里边有服务器确认的TLS版本号，也给出了随机数(Server Random)，然后从客户端的密码套件列表选择了一个合适的密码套件
- 发送「Server Certificate」给客户端，里边包含数字证书
- 发送「Server Hello Done」，告诉客户端，已经把所有东西都发送了

密码套件格式：密钥交换算法+签名算法+对称加密算法+摘要算法

**TLS第三次握手**
客户端生成一个新的随机数(pre-master)，用服务器的RSA公钥加密该随机数，通过「Client Key Exchange」消息传给服务端

服务端收到后使用RSA私钥解密，得到客户端发来的随机数(pre-master)

双方根据已得到的三个随机数，生成会话密钥，它是对称密钥，用于对后续的HTTP请求/响应的数据加解密

生成完「会话密钥」后，客户端发一个「Change Cipher Spec」，告诉服务器开始使用加密方式发送消息

客户端再发一个「Encrypted Handshake Message (Finishd)」消息，把之前所有发送的数据做个摘要，再用会话密钥加密一下，让服务器做个验证，验证加密通信「是否可用」和「之前握手信息是否有被中途篡改过」

「Change Cipher Spec」之前传输的TLS握手数据都是明文，之后都是对称密钥加密的密文

**TLS第四次握手**
服务器发送「Change Cipher Spec」和「Encrypted Handshake Message」消息，如果双方都验证加密和解密没有问题，那么握手正式完成

**缺陷**

使用 RSA 密钥协商算法的最大问题是不支持前向保密。

因为客户端传递随机数（用于生成对称加密密钥的条件之一）给服务端时使用的是公钥加密的，服务端收到后，会用私钥解密得到随机数。所以一旦服务端的私钥泄漏了，过去被第三方截获的所有 TLS 通讯密文都会被破解。

#### ECDHE握手

使用ECDHE，在TLS第四次握手前，客户端就已经发送了加密的HTTP数据，而对于RSA握手过程，必须要完成TLS四次握手，才能传输应用数据，所以ECDHE相比RSA省去了一个消息往返的时间

**TLS第一次握手**
客户端发一个「Client Hello」，里面有客户端使用的TLS版本号、支持的密码套件列表，以及生成的随机数(Client Random)

**TLS第二次握手**
- 服务端返回「Server Hello」，里面有服务器确认的TLS版本号，以及一个随机数(Server Random)，然后从客户端的密码套件列表选择了一个合适的密码套件
- 服务端为了证明自己的身份，发送「Certificate」，同时把证书也发给客户端
- 发送「Server Key Exchange」
	- 服务端选择椭圆曲线，选好了椭圆曲线相当于椭圆曲线基点G也定好了，这些都会公开给客户端
	- 生成随机数作为服务端椭圆曲线的私钥，保留到本地
	- 根据基点G和私钥计算出服务端的椭圆曲线公钥，这个会公开给客户端
- 「Server Hello Done」

**TLS第三次握手**
校验证书的过程会走证书链逐级验证，确认证书的真实性，再用证书的公钥验证签名，这样就能确认服务端的身份了

客户端生成一个随机数作为客户端椭圆曲线的私钥，然后再根据服务端前面给的信息，生成客户端的椭圆曲线公钥，然后用「Client Key Exchange」消息发给服务端

最终的会话密钥是用「客户端随机数+服务端随机数+x(ECDHE算法算出的共享密钥)」三个材料生成的。之所以这么麻烦，是因为TLS设计者不信任客户端或服务器「伪随机数」的可靠性，为了保证真正的完全随机，把三个不可靠的随机数混合起来，那么「随机」的程度就非常高了，足够让黑客计算不出最终的会话密钥，安全性更高

「Change Cipher Spec」，告诉服务端后续该用对称算法加密通信
「Encrypted Handshake Message」，把之前发送的数据做一个摘要，再用对称密钥加密，让服务端做个验证，验证下本次生成的对称密钥是否可以正常使用

**TLS第四次握手**
服务端发送「Change Cipher Spec」和「Encrypted Handshake Message」，如果双方都验证加密和解密没有问题，那么握手正式完成，可以正常收发加密的HTTP请求和响应了

#### RSA和ECDHE握手的区别

- RSA密钥协商算法不支持前向保密，ECDHE密钥协商算法支持前向保密
- 使用了RSA密钥协商算法，TLS完成四次握手之后才能进行应用数据传输，而对于ECDHE算法，客户端可以不用等服务端的最后一次TLS握手，就可以提前发出加密的HTTP数据，节省了一个消息的往返时间
- 使用ECDHE，在TLS第二次握手中，会出现服务端发出的「Server Key Exchange」消息，而RSA握手过程没有该消息

### SSL中的认证的证书

通过使用 **证书** 来对通信方进行认证。

数字证书认证机构（CA，Certificate Authority）是客户端与服务器双方都可信赖的第三方机构。

服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。

进行 HTTPS 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证，如果验证通过，就可以开始通信了。

### 浏览器HTTP请求的过程

- 浏览器从地址栏的输入获得服务器的IP地址和端口号
- 浏览器用TCP的三次握手与服务器建立连接
- 浏览器向服务器发送拼好的报文
- 服务器收到报文后处理请求，同样拼好报文再发给浏览器
- 浏览器解析报文，渲染出页面

### 如果是一个不存在的域名，浏览器的工作流程是怎样的

浏览器缓存->系统缓存->hosts文件->局域网域名服务器->广域网域名服务器->顶级域名服务器->根域名服务器->报错

## ARP协议在第几层，具体的作用是什么

## Cookie 与 Session
### Cookie

Cookie是客户端保持状态的方法，存储由服务器发至客户端一段字符串。为了保持会话，服务器可以在响应客户端请求时将Cookie字符串放在Set-Cookie下，客户机收到Cookie之后保存这段字符串，之后再请求时候带上Cookie就可以被识别。如果没有cookie，每刷新一次网页，就要重新输入一次账号密码进行登录

除了上面提到的这些，Cookie在客户端的保存形式可以有两种，一种是**会话Cookie**，一种是**持久Cookie**，会话Cookie是保存在内存中，关闭浏览器之后自动销毁，持久Cookie是存储在磁盘上，其有效时间在服务器响应头中被指定，在有效期内，客户端再次请求服务器时都可以直接从本地取出。需要说明的是，存储在磁盘中的Cookie是可以被多个浏览器代理所共享的。

#### 用途

-   会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）
-   个性化设置（如用户自定义设置、主题等）
-   浏览器行为跟踪（如跟踪分析用户行为等）

### Session

Session是服务器保持状态的方法。Session保存在服务器上，可以保存在数据库、文件或内存中，每个用户有独立的Session在服务端上记录用户的操作。我们可以理解为每个用户有一个独一无二的Session ID作为Session文件的Hash键，通过这个值可以锁定具体的Session结构的数据，这个Session结构中存储了用户操作行为。

当服务器需要识别客户端时就需要结合Cookie了。每次HTTP请求的时候，客户端都会发送相应的Cookie信息到服务端。实际上大多数的应用都是**用Cookie来实现Session跟踪**的，第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在Cookie里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，我就知道你是谁了。如果客户端的浏览器**禁用了Cookie**，会使用一种叫做**URL重写**的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如sid=xxxxx这样的参数，服务端据此来识别用户，这样就可以帮用户完成诸如用户名等信息自动填入的操作了。

#### Session 的使用

客户端登录完成之后，服务器会记录对应的用户信息，并生成session id用来索引这个信息，然后将session id 发送给客户端，客户端再存储到浏览器中。这样客户端每次访问服务器时，都会带着 session id，服务器拿到 session id 之后，在内存或者数据库找到与之对应的 session。这样就可以正常工作了。

1. 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；
2. 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；
3. 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中；
4. 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。

### Cookie与Session的区别

二者都是用来跟踪浏览器用户身份的会话方式。

Cookie：
- 存在浏览器里，可以设置过期时间
- 每次访问服务器时，浏览器会自动在header中携带cookie
- 如果浏览器禁用了cookie，可以使用**URL重写机制**，将信息保存在URL里

Session：
- 存在服务端，由服务器维护，一段时间后session就失效了
- **本质上，session还是通过cookie实现的**。浏览器的cookie中值保存一个sessionId，所有其他信息均保存在服务端，由sessionId标识
- Session失效，其实是服务器设置了失效时间。如果用户长时间不和服务器交互(比如30分钟)，那么session就会被销毁；交互的话，就会刷新session
- [session的实现](https://github.com/labuladong/fucking-algorithm/blob/master/%E6%8A%80%E6%9C%AF/session%E5%92%8Ccookie.md#%E4%BA%8Csession-%E7%9A%84%E5%AE%9E%E7%8E%B0)

### Cookie与缓存的区别

**缓存是对一种静态资源的处理机制，而cookie是一种动态机制**

- **大小**：cookie本身有**大小限制**，一般浏览器显示不超过**4kb，缓存大小受资源和磁盘空间的限制**
- **作用**：
    - 缓存可以从本地磁盘中显示文档，它可以加速页面的显示；
    - 而cookie是用于服务器辨别用户的
- **存储内容**：缓存存储 javascript、HTML 页面、CSS、图像、音频、视频等媒体。当您再次访问该网站时，这些都会快速加载。Cookie 存储用于跟踪特定网站上的用户活动、浏览会话、网站历史记录和偏好等的数据。
- **存储位置**：缓存仅存储在您设备上的浏览器数据中，但 Cookie 会同时保存在网站服务器和您的网络浏览器中。（服务器可能需要根据cookie索引数据）

## MSL、TTL、RTT

MSL（Maximum segment lifetime）：**报文最大生存时间**。它是任何 TCP 报文在网络上存在的最长时间，超过这个时间报文将被丢弃。实际应用中常用的设置是 30 秒，1 分钟和 2 分钟。

- 应用场景：TCP 四次挥手时，需要在 TIME-WAIT 状态等待 2MSL 的时间，可以保证本次连接产生的所有报文段都从网络中消失。

TTL（Time to live）：**IP 数据报在网络中可以存活的总跳数**，称为“生存时间”，但并不是一个真正的时间。该域由源主机设置初始值，每经过一个路由器，跳数减 1，如果减至 0，则丢弃该数据包，同时发送 ICMP 报文通知源主机。取值范围 1-255，如果设置的 TTL 值小于传输过程中需要经过的路由器数量，则该数据包在传输中就会被丢弃。

RTT（Round trip time）：**客户端到服务端往返所花时间**。RTT 受网络传输拥塞的变化而变化，由 TCP **动态地估算**。

MSS：最大报文长度，TCP的MSS最大为1460字节

MTU：最大传输单元，以太网是1500字节

RTO：超时重传时间，每次重传是前一次重传时间的两倍，重传次数达到上限后停止重传

## UDP

首部字段只有8字节，12字节的伪首部是为了计算检验和临时添加的。UDP可以选择是否启用检验和，不启用为全0。

![0jaAK5](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/0jaAK5.png)


- 目标和源端口：主要是告诉UDP协议应该把报文发给哪个进程
- 包长度：该字段保存了UDP首部的长度跟数据的长度之和
- 校验和：校验和是为了提供可靠的UDP首部和数据而设计，防止收到在网络传输中受损的UDP包

检验和添加伪首部的原因是传输过程中中间件可能会修改目的IP和IP首部检验和，会交付到错误主机，在传输层能发现错误并丢弃。

- UDP是**无连接的**；
- UDP使用**尽最大努力交付**，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）；
- UDP是**面向报文**的；
- UDP**没有拥塞控制**，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）；
- UDP**支持一对一、一对多、多对一和多对多**的交互通信；
- UDP的**首部开销小**，只有8个字节，比TCP的20个字节的首部要短。

**由于MTU的限制，UDP携带数据最大长度为1472字节。**

### 为什么UDP头部没有「首部长度」字段，而TCP头部有「首部长度」字段

TCP有可变长的「选项」字段，而UDP头部长度则是不会变化的，无需多一个字段去记录UDP的首部长度

### 为什么UDP头部有「包长度」字段，而TCP头部没有

![rwYhTk](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/rwYhTk.png)
UDP「包长度」是冗余的，因为为了网络设备硬件设计和处理方便，首部长度需要是4字节的整数倍

- 因为为了网络设备硬件设计和处理方便，首部长度需要是4字节的整数倍。如果去掉UDP「包长度」字段，那UDP首部长度就不是4字节的整数倍了。
- 如今的UDP协议是基于IP协议发展的，而当年可能并非如此，依赖的可能是别的不提供自身报文长度害怕首部长度的网络层协议，因此UDP报文首部需要有长度字段以供计算

### DHCP

**基于UDP**
- 客户端首先发起 **DHCP 发现报文（DHCP DISCOVER）** 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 UDP **广播**通信，其使用的广播目的地址是 255.255.255.255（**端口 67**） 并且使用 0.0.0.0（**端口 68**） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。
- DHCP 服务器收到 DHCP 发现报文时，用 **DHCP 提供报文（DHCP OFFER）** 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 **IP 地址租用期**。
- 客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器（第一个），并向选中的服务器发送 **DHCP 请求报文（DHCP REQUEST)**进行响应，回显配置的参数。之所以广播是因为要通知所有的DHCP SERVER进行相应的处理。
- 最后，服务端用 **DHCP ACK 报文**对 DHCP 请求报文进行响应，应答所要求的参数，一般携带服务器分配给客户端的dns以及ip，网关等信息

DHCP服务器的**offer与ack阶段既可以使用单播的方式又可以使用广播的方式**，这主要取决于服务器在**offer阶段对BROADCAST**位的置位情况,如果置位为1，则DHCP服务器使用广播的方式回应，否则使用单播的方式回应

**DHCP中继代理**
DHCP采用广播，如果 DHCP 服务器和客户端不是在同一个局域网内，路由器又不会转发广播包，所以为了解决这一问题，就出现了 **DHCP 中继代理**。有了 DHCP 中继代理以后，**对不同网段的 IP 地址分配也可以由一个 DHCP 服务器统一进行管理。**
- DHCP 客户端会向 DHCP 中继代理**广播**发送 DHCP 请求包，而 DHCP 中继代理在收到这个广播包以后，再以**单播**的形式发给 DHCP 服务器。
- 服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包**广播**给 DHCP 客户端 。

### UDP的使用场景

- 需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用
- 不需要一对一沟通，建立连接，而是可以广播的应用
- 需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也要进行传输的时候

### 如何基于UDP实现可靠传输




## TCP
### 什么是TCP

TCP是面向连接的、可靠的、基于字节流的传输层通信协议

- 面向连接：一定是「一对一」才能连接，不能像UDP协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的
- 可靠的：无论网络链路中出现了怎样的链路变化，TCP都可以保证一个报文一定能够到达接收端
- 字节流：用户消息通过TCP协议传输时，消息可能会被操作系统「分组」成多个的TCP报文，如果接收方的程序不知道「消息的边界」，是无法读出一个有效的用户消息的。并且TCP报文是「有序的」，当「前一个」TCP报文没有收到的时候，即使它先收到了后面的TCP报文，那么也不能扔给应用层去处理，同时对「重复」的TCP报文会自动丢弃

### 如何唯一确定一个TCP连接

TCP四元组可以唯一的确定一个连接，四元组包括
- 源地址
- 源端口
- 目的地址
- 目的端口

源地址和目的地址的字段（32位）是在 IP 头部中，作用是通过 IP 协议发送报文给对方主机。

源端口和目的端口的字段（16位）是在 TCP 头部中，作用是告诉 TCP 协议应该把报文发给哪个进程。

> 有一个 IP 的服务端监听了一个端口，它的 TCP 的最大连接数是多少？

服务端通常固定在某个本地端口上监听，等待客户端的连接请求。

因此，客户端 IP 和 端口是可变的，其理论值计算公式如下:

![](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/8gezs3.png)

对 IPv4，客户端的 IP 数最多为 `2` 的 `32` 次方，客户端的端口数最多为 `2` 的 `16` 次方，也就是服务端单机最大 TCP 连接数，约为 `2` 的 `48` 次方。

当然，服务端最大并发 TCP 连接数远不能达到理论上限，会受以下因素影响：

- **文件描述符限制**，每个 TCP 连接都是一个文件，如果文件描述符被占满了，会发生 too many open files。Linux 对可打开的文件描述符的数量分别作了三个方面的限制：
    - **系统级**：当前系统可打开的最大数量，通过 cat /proc/sys/fs/file-max 查看；
    - **用户级**：指定用户可打开的最大数量，通过 cat /etc/security/limits.conf 查看；
    - **进程级**：单个进程可打开的最大数量，通过 cat /proc/sys/fs/nr_open 查看；
- **内存限制**，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的，如果内存资源被占满后，会发生 OOM。

### TCP标志位

1.  **SYN**（synchronous）： 发送/同步标志，用来建立连接，和 ACK 标志位搭配使用。A 请求与 B 建立连接时，SYN=1，ACK=0；B 确认与 A 建立连接时，SYN=1，ACK=1
2.  **ACK**（acknowledgement）：确认标志，表示确认收到请求
3.  PSH（push） ：表示推送操作，就是指数据包到达接收端以后，不对其进行队列处理，而是尽可能的将数据交给应用程序处理
4.  **FIN**（finish）：结束标志，表示关闭一个 TCP 连接
5.  RST（reset）：重置复位标志，用于复位对应的 TCP 连接
6.  URG（urgent）：紧急标志，用于保证 TCP 连接不被中断，并且督促中间层设备尽快处理

### TCP 序列号、确认号

作用：序列号和确认号是TCP实现可靠传输的依赖。TCP使用序列号来记录发送数据包的顺序。TCP传送一个数据包后，只有在指定的时间里收到这个包的确认信息，才会将其从队列中删除，否则会重新发送该数据包。对接收方而言，通过数据分段中的序列号可以保证数据能够按照正常的顺序进行重组。

#### 序列号

是TCP的一个头部字段，标识了TCP发送端到TCP接收端的数据流的一个字节，因为TCP是面向字节流的可靠协议，为了保证消息的顺序性和可靠性，TCP为每个传输方向上的每个字节都赋予了一个编号，以便于传输成功后确认、丢失后重传以及在接收端保证不会乱序。序列号是一个32位的无符号数，因此在到达4G之后再循环回到0

- 在 SYN flag 置 1 时，表示当前连接的初始序列号（Initial Sequence Number，ISN）
- 在 SYN flag 置 0 时，表示当前报文段中的第一个字节的序列号

序列号的规则：

- 握手阶段，`[SYN]` 包即使没有传送数据，也会消耗一个序列号。因此，建立连接后的序列号从 `ISN+1` 开始
- 挥手阶段，`[FIN/ACK]` 包即使没有传送数据，也会消耗掉一个序列号
- 数据传输阶段，序列号 = 第一个报文段的序列号 + 已经发送的字节数
    - 比如第一个报文段的序列号为 `S`，已经发送了 100 个字节，则下一个报文段的序列号为 `S+100`
    - 如果某个报文段不携带数据，不会消耗序列号，下一个报文段还是用相同的序列号发送
    - 正常情况下，B 给 A 的确认号，就是 A 下一个报文段的序列号
- 客户端三次握手第三步的 `[ACK]` 包，和传输阶段的第一个报文段，有相同的序列号

#### 确认号

ACK flag 置1时才有效，表示接收方期待的下一个报文段的序列号。一般是上次收到的报文段 seq+1

#### TCP的序列号和确认号是如何变化的

为什么第二次和第三次握手报文中的确认号是将对方的序列号+1后作为确认号？
SYN报文是特殊的TCP报文，用于建立连接时使用，虽然SYN报文不携带用户数据，但是TCP将SYN报文视为1字节的数据，当对方收到了SYN报文后，在回复ACK报文时，就需要将ACK报文中的确认号设置为SYN的序列号 + 1，这样做是有两个目的：
- 告诉对方，我已收到了SYN报文
- 告诉对方，我方下一次「期望」收到的报文的序列号为此确认号，比如看客户端与服务端完成三次握手之后，服务端接下来期望收到的是序列号为 client_isn + 1 的TCP数据报文

客户端与服务端完成三次握手之后，发送的第一个「TCP数据报文的序列号和确认号」都是和「第三次握手的ACK报文中序列号和确认号」一样的

### 为什么需要TCP，TCP工作在哪一层

IP层是不可靠的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。如果需要保障网络数据包的可靠性，那么就需要由上层(传输层)的TCP协议来负责。

因为TCP是一个工作在传输层的可靠数据传输的服务，它能确保接收端接收的网络包是无损的、无间隔、非冗余和按序的。

### 三次握手
#### 三次握手过程

![5VJPKx](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/5VJPKx.png)

-  一次握手：客户端请求建立连接，向服务端发送一个**同步报文**（SYN=1），同时选择一个随机数 seq = x 作为**初始序列号**
- 第二次握手：服务端收到连接请求报文后，如果同意建立连接，则为该TCP连接分配TCP缓存和变量，并向客户端发送**同步确认报文**（SYN=1，ACK=1），确认号为 ack = x + 1，同时选择一个随机数 seq = y 作为**初始序列号**
- 第三次握手：客户端收到服务端的确认后，为该连接分配缓存和变量，并向服务端发送一个**确认报文**（ACK=1），确认号为 ack = y + 1，序列号为 seq = x + 1，因为连接已经建立，所以该SYN被置为0

这时就完成了三次握手，连接建立成功。随后，客户端和服务端的序列号将分别从 `x+1` 和 `y+1` 开始进行传输。

#### 为什么使用随机数来作为初始序列号

- 为了防止历史报文被下一个相同四元组的连接接收
	- 如果每次建立连接客户端和服务端的初始化序列号都一样，就有大概率遇到历史报文的序列号刚好在对方的接收窗口内，从而导致历史报文被新连接成功接收
	- 初始化不同的序列号虽然也可能接收到历史报文，但是序列号大概率不在对方的接收窗口内，接回被丢弃
	- 正常挥手4次，由于TIME_WAIT状态会持续2MSL时长，历史报文会在下一个连接之前就自然消失，但是并不能保证每次连接都能通过四次挥手来正常关闭
- 为了安全性，防止黑客伪造的相同序列号的TCP报文被对方接收

#### 为什么需要三次握手，而不是两次或四次？

- 三次握手才可以阻止重复历史连接的初始化(==主要原因==)
	- 两次握手连接，服务器就没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费。
		
	- 如果服务器收到SYN报文后就立即进入了ESTABLISHED状态，这就意味着可以给对方发送数据了，但是客户端还没有进入ESTABLISHED，加入是历史连接，客户端判断到此次连接为历史连接，那么就会回RST报文来断开连接，而服务端在第一次握手的时候就进入了ESTABLISHED状态，所以它是可以发送数据的，但是它并不知道这个是历史连接，它只有在收到RST报文后才会断开连接。

- 三次握手才可以同步双方的初始序列号
	- TCP协议的双方，都必须维护一个序列号，序列号是可靠传输的一个关键因素，它的作用：
		- 接收方可以去除重复的数据
		- 接收方可以根据数据包的序列号按序接收
		- 可以标识发送出去的数据包中，哪些是已经被对方收到的(通过ACK报文中的序列号知道)
	- 只有一来一回才能确保双方的初始序列号能被可靠的同步
	- 两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收

- 三次握手才可以避免资源浪费
	- 如果只有两次握手，当客户端发送的SYN报文在网络中阻塞，客户端没有收到ACK报文就会重新发送SYN，那么服务端在收到请求后就会健力多个冗余的无效连接，造成不必要的资源浪费

#### 三次握手能否携带数据

第一次、第二次握手不能携带数据，第三次握手可以携带数据

加入第一次握手可以携带数据，攻击者会在第一次握手中放入大量的数据，并重复发SYN报文，会让服务器花费很多时间与空间来接收报文
而第三次握手能携带数据是因为客户端已经处于建立状态，能知道自己与服务器的发送接收能力正常，所以能携带数据


#### 第一次握手丢失了会发生什么

会触发「超时重传」机制，重传SYN报文，并且重传的SYN报文的序列号都是一样的。

当客户端超时重传3次SYN报文之后，已达到最大重传次数，于是再等待一段时间(时间一般是上一次超时时间的2倍)，如果还是没有收到服务端的第二次握手，那么客户端就会断开连接。

#### 第二次握手丢失了会发生什么

第二次握手的目的：
- 第二次握手里的ACK，是对第一次握手的确认报文
- 第二次握手里的SYN，是服务端发起建立TCP连接的报文

当第二次握手丢失之后
- 客户端会重传SYN报文，即第一次握手
	- 当客户端超时重传1次SYN报文后，已达到最大重传次数，于是再等待一段时间，如果还没有收到服务端的第二次握手，那么客户端就会断开连接
- 服务端会重传SYN-ACK 报文，即第二次握手
	- 当服务端超时重传2次SYN-ACK报文后，已达到最大重传次数，于是再等待一段时间，如果还没有收到客户端的第三次握手，那么服务端就会断开连接

#### 第三次握手丢失了会发生什么

如果服务端迟迟收不到确认报文，就会触发超时重传机制，重传SYN-ACK报文，直到收到第三次握手，或者达到最大重传次数

客户端发送的数据报文，因为有ACK标志位，服务端收到数据报后，数据报文中的ACK确认号等同于确认了服务端的第二次握手，然后服务端内核就会进入ESTABLISHED状态，并分配发送和接收缓冲区，然后内核将客户端的数据报文放到接收缓冲区中，等待服务端的应用读取该数据。

**ACK报文不会重传，当ACK丢失了，就由对方重传对应的报文**

#### 什么是SYN攻击？如何防范？

SYN 攻击属于 DOS 攻击的一种，它利用 TCP 协议缺陷，通过发送大量的半连接请求，耗费 CPU 和内存资源。

原理：
- 在三次握手过程中，服务器发送 `[SYN/ACK]` 包（第二个包）之后、收到客户端的 `[ACK]` 包（第三个包）之前的 TCP 连接称为半连接（half-open connect），此时服务器处于 `SYN_RECV`（等待客户端响应）状态。如果接收到客户端的 `[ACK]`，则 TCP 连接成功，如果未接受到，则会**不断重发请求**直至成功
- SYN 攻击的攻击者在短时间内**伪造大量不存在的 IP 地址**，向服务器不断地发送 `[SYN]` 包，服务器回复 `[SYN/ACK]` 包，并等待客户的确认。由于源地址是不存在的，服务器需要不断的重发直至超时
- 这些伪造的 `[SYN]` 包将长时间占用未连接队列，影响了正常的 SYN，导致目标系统运行缓慢、网络堵塞甚至系统瘫痪

检测：当在服务器上看到大量的半连接状态时，特别是源 IP 地址是随机的，基本上可以断定这是一次 SYN 攻击。

防范：主要有两大类，一类是通过防火墙、路由器等过滤网关防护，另一类是通过加固 TCP/IP 协议栈防范，如增加最大半连接数，缩短超时时间。但 SYN 攻击不能完全被阻止，除非将 TCP 协议重新设计，否则只能尽可能的减轻 SYN 攻击的危害。

- 调大 netdev_max_backlog
	- 当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包
- 增大 TCP 半连接队列，同时也要增大全连接队列
- 开启 tcp_syncookies
	- 可以在不使用SYN半连接队列的情况下成功建立连接，相当于绕开SYN半连接来建立连接
	- 当「SYN队列」满之后，后续服务端收到SYN包，不会丢弃，而是根据算法，计算出一个cookie值，并且不会将其放入半连接队列里
		- cookies没有队列，如果有的话，也会像半连接队列一样被打满，cookies是通过通信双方的IP地址端口、时间戳、MSS等信息进行实时计算的，保存在TCP报头的seq里
		- cookies虽然可以防御SYN攻击，但是因为服务端并不会保存连接信息，所以如果传输过程中数据包丢了，也不会重发第二次握手的信息。另外编码解码cookies都是比较耗CPU的，利用这一点，如果攻击者构造大量的第三次握手包，同时带上各种瞎编的cookies信息，服务端可能会因为CPU资源耗尽导致没能响应真正的请求
	- 将cookie值放到第二次握手报文的「序列号」里，然后服务端回第二次握手给客户端
	- 服务端接收到客户端的应答报文时，服务端会检查这个ACK包的合法性。如果合法，将该连接对象放入到「Accept队列」
	- 最后应用程序通过调用 accept() 接口，从「Accept队列」取出连接
- 减少 SYN+ACK 重传次数，即第二次握手

#### SYN什么时候会被丢弃

- TCP两个队列满了，造成SYN报文被丢弃

##### 半连接队列满了

当服务器造成syn攻击，就有可能导致TCP半连接队列满了，这时后面的syn包都会被丢弃，但是如果开启了syncookies功能，即使半连接队列满了，也不会丢弃SYN包。

syncookies，服务器根据当前的状态计算出一个值，放在己方发出的SYN+ACK报文中发出，当客户端返回ACK报文时，取出该值验证，如果合法，就认为连接建立成功。

syncookies主要有以下三个值：

- 0：表示关闭该功能
- 1：表示仅当SYN半连接队列放不下时，再启用它
- 2：表示无条件开启该功能

##### 全连接队列满了

在服务端并发处理大量请求时，如果TCP accept队列过小，或者应用程序调用accept()不及时，就会造成accept队列满了，这时后续的连接就会被丢弃，这样就会出现服务端请求输了上不去的现象

#### 已建立连接的TCP，收到SYN会发生什么

客户端中途宕机重启后，向服务端建立连接，此时服务端会怎么处理

1. 客户端的SYN报文里的端口号与历史连接不同

如果客户端恢复后发送的 SYN 报文中的源端口号跟上一次连接的源端口号不一样，此时服务端会认为是新的连接要建立，于是就会通过三次握手来建立新的连接。

那旧连接里处于 establish 状态的服务端最后会怎么样呢？

如果服务端发送了数据包给客户端，由于客户端的连接已经被关闭了，此时客户的内核就会回 RST 报文，服务端收到后就会释放连接。

如果服务端一直没有发送数据包给客户端，在超过一段时间后， TCP 保活机制就会启动，检测到客户端没有存活后，接着服务端就会释放掉该连接。



2. 客户端的SYN报文里的端口号与历史连接相同

处于 establish 状态的服务端如果收到了客户端的 SYN 报文（注意此时的 SYN 报文其实是乱序的，因为 SYN 报文的初始化序列号其实是一个随机数），会回复一个携带了正确序列号和确认号的 ACK 报文，这个 ACK 被称之为 Challenge ACK。

接着，客户端收到这个 Challenge ACK，发现确认号（ack num）并不是自己期望收到的，于是就会回 RST 报文，服务端收到后，就会释放掉该连接。

#### 处于TIME_WAIT状态的连接，收到相同四元组的SYN后会发生什么

如果双方开启了时间戳机制：

- 如果客户端的SYN的「序列号」bi服务端「期望下一个收到的序列号」要大，并且SYN的「时间戳」bi服务端「最后收到的报文的时间戳」要大，那么就会重用该四元组连接，跳过2MSL而转变为SYN_RECV状态，接着就能进行建立连接过程
- 如果客户端的SYN的「序列号」比服务端「期望下一个收到的序列号」要小，或者SYN的「时间戳」比服务端「最后收到的报文的时间戳」要小，那么就会再回复一个第四次挥手的ACK报文，客户端收到后，发现班不是自己期望收到的确认号，就回RST报文给服务端

在TIME_WAIT状态，收到RST会断开连接吗？

- 如果 `net.ipv4.tcp_rfc1337` 参数为0，则提前结束 TIME_WAIT 状态，释放连接
- 如果 `net.ipv4.tcp_rfc1337` 参数为1， 则会丢掉该RST报文

### 四次挥手

#### 四次挥手过程

![](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/PgIOmk.png)



- 第一次挥手：客户端向服务端发送**连接释放报文**（FIN=1，ACK=1），主动关闭连接，同时等待服务端的确认，进入 FIN_WAIT_1 状态
    - 序列号 seq = u，即客户端上次发送的报文的最后一个字节的序号 + 1
    - 确认号 ack = k, 即服务端上次发送的报文的最后一个字节的序号 + 1
- 第二次挥手：服务端收到连接释放报文后，立即发出**确认报文**（ACK=1），序列号 seq = k，确认号 ack = u + 1，进入 CLOSE_WAIT 状态
∏
这时 TCP 连接处于半关闭状态，即客户端到服务端的连接已经释放了，但是服务端到客户端的连接还未释放。这表示客户端已经没有数据发送了，但是服务端可能还要给客户端发送数据。

- 第三次挥手：服务端向客户端发送**连接释放报文**（FIN=1，ACK=1），主动关闭连接，同时等待 A 的确认
    - 序列号 seq = w，即服务端上次发送的报文的最后一个字节的序号 + 1。如果半关闭状态，服务端没有发送数据，那么 w == k
    - 确认号 ack = u + 1，与第二次挥手相同，因为这段时间客户端没有发送数据
- 第四次挥手：客户端收到服务端的连接释放报文后，立即发出**确认报文**（ACK=1），序列号 seq = u + 1，确认号为 ack = w + 1

此时，客户端就进入了 `TIME-WAIT` 状态。注意此时客户端到 TCP 连接还没有释放，必须经过 2\*MSL（最长报文段寿命）的时间后，才进入 `CLOSED` 状态。而服务端只要收到客户端发出的确认，就立即进入 `CLOSED` 状态。可以看到，服务端结束 TCP 连接的时间要比客户端早一些。

TCP 规定，`[FIN/ACK]` 包即使没有传送数据，也会消耗掉一个序列号。`[FIN/ACK]` 包是第一、三次挥手：

- 第一次挥手时，客户端的序列号 seq = u，消耗一个序列号。因此：
    - 第二次挥手时，服务端的确认号 ack = u + 1
    - 第四次挥手时，客户端的序列号 seq = u + 1
- 第三次挥手时，服务端的序列号 seq = w，消耗一个序列号。因此：
    - 第四次挥手时，客户端的确认号 ack = w + 1

#### 为什么需要四次挥手

- 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了，但是还能接收数据
- 服务端收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接

==在特定的情况下，四次挥手也可以变成三次挥手==
当被动关闭方在TCP挥手的过程中，「没有数据要发送」并且「开启了TCP延迟确认机制」，那么第二次和第三次挥手就会合并，这样就出现了三次挥手

TCP延迟确认机制
当发送没有携带数据的ACK，它的网络效率是很低的，因为它也有40个字节的IP头和TCP头，但却没有携带数据报文。为了解决ACK传输效率低的问题，所以就衍生出了TCP延迟确认。TCP延迟确认的策略：
- 当有响应数据要发送时，ACK会随着响应数据一起立刻发送给对方
- 当没有响应数据要发送时，ACK将会延迟一段时间，以等待是否有响应数据可以一起发送
- 如果在延迟等待发送ACK期间，对方的第二个数据报文到达了，这时就会立刻发送ACK

#### 第一次挥手丢失了，会发生什么

会触发超时重传机制，重传FIN报文，当超过一定的次数之后，就不会再发送FIN报文，则会等待一段时间，如果还是没有收到第二次挥手，那么直接进入 close 状态

#### 第二次挥手丢失了，会发生什么

ACK不会进行重传，所以客户端会触发超时重传机制，重传FIN报文，直到收到服务端的第二次挥手，或者达到最大的重传次数

当客户端收到第二次挥手，会处于 FIN_WAIT2 状态，需要等待服务端发送第三次挥手

对于调用close关闭的连接，如果在默认60秒后还没有收到FIN报文，客户端(主动关闭方)的连接就会直接关闭

如果主动关闭方使用 shutdown 函数关闭连接，指定了只关闭发送方向，而接收方向并没有关闭，那么意味着主动关闭方还是可以接收数据的，此时，如果主动关闭方一直没收到第三次握手，那么主动关闭方的连接将会一直处于 FIN_WAIT2 状态

#### 第三次挥手丢失了，会发生什么

服务端会重发FIN报文，如果超过一定的次数还没有收到第四次回复，那么服务端就会断开连接

客户端因为是通过close函数关闭连接的，处于 FIN_WAIT_2 状态是有时长限制的，如果一定的时间内还是没有收到服务端的第三次挥手，那么客户端就会断开连接

#### 第四次挥手丢失了，会发生什么

服务端会重发FIN报文，一定时间内没有收到第四次挥手，服务端就会断开连接

#### 为什么第四次挥手，客户端的TIME-WAIT状态必须等待2MSL的时间才能返回到CLOSED状态

主要有两个原因：
(1) 确保 ACK 报文能够到达服务端，从而使服务端正常关闭连接。

第四次挥手时，客户端第四次挥手的 ACK 报文不一定会到达服务端。服务端会超时重传 FIN/ACK 报文，此时如果客户端已经断开了连接，那么就无法响应服务端的二次请求，这样服务端迟迟收不到 FIN/ACK 报文的确认，就无法正常断开连接。

MSL 是报文段在网络上存活的最长时间。客户端等待 2MSL 时间，即「客户端 ACK 报文 1MSL 超时 + 服务端 FIN 报文 1MSL 传输」，就能够收到服务端重传的 FIN/ACK 报文，然后客户端重传一次 ACK 报文，并重新启动 2MSL 计时器。如此保证服务端能够正常关闭。

那如果服务端重发的 FIN 没有成功地在 2MSL 时间里传给客户端，会怎样？服务端会继续超时重试直到断开连接，见下文。

(2) 防止已失效的连接请求报文段出现在之后的连接中。

TCP 要求在 2MSL 内不使用相同的序列号。客户端在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以保证本连接持续的时间内产生的所有报文段都从网络中消失。这样就可以使下一个连接中不会出现这种旧的连接请求报文段。或者即使收到这些过时的报文，也可以不处理它。

#### 为什么要有 TIME_WAIT

- 防止历史连接中的数据，被后面相同四元组的连接错误的接收
  - 序列号是TCP一个头部字段，标识了TCP发送端到TCP接收端的数据流的一个字节，因为TCP是面向字节流的可靠协议，为了保证消息的顺序性和可靠性，TCP为每个传输方向上的每个字节都赋予了一个编号，以便于传输成功后确认、丢失后重传以及在接收端保证不会乱序。序列号是一个32位的无符号数，因此在到达4G之后再循环回到0
- 保证「被动关闭连接」的一方，能被正确的关闭
  - 如果没有TIME_WAIT，而是最后一次挥手之后直接进入CLOSE状态，如果最后一次ACK丢失，服务端则重传FIN报文，而这是客户端已进入到关闭状态，在收到服务端重传的FIN报文后，就会回RST报文，服务端收到这个RST，并将其解释为一个错误，这对于一个可靠的协议来说不是一个优雅的终止方式

#### 四次挥手中收到乱序的FIN包会如何处理

在FIN_WAIT_2状态时，如果收到乱序的FIN报文，那么就会被加入到「乱序队列」，并不会进入到TIME_WAIT状态。

等再次收到前面网络延迟的数据包时，会判断乱序队列有没有数据，然后会检测乱序队列中是否有可用的数据，如果能在乱序队列中找到与当前报文的序列号保持的顺序的报文，就会看该报文是否有FIN标志，如果发现有FIN标志，这时才会进入TIME_WAIT状态

#### 如果已建立了连接，但是客户端出现了故障怎么办？

或者说，如果三次握手阶段、四次挥手阶段的包丢失了怎么办？比如上面描述的“服务端重发 FIN”的问题。

简而言之，通过**定时器 + 超时重试机制**，尝试获取确认，直到最后会自动断开连接。

具体而言，TCP 设有一个保活计时器。服务器每收到一次客户端的数据，都会重新复位这个计时器，时间通常是设置为 2 小时。若 2 小时还没有收到客户端的任何数据，服务器就开始重试：每隔 75 秒发送一个探测报文段，若一连发送 10 个探测报文后客户端依然没有回应，那么服务器就认为连接已经断开了。

#### TIME_WAIT 是主动断开连接的一方、还是被动断开连接的一方会进入的状态

`TIME_WAIT` 是主动断开连接的一方会进入的状态。

`TIME_WAIT` 需要等待 2MSL，在大量短连接的情况下，`TIME_WAIT` 会太多，这也会消耗很多系统资源。对于服务器来说，在 HTTP 协议里指定 KeepAlive（浏览器重用一个 TCP 连接来处理多个 HTTP 请求），由浏览器来主动断开连接，可以一定程度上减少服务器的这个问题。

#### TIME_WAIT 过多的危害

- 占用系统资源，比如文件描述符、内存资源、CPU资源、线程资源等
- 端口资源的占用，一个TCP连接至少消耗发起连接方的一个本地端口
- 客户端受端口资源限制，服务端受文件描述符、内存资源、CPU资源、线程资源等等系统资源的限制

**如果客户端的TIME_WAIT状态过多**，占满了所有的端口资源，那么就无法对「目的IP+目的PORT」都一样的服务端发起连接了，但是被使用的端口，还是可以继续对另外一个服务端发起连接的。

因此，客户端（发起连接方）都是和「目的 IP+ 目的 PORT 」都一样的服务端建立连接的话，当客户端的 TIME_WAIT 状态连接过多的话，就会受端口资源限制，如果占满了所有端口资源，那么就无法再跟「目的 IP+ 目的 PORT」都一样的服务端建立连接了。

不过，即使是在这种场景下，只要连接的是不同的服务端，端口是可以重复使用的，所以客户端还是可以向其他服务端发起连接的，这是因为内核在定位一个连接的时候，是通过四元组（源IP、源端口、目的IP、目的端口）信息来定位的，并不会因为客户端的端口一样，而导致连接冲突。

**如果服务端（主动发起关闭连接方）的 TIME_WAIT 状态过多**，并不会导致端口资源受限，因为服务端只监听一个端口，而且由于一个四元组唯一确定一个 TCP 连接，因此理论上服务端可以建立很多连接，但是 TCP 连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等。

#### 服务器出现大量TIME_WAIT状态的原因有哪些

TIME_WAIT 状态是主动关闭连接方才会出现的状态，所以如果服务器出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务器主动断开了很多 TCP 连接。

服务器主动断开了连接的场景有下面这些：

- 在使用 HTTP/1.1长连接的时候，当发起 HTTP 请求的客户端数量超过服务器指定的最大长连接个数（比如 nginx 配置中的 keepalive_requests 参数），那么服务器会主动断开这个连接，此时服务器上就会出现大量的TIME_WAIT 状态。解决方式：调大最大长连接个数。
- 如果服务器是反向代理服务器，nginx（在服务器上跑）与后端进行大量的短连接请求，由于nginx 会主动挂断这个连接，在服务器上就会出现大量的 TIME_WAIT 状态。解决方式：使用长连接
- HTTP/1.1长连接的时候，客户端在超时时间内没有新的数据发送，那么服务器会主动挂断这个连接，在服务器上就会出现 TIME_WAIT 状态。这种情况一般不会出现大量的 TIME_WAIT 状态，因为很难出现同一时间出现大量客户端一直不发送新的数据。如果出现了，可以往网络问题的方向排查，比如是否是因为网络问题，导致客户端发送的数据一直没有被服务器接收到。
- 服务器的进程挂掉了，内核会发起 FIN 报文，这时候相当于服务器会主动挂断这个连接，于是在服务器上就会出现大量的 TIME_WAIT 状态。

#### 如果已经建立了连接，但是客户端突然出现故障了怎么办

TCP 有一个机制是**保活机制**。这个机制的原理是这样的：

定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。

如果开启了 TCP 保活，需要考虑以下几种情况：

- 第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。
- 第二种，对端程序崩溃并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，**会产生一个 RST 报文**，这样很快就会发现 TCP 连接已经被重置。
- 第三种，是对端程序崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**。

#### 如果已经建立了连接，但是服务端的进程崩溃会发生什么

TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程。

### 既然IP层会分片，为什么TCP层还需要MSS

如果仅靠IP层的MTU进行分片，由于IP层无超时重传，重传需要靠TCP来实现，因此如果一个IP分配丢失，整个IP报文的所有分配都得重传
经过TCP层分片后，如果一个TCP分配丢失后，进行重发时也是以MSS为单位，而不用重传所有的分片，大大增加了重传的效率。

### TCP为什么是面向连接的

- 发送之前需要先建立连接(三次握手)
- 使用排序和确认机制(分组之间并不是独立的；记录了分组之间的状态信息)
- 具有流量控制和拥塞控制
- 发送完毕后要释放连接(四次挥手)

### TCP是怎么实现可靠传输的

重传、滑动窗口、流量控制、拥塞控制


### TCP 与 UDP 的区别

- 连接
	- TCP：面向连接的、可靠的、基于字节流的传输层通信协议，分为建立连接、传输数据、终止连接三部分
	- UDP：无连接的、不可靠的、基于报文的传输层通信协议，不需要建立连接直接传输数据
- 服务对象
	- 每一条TCP连接只能点对点通信
	- UDP可以一对一、一对多、多对一和多对多通信
- 可靠性
	- TCP是可靠交付数据的，利用确认重传机制、差错控制将数据完整发送给对方，数据可以无差错、不丢失、不重复、按需到达
	- UDP是尽最大努力交付，没有重传机制，差错控制只有一个检验和字段，不保证可靠交付数据
- 拥塞控制、流量控制
	- TCP有拥塞控制和流量控制，保证数据传输的安全性
	- UDP则没有，及时网络非常拥堵了，也不影响UDP的发送速率
- 首部开销
	- TCP首部开销20-60字节
	- UDP只有固定8字节，开销更小
- 传输方式
	- TCP是流式控制，没有边界，但保证顺序和可靠性
	- UDP是一个包一个包的发送，是有边界的，但可能会丢包和乱序
- 分片不同
	- TCP面向字节流，对于应用程序传下来的报文会根据MSS进行TCP分段，避免IP分片，中途丢失了一个分片，只需要传输丢失的这个分片
	- UDP面向报文，对于报文不合并不拆分，只会添加首部、超过MTU只能在IP层分片

- 面向字节流：TCP将要发送的数据视为无结构的字节流，如果发送的数据太长，就拆分发送，如果发送的数据太短，则积累较多的字节后再发送
- 面向报文：UDP一次发送一个报文，不管多大，都以报文为发送单位

|                   | TCP                                                                | UDP                                                            |
| ----------------- | ------------------------------------------------------------------ | -------------------------------------------------------------- |
| 连接性            | 面向连接                                                           | 无连接                                                         |
| 可靠性            | 可靠                                                               | 不可靠                                                         |
| 传输方式          | 面向字节流                                                         | 面向报文(保留报文的边界)                                       |
| 传输速度          | 慢                                                                 | 快                                                             |
| 双工性            | 全双工                                                             | 一对一、一对多、多对一、多对多                                 |
| 流量控制/拥塞控制 | 有                                                                 | 无                                                             |
| 应用场景          | 对效率要求相对低，但是对准确性要求高的场景。如文件传输、发送邮件等 | 对效率要求相对高、对准确性要求相对低的场景。如即时通信、直播等 |
| 应用层协议        | SMTP(电子邮件)、TELNET(远程登录控制)、HTTP、FTP                    | DNS、TFTP(文件传输)、DHCP(动态主机配置)...                                                               |




### TCP连接两端一个突然断连，另一端如何感知

### TCP 如何保证可靠性

- 序列号：解决乱序问题
- 确认号/超时重传机制：解决丢包问题

- 确认和重传：接收方收到报文就会确认，发送方发送一段时间后没有收到确认就会重传
- 数据校验：TCP报文头有校验和，用于校验报文是否损坏
- 数据合理分片和排序：TCP会按最大传输单元(MTU)合理分片，接收方会缓存未按序到达的数据，重新排序后交给应用层。而UDP：IP数据报大于1500字节，大于MTU。这个时候发送方的IP层就需要分片，把数据报分成若干片，是的每一片都小于MTU。而接收方IP层则需要进行数据报的重组。由于UDP的特性，某一片数据丢失时，接收方便无法重组数据报，导致丢弃整个UDP数据报。
- 流量控制：当接收方来不及处理发送方的数据，能通过滑动窗口，提示发送方降低发送的速率，防止包丢失
- 拥塞控制：当网络拥塞时，通过拥塞窗口，减少数据的发送，防止包丢失

### TCP 怎么实现拥塞控制，为什么要慢开始



### DNS的过程及其传输的内容

### 重传机制

#### 超时重传

在数据发送时，设定一个定时器，当超过指定的时间后，没收到对方的ACK确认应答报文，就会重发该数据

TCP会在以下两种情况发生超时重传：

- 数据包丢失
- 确认应答丢失

超时重传时间RT0：应该略大于报文往返时间RTT

因为RTT是变化的，所以RTO的值也应该是动态变化的，估计往返时间，通常需要采样以下两个：

- 需要TCP通过采样RTT的时间，然后进行加权平均，算出一个平滑RTT的值，而且这个值还是要不断变化的，因为网络状况不断地变化
- 除了采样RTT，还要采样RTT的波动范围，这样就避免如果RTT有一个大的波动的话，很难被发现的情况

如果发送端超时还未收到 ACK 包，就可以认为网络出现了拥塞，需要解决拥塞：

1.  把 sshthresh 设为当前拥塞窗口的一半（乘性减）
2.  cwnd 重置为 1，重新开始**慢启动**过程

#### 快速重传/快速恢复

快速重传：接收端收到乱序包时，会发送 duplicate ACK 通知发送端。当发送端收到 3 个 duplicate ACK 时，就立刻开始重传，而不必继续等待到计时器超时。快速重传会配合快速恢复算法：

1.  把 sshthresh 设为当前拥塞窗口的一半（乘性减）
2.  cwnd 重置为 sshthresh，重新开始**拥塞避免**过程

为什么快速重传不需要像超时重传那样，将 cwnd 重置为 1 重新开始慢启动呢？因为它认为如果网络出现拥塞的话，是不会收到好几个重复的 ACK 的，所以现在网络可能没有出现拥塞。

快速重传会把丢失报文之后的所有报文都重传一次，但是后边有的报文已经接收到了，所以相当于做了一次无用功，浪费资源

#### SACK，选择性确认

在TCP头部字段里加一个SACK，它可以将已收到的数据信息发送给「发送方」，这趟发送方就可以直到哪些数据收到了，哪些数据没有收到，知道了这些信息，就可以只重传丢失的数据

#### Duplicate SACK

重要使用了SACK来告诉「发送方」有哪些数据被重复接收了



### 流量控制

目的是控制发送端的发送速度，使其按照接收端的数据处理速度来发送数据，避免接收端处理不过来，产生网络拥塞或丢包。

#### 滑动窗口

发送端和接收端均有一个滑动窗口，对应一个缓冲区，记录当前发送或接收到的数据。接收端会在返回的ACK报文中包含自己**可用于接收数据的缓冲区的大小**，在TCP报文首部里用windows表示。发送端发送的数据不会超过window的大小。

![16042843490197.jpg](https://imageslr.com/media/16042843490197.jpg)

接收端返回给发送端的ACK报文中的window字段等于

![](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/Sdm3wP.png)

即只能在收到的包的最后一个位置之后继续接收，尽管`NextByteExpected`和`LastByteRcvd`中间还有一段数据空白区，但这些数据可能发送端已经发送，只是还未到大接收端，因此不能将这段空白区大小计入window

发送端在接收到这个ACK报文后，下一个报文的大小是：
![](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/enIuWR.png)

#### 零窗口

如果接收端处理过慢，window可能变为0，在这种情况下发送端就不再发送数据了。如何在接收端window可用的时候通知发送端呢？

TCP 使用ZWP(零窗口探针)技术。具体是在发送端引入一个计时器，每当收到一个零窗口的应答后就启动该计时器。每间隔一段时间就主动发送报文，由接收端来返回ACK窗口的大小。若接收者持续返回零窗口(一般是3次)，则有TCP实现会发送RST断开连接。

#### 发送端如何调节发送速率

发送端的发送速率受到多个因素的影响
- 接收端将自己的可接收的大小通过window字段发送给发送端，发送端据此做出调整(流量控制)
- 当发送端监测到网络出现拥塞时，通过各种协同工作的机制来解决拥塞(拥塞控制)，通过一个状态变量cwnd控制发送速率

发送端的发送速率是上诉两个变量的较小值

#### 糊涂窗口综合征

如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合征

解决方案：

- 让接收方不通告小窗口给发送方
  - 当窗口大小小于 min(MSS, 缓存空间/2)，就会向发送方通告窗口为0，也就阻止了发送方再发数据过来
- 让发送方避免发送小数据
  - 使用Nagle算法

### Nagle 算法

延时处理，只只有满足下面两个条件中的任意一个条件，才可以发送数据：

- 要等到窗口大小 >= MSS 并且 数据大小 >= MSS
- 收到之前发送数据的 ack 回包

### 拥塞控制

目的是避免发送方的数据填满整个网络，在网络拥塞的时候，如果继续发送大量的数据包，可能会导致数据包时延、丢失等，这是TCP就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大
- 基于丢包的拥塞控制：将丢包视为出现拥塞，采取缓慢探测的方式，逐渐增大拥塞窗口，当出现丢包时，将拥塞窗口减小，如 Reno、Cubic等
- 基于时延的拥塞控制：将时延增加视为出现拥塞，延时增加时增大拥塞窗口，延时减小时减小拥塞窗口，如 Vegas、FastTCP 等
- 基于链路容量的拥塞控制：实时测量网络带宽和时延，认为网络上报文总量大于带宽时延乘积时出现了拥塞，如 BBR

**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。**发生了重传，就会认为网络出现了拥塞。**
cwdn会对一个TCP发送方能向网络中发送流量的速率进行了限制

发送窗口的值是是拥塞窗口和接收窗口中的最小值。

拥塞窗口 `cwnd` 变化的规则：
-   只要网络中没有出现拥塞，`cwnd` 就会增大；
-   但网络中出现了拥塞，`cwnd` 就减少；

只要发送方没有在规定的时间内接收到ACK应答报文，也就是发生了超时重传，就会认为网络出现了拥塞

慢启动和拥塞避免是 TCP 的强制部分，两者的差异在于对收到的 ACK 做出反应时增加 cwnd 长度的方式。慢启动比拥塞避免能更快地增加 cwnd 长度。

#### 慢启动

- 连接建立时，初始化 cwnd = 1，表示可以传一个 MSS 大小的数据
- 每收到一个 ACK 包，cwnd++
- 每经过一个 RTT，cwnd 会翻倍（指数增长）

何时结束**指数增长**？
* 如果存在一个由超时指示的丢包事件（即拥塞），TCP 发送方将 cwnd 设置为 1 并重新开始慢启动过程，并将第二个状态变量的值 ssthresh（慢启动阈值）设置为 cwnd/2，即当检测到拥塞时将 ssthresh 置为拥塞窗口值的一半。
* 当 cwnd 的值等于 ssthresh 时，结束慢启动并且 TCP 转移到拥塞避免模式。
* 如果检测到 3 个冗余 ACK，这时 TCP 执行一种快速重传并进入快速恢复状态。



- 当 cwnd < ssthresh 时，使用慢启动算法
- 当 cwnd >= ssthresh 时，就会使用拥塞避免算法

#### 拥塞避免

- 每收到一个 ACK 包，cwnd = cwnd + 1/cwnd
- 每经过一个 RTT，cwnd = cwnd + 1（加性增）

何时结束**线性增长**？
当出现超时时，与慢启动的情况一样，cwnd 的值被设置为 1 个 MSS；

当丢包事件出现时，ssthresh 的值被更新为 cwnd 值的一半。

如果是由三个冗余 ACK 触发的丢包事件，网络继续从发送方向接收方交付报文段，TCP 将 cwnd 的值减半，并且当收到 3 个冗余的 ACK，将 ssthresh 的值记录为 cwnd 的值的一半，接下来进入快速恢复状态。

#### 拥塞发生

当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：

- 重试重传
- 快速重传

当发生了超时重传，就会使用拥塞发生算法

- ssthresh 设为 cwnd/2
- cwnd 重置为 1 (是恢复为 cwnd 初始化值)

发生快速重传的拥塞发生算法

- cwnd = cwnd/2
- ssthresh = cwnd
- 进入快速恢复算法

#### 快速恢复

快速恢复算法认为，还能收到3个重复的ACK，说明网络也不是特别糟糕，所以没必要像RTO超时那么强烈

- 拥塞窗口 cwnd = ssthresh + 3 (3的意思是确认有3个数据包被收到了)
- 重传丢失的数据包
- 如果再收到重复的ACK，那么cwnd增加1
- 如果收到新数据的ACK后，把cwnd设置为第一步中的ssthresh的值，原因是该ACK确认了新的数据，说明从duplicated ACK时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，即再次进入拥塞避免算法



**为什么收到新数据后，cwnd设置回了ssthresh？**

1. 在快速恢复的过程中，首先 ssthresh = cwnd/2，然后 cwnd = ssthresh + 3，表示网络可能出现了阻塞，所以需要减小 cwnd 以避免，加 3 代表快速重传时已经确认接收到了 3 个重复的数据包；
2. 随后继续重传丢失的数据包，如果再收到重复的 ACK，那么 cwnd 增加 1。加 1 代表每个收到的重复的 ACK 包，都已经离开了网络。这个过程的目的是尽快将丢失的数据包发给目标。
3. 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，恢复过程结束。

**首先，快速恢复是拥塞发生后慢启动的优化，其首要目的仍然是降低 cwnd 来减缓拥塞，所以必然会出现 cwnd 从大到小的改变。**

**其次，过程2（cwnd逐渐加1）的存在是为了尽快将丢失的数据包发给目标，从而解决拥塞的根本问题（三次相同的 ACK 导致的快速重传），所以这一过程中 cwnd 反而是逐渐增大的。**

### 如何区分流量控制和拥塞控制

- 流量控制属于双方协商；拥塞控制涉及通信链路全局
- 流量控制需要通信双方各维护一个发送窗，对任意一方，接收窗大小由自身决定，发送窗大小由接收方响应的TCP报文段中的窗口值确定；拥塞控制的拥塞窗口大小变化由试探性发送一定数据量数据探查网络状况后而自适应调整
- 实际最终发送窗口 = min{流控发送窗口，拥塞窗口}

### 半连接队列和全连接队列

- 半连接队列，也称SYN队列，是一个哈希表
	- 队列里都是不完整的连接，现在有一个第三次握手来了，则需要从队列里把相应的IP端口连接取出，如果半连接队列还是个链表，那就需要依次遍历，才能拿到想要的那个连接，算法复杂度就是O(n)
- 全连接队列，也称accept队列，是一个链表
	- 里面存放的都是已经建立完成的连接，这些连接正等待被取走。而服务端取走连接的过程中，并不关心具体是哪个连接，只要是个连接就行，所以直接从队头取就行，因为每个监听socket都有各自的链接队列，所以从全连接队列取的连接就是自己所监听的

服务端收到客户端发起的SYN请求后，内核会把该连接存储到半连接队列，并向客户端响应SYN+ACK，接着客户端会返回ACK，服务端收到第三次握手的ACK后，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到accept队列，等待进程调用accept函数时把连接取出来。

不管半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回RST包。
- 对于全连接，如果 `tcp_abort_on_overflow` 设置为0，全连接队列满了之后，会丢弃这个第三次握手ACK包，并且开启定时器，重传第二次握手的SYN+ACK，如果重传超过了一定限制次数，还会把对应的半连接队列里的连接给删掉
- 如果 `tcp_abort_on_overflow` 设置为1，全连接队列满了之后，就直接法RST给客户端，效果看上去就是连接断了，类似于服务端端口未监听

进程从全连接队列取出连接后，直接就但会应用层了，然后应用层自己管理，也就是自己写代码管理的socket fd。

内核会对每一个完成三次握手的socket建立一个哈希表，当收到消息，根据数据包中的tcp四元组信息从哈希表判断连接是否存在，不存在就返回rst，存在就把数据包放到对应的socket的缓冲区。

### 如何优化TCP

#### TCP三次握手的性能提升

##### 客户端优化

三次握手建立连接的目的是「同步序列号」

可以根据网络的稳定性和目标服务器的繁忙程度修改SYN的重传次数，调整客户端的三次握手时间上限。比如内网中通讯时，就可以适当调低重试次数，尽快把错误暴露给应用程序。

### 如何理解TCP是面向字节流的协议

#### 为什么UDP是面向报文的协议

当用户消息通过UDP协议传输时，操作系统不会对消息进行拆分，在组装好UDP头部后交给网络层来处理，所以发出去的UDP报文中的数据部分就是完整的用户消息，也就是每个UDP报文就是一个用户消息的边界，这样接收方在接收到UDP报文后，读一个UDP报文就能读取到完整的用户消息。

**如果收到了两个UDP报文，操作系统是怎么区分的？**

操作系统在收到UDP报文后，会将其插入到队列里，队列里的每一个元素就是一个UDP报文，这样当用户调用recvfrom()系统调用读数据的时候，就会从队列里取出一个数据，然后从内核里拷贝给用户缓冲区。

#### 为什么TCP是面向字节流的协议

当用户消息通过 TCP 协议传输时，**消息可能会被操作系统分组成多个的 TCP 报文**，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。

这时，接收方的程序如果不知道发送方发送的消息的长度，也就是不知道消息的边界时，是无法读出一个有效的用户消息的，因为用户消息被拆分成多个 TCP 报文后，并不能像 UDP 那样，一个 UDP 报文就能代表一个完整的用户消息。

当两个消息的某个部分内容被分到同一个 TCP 报文时，就是我们常说的 TCP 粘包问题，这时接收方不知道消息的边界的话，是无法读出有效的消息。

要解决这个问题，要交给**应用程序**。

### TCP粘包

#### 什么是粘包

粘包并不是TCP自己本身的"问题"，而是一个"现象"。TCP本身面向字节流的特性，导致会有所谓的"粘包"问题，需要应用层进行拆分。所以也有一种说法是"TCP粘包是一个伪命题"

为什么UDP协议没有粘包问题？
UDP是面向报文的，应用层交给UDP多长的报文，UDP就照样发送，既不合并，也不拆分，而是保留这些报文的边界

#### 粘包产生的原因

TCP是基于字节流的，数据块是没有边界、没有结构的字节流，因此可能产生粘包：

- 发送方为了将多个发往接收端的包，更有效的发到对方，使用了优化算法(Nagle算法)，将多次间隔较小、数据量小的数据包，合并成一个大的数据包一次性发送
- 接收方不能及时读取数据，导致缓冲区中的多个包粘连

#### 如何解决粘包问题

1. 发送方关闭 Nagle 算法
2. 应用层定义消息边界，最常见的两种解决方案是基于长度或者基于终结符
   - 基于长度的实现有两种方式，一种是**使用固定长度**；另一种是使用不固定长度，但是需要在应用层协议的协议头中增加表示负载长度的字段，HTTP协议的消息边界就是基于长度实现的
   - HTTP协议除了基于长度的方式实现边界，也会使用基于**终结符**的策略，当HTTP使用块传输机制时，HTTP头中就不再包含 Content-Length 了，它会使用负载大小为0的HTTP消息作为终结符表示消息的边界，如果消息里刚好有这个作为边界的特殊字符，我们要对这个字符转义，避免被接收方打后排消息的边界点而解析到无效的数据
   - 基于特定的规则实现消息的边界，例如：使用TCP协议发送JSON数据，接收方可以根据接收到的数据是否能够被解析成合法的JSON判断消息是否终结

### keep alive 状态

定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的TCP连接已经死亡，系统内核将错误信息通知给上层应用程序

### TCP的Keep-Alive和HTTP的Keep-Alive的区别

- HTTP的Keep-Alive：是由应用层(用户态)实现的，称为HTTP长连接
  - 使用同一个TCP连接来发送和接收多个HTTP请求/应答，避免了连接建立和释放的开销，即HTTP长连接
- TCP的Keep-Alive：是由TCP层(内核态)实现的，称为TCP保活机制

### TCP的缺陷

- 升级TCP的工作很困难
- TCP建立连接的延迟
- TCP存在队头阻塞问题
- 网络迁移需要重新建立TCP连接



## TCP和UDP可以使用同一个端口吗

### TCP和UDP可以绑定相同的端口吗

可以

在数据链路层中，通过MAC地址来寻找局域网中的主机。在网际层中，通过IP地址来寻找网络中互连的主机或路由器。在传输层中，需要通过端口进行寻址，来识别同一计算机中同时通信的不同应用程序。

所以传输层的端口号是为了区分同一主机上不同应用程序的数据包。

传输层有两个传输协议分别是TCP和UDP，在内核中是两个完全独立的软件模块。当主机收到数据包后，可以在IP包头的「协议号」字段知道该数据包是 TCP/UDP，所以可以根据这个信息确定发送给哪个模块处理，发送给TCP/UDP模块的报文根据「端口号」确定发送给哪个应用程序处理。

因此，TCP/UDP各自的端口号也相互独立，如TCP有一个80号端口，UDP也可以有一个80号端口，二者并不冲突

### 多个TCP服务进程可以绑定同一个端口吗

如果两个TCP服务进程同时绑定的IP地址和端口号都相同，那么执行bind()时候就会出错，错误是"Address already in use"

0.0.0.0 代表任意地址，意味着绑定了0.0.0.0地址，相当于把主机上的所有IP地址都绑定了

当TCP服务进程重启时，服务端会出现 TIME_WAIT状态的连接，TIME_WAIT状态的连接使用的IP+PORT 仍然被认为是一个有效的IP+PORT组合，相同机器上不能够在该IP+PORT组合上进行绑定，那么执行bind()函数的时候，就会返回 Address already in use 的错误

SO_REUSEADDR：

- 如果当前启动进程绑定的IP+PORT 与处于 TIME_WAIT 状态的连接占用的 IP+PORT 存在冲突，但是新启动的进程使用了 SO_REUSEADDR 选项，那么该进程就可以绑定成功
- 绑定 IP 地址 + 端口时，只要 IP 地址不是正好相同，那么允许绑定

### 客户端的端口可以重复使用吗

TCP 连接是由四元组（源IP地址，源端口，目的IP地址，目的端口）唯一确认的，那么只要四元组中其中一个元素发生了变化，那么就表示不同的 TCP 连接的。所以如果客户端已使用端口 64992 与服务端 A 建立了连接，那么客户端要与服务端 B 建立连接，还是可以使用端口 64992 的，因为内核是通过四元祖信息来定位一个 TCP 连接的，并不会因为客户端的端口号相同，而导致连接冲突的问题。

### 如何解决客户端TCP连接TIME_WAIT 过多，导致无法与同一个服务器建立连接的问题

打开`net.ipv4.tcp_tw_reuse`，开启了这个内核参数后，客户端调用connect函数时，如果选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于TIME_WAIT状态，如果该连接处于TIME_WAIT状态并且TIME_WAIT状态持续的时间超过了1秒，那么就会重用这个连接，然后就可以正常使用该端口了。

## 服务端没有listen，客户端发起连接建立，会发生什么

不使用listen也可以建立连接，客户端可以自己连自己的形成连接，也可以两个客户端同时向对方发送请求建立连接，这两种情况都有个共同点，就是没有服务端参与，也就是没有listen就能建立连接

**没有listen，为啥还能建立连接**
执行listen时，会创建半连接队列和全连接队列，但是客户端因为没有listen，所以没有这两个队列，但内核还有个全局hash表，可以用于存放sock连接的信息。

在TCP自连接的情况中，客户端在connect方法时，最后会将自己的连接信息放入到这个全局hash表中，然后将信息发出，消息在经过回环地址重新回到TCP传输层的时候，就会根据IP+端口信息，再一次从这个全局hash中取出信息，于是握手包一来一回，最后成功建立连接

## 没有accept，能建立TCP连接吗

执行accept()只是为了从全连接队列里取出一条连接

## 使用TCP数据一定不会丢失吗

- 建立连接时丢包
	- 半连接队列和全连接队列是有长度的，如果满了的话，新来的包可能会被丢弃

- 流量控制丢包
	- 如果发送数据过快，但是流控队列的长度又不够大，那么就容易出现丢包现象

- 网卡丢包
	- RingBuffer过小导致丢包
		- 在接收数据时，会将数据暂存到RingBuffer接收缓冲区中，然后等着内核触发软中断慢慢收走。如果这个缓冲区过小，而这时候发送的数据又过快，就有可能发生溢出，此时也会产生丢包
	- 网卡的性能不足
		- 网卡作为硬件，传输速度是有上限的。当网络传输速度过大，达到网卡上限时，就会发生丢包

- 接收缓冲区丢包
	- 当接收缓冲区满了，即零窗口，一般这种情况发送端会停止发消息了，但如果这时候确实还有数据发来，就会发生丢包

- 两端之间的网络丢包
	- 两端之间的链路，即各种路由器、交换机和光缆等



## udp丢包会发生什么




## 网络层如何转发数据包

## URL输入后的执行过程

## IP

- IP处于第三层的网络层，主要作用是实现主机与主机之间的通信，也叫点对点通信
- MAC(数据链路层)的作用是实现「直连」的两个设备之间通信，IP则负责「没有直连」的两个网络之间进行通信传输。

### IP地址的分类

![cmDMKo](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/cmDMKo.png)

分为A、B、C、D、E类地址，根据的是相应的位是否为0来判断，如果前四位全是1，则为E类

- 主机号全为1指定某个网络下的左右主机，用于广播
- 主机号全为0指定某个网络

广播地址用于在同一个链路中相互连接的主机之间发送数据包
- 本地广播：在本网络内的广播
- 直接广播：在不同网络之间的广播

D类和E类地址没有主机号，所以不可用于主机IP，D类常用于多播，E类是预留的分类，暂时未使用

多播是将包发送给特定组内的所有主机

IP分类的优点
- 简单明了、选路(基于网络地址)简单
IP分类的缺点
- 同一网络下没有地址层次，所以缺少地址的灵活性
- 不能很好的与显示网络匹配，C类地址包含的最大主机数太少了，只有254个，而B类地址包含的主机数却有6万多个
- 可以通过CIDR解决

### 无分类地址CIDR

不再使用分类地址
- 将32比特的IP地址划分为网络号和主机号
- 使用子网掩码

#### 为什么要分离网络号和主机号

因为两台计算机要通讯，首先要判断是否处于同一个广播域内，即网络地址是否相同。如果网络地址相同，表明接受方在本网络上，那么就可以把数据包直接发送到目标主机。

路由器寻址工作中，也就是通过这样的方式来找到对应的网络号的，进而把数据包转发给对应的网络内。

#### 怎么进行子网划分

子网划分实际上是将主机地址划分为两个部分：子网网络地址和子网主机地址

### IP地址与路由控制

IP地址的网络地址这一部分是用于进行路由控制

路由控制表中记录着网络地址与下一步应该发送至路由器的地址。在主机和路由器上都会有各自的路由控制表。

在发送IP包时，首先要确定IP包首部中的目标地址，再从路由控制表中找到与该地址具有相同网络地址的记录，根据该记录将IP包转发给相应的下一个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择相同位数最多的网络地址，也就是最长匹配

### IP分片与重组

每种数据链路的最大传输单元MTU都是不同的，主要是因为每个不同类型的数据链路的使用目的不同，使用目的不同，可承载的MTU也就不同。

在分片传输的过程中，一旦某个分片丢失，则会造成整个IP数据报作废，所以TCP引入了MSS，也就是在TCP层进行分片，不由IP层分片

## ARP

ARP协议是已知IP地址求MAC地址

- 主机会通过广播发送ARP请求，这个包中包含了想要直到的MAC地址的主机IP地址
- 当同个链路中的所有设备收到ARP请求时，会去拆开ARP请求包里的内容，如果ARP请求包中的目标IP地址与自己的IP地址一致，那么这个设备就将自己的MAC地址塞入ARP响应包返回给主机

## RARP

概括： 反向地址转换协议，网络层协议，RARP与ARP工作方式相反。 RARP使只知道自己硬件地址的主机能够知道其IP地址。RARP发出要反向解释的物理地址并希望返回其IP地址，应答包括能够提供所需信息的RARP服务器发出的IP地址。 

原理： 
- 网络上的每台设备都会有一个独一无二的硬件地址，通常是由设备厂商分配的MAC地址。主机从网卡上读取MAC地址，然后在网络上发送一个RARP请求的广播数据包，请求RARP服务器回复该主机的IP地址。
- RARP服务器收到了RARP请求数据包，为其分配IP地址，并将RARP回应发送给主机。
- PC1收到RARP回应后，就使用得到的IP地址进行通讯。

## DHCP

DHCP是用来动态获取IP地址

- 客户端首先发起DHCP发现报文的IP数据报，由于客户端没有IP地址，也不知道DHCP服务器的地址，所以使用的是UDP广播通信，其使用的广播目的地址是 255.255.255.255，并且使用 0.0.0.0 作为源IP地址，DHCP客户端将该IP数据报传递给链路层，链路层然后将帧广播到所有的网络设备
- DHCP服务器收到DHCP发现报文时，用DHCP提供报文向客户端做出响应。该报文仍然使用IP广播地址 255.255.255.255，该报文信息携带服务器提供可租约的IP地址、子网掩码、默认网关、DNS服务器以及IP地址租用期
- 客户端收到一个或多个服务器的DHCP提供报文后，从中选择一个服务器，并向选中的服务器发送DHCP请求报文进行响应，回显配置的参数
- 最后，服务端用DHCP ACK报文对DHCP请求报文进行响应，应答所要求的参数

如果租约的DHCP IP地址快到期时，客户端会向服务端发送DHCP请求报文：
- 服务器如果同意继续租用，则用DHCP ACK 报文进行应答，客户端就会继续延长租期
- 服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要弹指使用租约的 IP 地址

在 DHCP 交互中，全程都是使用 UDP 广播通信

DHCP中继代理：
如果DHCP服务器和客户端不是在同一个局域网内，路由器又不会转发广播包的问题，有了DHCP中继代理，对不同网段的IP地址分配也可以由一个DHCP服务器统一进行管理
- DHCP客户端向DHCP中继代理发送DHCP请求包，而DHCP中继代理在收到这个广播包以后，再以单播的形式发给DHCP服务器
- 服务端收到该包以后再向DHCP中继代理返回应答，并由DHCP中继代理将此包广播给DHCP客户端

## NAT

NAT是为了缓解IPV4地址耗尽而提出的，即把私有IP地址转换为公有IP地址，可以把多个私有IP地址转换为同一个公有IP地址，但是是以不同的端口号作为区分的

NAT的缺陷
- 外部无法主动与NAT内部服务器建立连接，因为NAPT转换表没有转换记录
- 转换表的生成与转换操作都会产生性能开销
- 通信过程中，如果NAT路由器重启了，所有的TCP连接都将被重置

解决方案：
- 改用IPV6
- NAT穿透技术
	- 客户端主动获取NAT设备的公有IP，并为自己建立端口映射条目，然后用这个条目对外通信，就不需要NAT设备来进行转换了

## ICMP

主要功能：确认IP包是否发送到达目的地址，报告发送过程中IP包被废弃的原因和改善网络设置等

ICMP大致可以分为两大类
- 用于诊断的查询信息，即「查询报文类型」
- 通知出错原因的错误信息，即「差错报文类型」

![XQb8Jw](https://cdn.jsdelivr.net/gh/Maxaayang/pic@main/uPic/XQb8Jw.png)

**查询报文**

回送消息——类型 0 和 8

回送消息用于进行通信的主机或路由器之间，判断所发送的数据包是否已经成功到达对端的一种消息，ping 命令就是利用这个消息实现的。
只要正常返回了ICMP回送响应，则代表发送端主机到达接收端主机是否可达

可以向对端主机发送**回送请求**的消息（`ICMP Echo Request Message`，类型 `8`），也可以接收对端主机发回来的**回送应答**消息（`ICMP Echo Reply Message`，类型 `0`）。

相比原生的 ICMP，这里多了两个字段：
-   **标识符**：用以区分是哪个应用程序发 ICMP 包，比如用进程 `PID` 作为标识符；
-   **序号**：序列号从 `0` 开始，每发送一次新的回送请求就会加 `1`， 可以用来确认网络包是否有丢失。

在**选项数据**中，`ping` 还会存放发送请求的时间值，来计算往返时间，说明路程的长短。

**差错报文**

- 目标不可达消息——类型为3
- 原点抑制消息——类型为4
- 重定向消息——类型为5
- 超时消息——类型为11

## IGMP

IGMP 是因特网组管理协议，工作在主机（组播成员）和最后一跳路由之间
- IGMP 报文向路由器申请加入和退出组播组，默认情况下路由器是不会转发组播包到连接中的主机，除非主机通过 IGMP 加入到组播组，主机申请加入到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转发组播包到对应的主机了。
- IGMP 报文采用 IP 封装，IP 头部的协议号为 2，而且 TTL 字段值通常为 1，因为 IGMP 是工作在主机与连接的路由器之间。

## ping 的工作原理

ping 是基于 ICMP 协议工作的





## IP数据分片有什么弊端